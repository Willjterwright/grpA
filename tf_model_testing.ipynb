{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Loading modules\n",
    "\n",
    "import tensorflow as tf\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "from sklearn import metrics\n",
    "from sklearn.metrics import f1_score\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "import model_stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lets load the data, i have preprocessed it, pslit it randomly and exported it in another notebook\n",
    "#To make it easier to manipulate here\n",
    "\n",
    "train = pd.read_csv('train.csv')\n",
    "test = pd.read_csv('test.csv')\n",
    "val = pd.read_csv('val.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Lets drop the unnecessary columns and select our X and y data\n",
    "train_X = train.drop(['Unnamed: 0', 'ids', 'tox_bin'], axis = 1)\n",
    "train_y = train['tox_bin']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Similarly for the val data\n",
    "val_X = val.drop(['Unnamed: 0', 'ids', 'tox_bin'], axis = 1)\n",
    "val_y = val['tox_bin']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#And the test data, I have kept the ids column in the test data so we can have a look at the most toxic molecules\n",
    "test_X = test.drop(['Unnamed: 0', 'tox_bin'], axis = 1)\n",
    "test_y = test['tox_bin']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "small_model = tf.keras.models.Sequential(\n",
    "    [\n",
    "        tf.keras.layers.Dense(32, activation = 'relu', input_shape = (train_X.shape[1],)),\n",
    "        tf.keras.layers.Dropout(0.5),\n",
    "        tf.keras.layers.BatchNormalization(),\n",
    "        tf.keras.layers.Dense(10, activation = 'relu'),\n",
    "        tf.keras.layers.Dropout(0.5),\n",
    "        tf.keras.layers.BatchNormalization(),\n",
    "        tf.keras.layers.Dense(1, activation = 'sigmoid')\n",
    "    ]\n",
    ")\n",
    "\n",
    "small_model.compile(\n",
    "    optimizer = 'adam',\n",
    "    loss = 'binary_crossentropy',\n",
    "    metrics = ['accuracy']\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "medium_model = tf.keras.models.load_model('tf_model.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "large_model = tf.keras.models.Sequential(\n",
    "    [\n",
    "        tf.keras.layers.Dense(1500, activation = 'relu', input_shape = (train_X.shape[1],)),\n",
    "        tf.keras.layers.Dropout(0.7),\n",
    "        tf.keras.layers.BatchNormalization(),\n",
    "        tf.keras.layers.Dense(750, activation = 'relu'),\n",
    "        tf.keras.layers.Dropout(0.7),\n",
    "        tf.keras.layers.BatchNormalization(),\n",
    "        tf.keras.layers.Dense(250, activation = 'relu'),\n",
    "        tf.keras.layers.Dropout(0.7),\n",
    "        tf.keras.layers.BatchNormalization(),\n",
    "        tf.keras.layers.Dense(1, activation = 'sigmoid')\n",
    "    ]\n",
    ")\n",
    "\n",
    "large_model.compile(\n",
    "    optimizer = 'adam',\n",
    "    loss = 'binary_crossentropy',\n",
    "    metrics = ['accuracy']\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU')]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.config.list_physical_devices('GPU')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/500\n",
      "62/62 [==============================] - 1s 13ms/step - loss: 0.6642 - accuracy: 0.6038 - val_loss: 0.6435 - val_accuracy: 0.6849\n",
      "Epoch 2/500\n",
      "62/62 [==============================] - 1s 11ms/step - loss: 0.6613 - accuracy: 0.6092 - val_loss: 0.6437 - val_accuracy: 0.6760\n",
      "Epoch 3/500\n",
      "62/62 [==============================] - 1s 10ms/step - loss: 0.6577 - accuracy: 0.6149 - val_loss: 0.6420 - val_accuracy: 0.6798\n",
      "Epoch 4/500\n",
      "62/62 [==============================] - 1s 10ms/step - loss: 0.6582 - accuracy: 0.6112 - val_loss: 0.6394 - val_accuracy: 0.6824\n",
      "Epoch 5/500\n",
      "62/62 [==============================] - 1s 10ms/step - loss: 0.6573 - accuracy: 0.6130 - val_loss: 0.6387 - val_accuracy: 0.6837\n",
      "Epoch 6/500\n",
      "62/62 [==============================] - 1s 10ms/step - loss: 0.6572 - accuracy: 0.6191 - val_loss: 0.6361 - val_accuracy: 0.6862\n",
      "Epoch 7/500\n",
      "62/62 [==============================] - 1s 10ms/step - loss: 0.6539 - accuracy: 0.6259 - val_loss: 0.6367 - val_accuracy: 0.6837\n",
      "Epoch 8/500\n",
      "62/62 [==============================] - 1s 10ms/step - loss: 0.6526 - accuracy: 0.6205 - val_loss: 0.6345 - val_accuracy: 0.6875\n",
      "Epoch 9/500\n",
      "62/62 [==============================] - 1s 11ms/step - loss: 0.6481 - accuracy: 0.6324 - val_loss: 0.6334 - val_accuracy: 0.6888\n",
      "Epoch 10/500\n",
      "62/62 [==============================] - 1s 10ms/step - loss: 0.6459 - accuracy: 0.6299 - val_loss: 0.6322 - val_accuracy: 0.6888\n",
      "Epoch 11/500\n",
      "62/62 [==============================] - 1s 11ms/step - loss: 0.6448 - accuracy: 0.6319 - val_loss: 0.6313 - val_accuracy: 0.6888\n",
      "Epoch 12/500\n",
      "62/62 [==============================] - 1s 10ms/step - loss: 0.6470 - accuracy: 0.6282 - val_loss: 0.6307 - val_accuracy: 0.6901\n",
      "Epoch 13/500\n",
      "62/62 [==============================] - 1s 10ms/step - loss: 0.6456 - accuracy: 0.6335 - val_loss: 0.6303 - val_accuracy: 0.6913\n",
      "Epoch 14/500\n",
      "62/62 [==============================] - 1s 10ms/step - loss: 0.6453 - accuracy: 0.6373 - val_loss: 0.6308 - val_accuracy: 0.6901\n",
      "Epoch 15/500\n",
      "62/62 [==============================] - 1s 10ms/step - loss: 0.6467 - accuracy: 0.6348 - val_loss: 0.6284 - val_accuracy: 0.6939\n",
      "Epoch 16/500\n",
      "62/62 [==============================] - 1s 10ms/step - loss: 0.6436 - accuracy: 0.6357 - val_loss: 0.6279 - val_accuracy: 0.6862\n",
      "Epoch 17/500\n",
      "62/62 [==============================] - 1s 10ms/step - loss: 0.6414 - accuracy: 0.6415 - val_loss: 0.6285 - val_accuracy: 0.6913\n",
      "Epoch 18/500\n",
      "62/62 [==============================] - 1s 10ms/step - loss: 0.6389 - accuracy: 0.6447 - val_loss: 0.6274 - val_accuracy: 0.6901\n",
      "Epoch 19/500\n",
      "62/62 [==============================] - 1s 10ms/step - loss: 0.6395 - accuracy: 0.6449 - val_loss: 0.6284 - val_accuracy: 0.6824\n",
      "Epoch 20/500\n",
      "62/62 [==============================] - 1s 10ms/step - loss: 0.6374 - accuracy: 0.6473 - val_loss: 0.6282 - val_accuracy: 0.6824\n",
      "Epoch 21/500\n",
      "62/62 [==============================] - 1s 11ms/step - loss: 0.6378 - accuracy: 0.6470 - val_loss: 0.6274 - val_accuracy: 0.6952\n",
      "Epoch 22/500\n",
      "62/62 [==============================] - 1s 11ms/step - loss: 0.6360 - accuracy: 0.6454 - val_loss: 0.6277 - val_accuracy: 0.6798\n",
      "Epoch 23/500\n",
      "62/62 [==============================] - 1s 11ms/step - loss: 0.6346 - accuracy: 0.6435 - val_loss: 0.6262 - val_accuracy: 0.6913\n",
      "Epoch 24/500\n",
      "62/62 [==============================] - 1s 11ms/step - loss: 0.6339 - accuracy: 0.6479 - val_loss: 0.6254 - val_accuracy: 0.6901\n",
      "Epoch 25/500\n",
      "62/62 [==============================] - 1s 10ms/step - loss: 0.6347 - accuracy: 0.6505 - val_loss: 0.6258 - val_accuracy: 0.6849\n",
      "Epoch 26/500\n",
      "62/62 [==============================] - 1s 9ms/step - loss: 0.6387 - accuracy: 0.6480 - val_loss: 0.6292 - val_accuracy: 0.6798\n",
      "Epoch 27/500\n",
      "62/62 [==============================] - 1s 10ms/step - loss: 0.6316 - accuracy: 0.6503 - val_loss: 0.6289 - val_accuracy: 0.6811\n",
      "Epoch 28/500\n",
      "62/62 [==============================] - 1s 11ms/step - loss: 0.6304 - accuracy: 0.6553 - val_loss: 0.6299 - val_accuracy: 0.6760\n",
      "Epoch 29/500\n",
      "62/62 [==============================] - 1s 10ms/step - loss: 0.6305 - accuracy: 0.6504 - val_loss: 0.6273 - val_accuracy: 0.6862\n",
      "Epoch 30/500\n",
      "62/62 [==============================] - 1s 11ms/step - loss: 0.6354 - accuracy: 0.6544 - val_loss: 0.6285 - val_accuracy: 0.6798\n",
      "Epoch 31/500\n",
      "62/62 [==============================] - 1s 10ms/step - loss: 0.6322 - accuracy: 0.6554 - val_loss: 0.6287 - val_accuracy: 0.6837\n",
      "Epoch 32/500\n",
      "62/62 [==============================] - 1s 10ms/step - loss: 0.6251 - accuracy: 0.6657 - val_loss: 0.6279 - val_accuracy: 0.6773\n",
      "Epoch 33/500\n",
      "62/62 [==============================] - 1s 10ms/step - loss: 0.6271 - accuracy: 0.6585 - val_loss: 0.6261 - val_accuracy: 0.6747\n",
      "Epoch 34/500\n",
      "62/62 [==============================] - 1s 10ms/step - loss: 0.6219 - accuracy: 0.6589 - val_loss: 0.6291 - val_accuracy: 0.6735\n",
      "Epoch 35/500\n",
      "62/62 [==============================] - 1s 10ms/step - loss: 0.6238 - accuracy: 0.6630 - val_loss: 0.6261 - val_accuracy: 0.6888\n",
      "Epoch 36/500\n",
      "62/62 [==============================] - 1s 10ms/step - loss: 0.6259 - accuracy: 0.6646 - val_loss: 0.6276 - val_accuracy: 0.6786\n",
      "Epoch 37/500\n",
      "62/62 [==============================] - 1s 11ms/step - loss: 0.6225 - accuracy: 0.6673 - val_loss: 0.6273 - val_accuracy: 0.6773\n",
      "Epoch 38/500\n",
      "62/62 [==============================] - 1s 10ms/step - loss: 0.6233 - accuracy: 0.6718 - val_loss: 0.6261 - val_accuracy: 0.6849\n",
      "Epoch 39/500\n",
      "62/62 [==============================] - 1s 10ms/step - loss: 0.6189 - accuracy: 0.6646 - val_loss: 0.6344 - val_accuracy: 0.6658\n",
      "Epoch 40/500\n",
      "62/62 [==============================] - 1s 10ms/step - loss: 0.6221 - accuracy: 0.6655 - val_loss: 0.6293 - val_accuracy: 0.6747\n",
      "Epoch 41/500\n",
      "62/62 [==============================] - 1s 11ms/step - loss: 0.6255 - accuracy: 0.6670 - val_loss: 0.6314 - val_accuracy: 0.6645\n",
      "Epoch 42/500\n",
      "62/62 [==============================] - 1s 10ms/step - loss: 0.6207 - accuracy: 0.6730 - val_loss: 0.6312 - val_accuracy: 0.6684\n",
      "Epoch 43/500\n",
      "62/62 [==============================] - 1s 10ms/step - loss: 0.6191 - accuracy: 0.6621 - val_loss: 0.6304 - val_accuracy: 0.6645\n",
      "Epoch 44/500\n",
      "62/62 [==============================] - 1s 11ms/step - loss: 0.6193 - accuracy: 0.6672 - val_loss: 0.6271 - val_accuracy: 0.6760\n",
      "Epoch 45/500\n",
      "62/62 [==============================] - 1s 11ms/step - loss: 0.6218 - accuracy: 0.6626 - val_loss: 0.6298 - val_accuracy: 0.6684\n",
      "Epoch 46/500\n",
      "62/62 [==============================] - 1s 10ms/step - loss: 0.6164 - accuracy: 0.6702 - val_loss: 0.6246 - val_accuracy: 0.6709\n",
      "Epoch 47/500\n",
      "62/62 [==============================] - 1s 10ms/step - loss: 0.6179 - accuracy: 0.6679 - val_loss: 0.6307 - val_accuracy: 0.6709\n",
      "Epoch 48/500\n",
      "62/62 [==============================] - 1s 10ms/step - loss: 0.6207 - accuracy: 0.6677 - val_loss: 0.6305 - val_accuracy: 0.6658\n",
      "Epoch 49/500\n",
      "62/62 [==============================] - 1s 10ms/step - loss: 0.6158 - accuracy: 0.6778 - val_loss: 0.6264 - val_accuracy: 0.6696\n",
      "Epoch 50/500\n",
      "62/62 [==============================] - 1s 10ms/step - loss: 0.6104 - accuracy: 0.6795 - val_loss: 0.6287 - val_accuracy: 0.6684\n",
      "Epoch 51/500\n",
      "62/62 [==============================] - 1s 10ms/step - loss: 0.6170 - accuracy: 0.6747 - val_loss: 0.6299 - val_accuracy: 0.6582\n",
      "Epoch 52/500\n",
      "62/62 [==============================] - 1s 11ms/step - loss: 0.6125 - accuracy: 0.6710 - val_loss: 0.6284 - val_accuracy: 0.6658\n",
      "Epoch 53/500\n",
      "62/62 [==============================] - 1s 11ms/step - loss: 0.6072 - accuracy: 0.6785 - val_loss: 0.6257 - val_accuracy: 0.6722\n",
      "Epoch 54/500\n",
      "62/62 [==============================] - 1s 10ms/step - loss: 0.6163 - accuracy: 0.6759 - val_loss: 0.6279 - val_accuracy: 0.6722\n",
      "Epoch 55/500\n",
      "62/62 [==============================] - 1s 10ms/step - loss: 0.6112 - accuracy: 0.6732 - val_loss: 0.6275 - val_accuracy: 0.6722\n",
      "Epoch 56/500\n",
      "62/62 [==============================] - 1s 10ms/step - loss: 0.6109 - accuracy: 0.6781 - val_loss: 0.6285 - val_accuracy: 0.6645\n",
      "Epoch 57/500\n",
      "62/62 [==============================] - 1s 10ms/step - loss: 0.6158 - accuracy: 0.6756 - val_loss: 0.6321 - val_accuracy: 0.6722\n",
      "Epoch 58/500\n",
      "62/62 [==============================] - 1s 11ms/step - loss: 0.6129 - accuracy: 0.6780 - val_loss: 0.6313 - val_accuracy: 0.6620\n",
      "Epoch 59/500\n",
      "62/62 [==============================] - 1s 10ms/step - loss: 0.6122 - accuracy: 0.6761 - val_loss: 0.6328 - val_accuracy: 0.6696\n",
      "Epoch 60/500\n",
      "62/62 [==============================] - 1s 9ms/step - loss: 0.6075 - accuracy: 0.6737 - val_loss: 0.6336 - val_accuracy: 0.6620\n",
      "Epoch 61/500\n",
      "62/62 [==============================] - 1s 9ms/step - loss: 0.6071 - accuracy: 0.6818 - val_loss: 0.6353 - val_accuracy: 0.6607\n",
      "Epoch 62/500\n",
      "62/62 [==============================] - 1s 9ms/step - loss: 0.6087 - accuracy: 0.6742 - val_loss: 0.6309 - val_accuracy: 0.6722\n",
      "Epoch 63/500\n",
      "62/62 [==============================] - 1s 10ms/step - loss: 0.6074 - accuracy: 0.6900 - val_loss: 0.6357 - val_accuracy: 0.6569\n",
      "Epoch 64/500\n",
      "62/62 [==============================] - 1s 10ms/step - loss: 0.6054 - accuracy: 0.6786 - val_loss: 0.6359 - val_accuracy: 0.6620\n",
      "Epoch 65/500\n",
      "62/62 [==============================] - 1s 10ms/step - loss: 0.6108 - accuracy: 0.6797 - val_loss: 0.6328 - val_accuracy: 0.6735\n",
      "Epoch 66/500\n",
      "62/62 [==============================] - 1s 10ms/step - loss: 0.6051 - accuracy: 0.6836 - val_loss: 0.6310 - val_accuracy: 0.6760\n",
      "Epoch 67/500\n",
      "62/62 [==============================] - 1s 10ms/step - loss: 0.6019 - accuracy: 0.6832 - val_loss: 0.6317 - val_accuracy: 0.6684\n",
      "Epoch 68/500\n",
      "62/62 [==============================] - 1s 10ms/step - loss: 0.6078 - accuracy: 0.6804 - val_loss: 0.6284 - val_accuracy: 0.6824\n",
      "Epoch 69/500\n",
      "62/62 [==============================] - 1s 10ms/step - loss: 0.6027 - accuracy: 0.6818 - val_loss: 0.6251 - val_accuracy: 0.6773\n",
      "Epoch 70/500\n",
      "62/62 [==============================] - 1s 10ms/step - loss: 0.6052 - accuracy: 0.6829 - val_loss: 0.6295 - val_accuracy: 0.6786\n",
      "Epoch 71/500\n",
      "62/62 [==============================] - 1s 11ms/step - loss: 0.5986 - accuracy: 0.6865 - val_loss: 0.6344 - val_accuracy: 0.6709\n",
      "Epoch 72/500\n",
      "62/62 [==============================] - 1s 10ms/step - loss: 0.5986 - accuracy: 0.6919 - val_loss: 0.6285 - val_accuracy: 0.6722\n",
      "Epoch 73/500\n",
      "62/62 [==============================] - 1s 10ms/step - loss: 0.6038 - accuracy: 0.6793 - val_loss: 0.6262 - val_accuracy: 0.6786\n",
      "Epoch 74/500\n",
      "62/62 [==============================] - 1s 11ms/step - loss: 0.6008 - accuracy: 0.6935 - val_loss: 0.6293 - val_accuracy: 0.6760\n",
      "Epoch 75/500\n",
      "62/62 [==============================] - 1s 10ms/step - loss: 0.6028 - accuracy: 0.6848 - val_loss: 0.6347 - val_accuracy: 0.6722\n",
      "Epoch 76/500\n",
      "62/62 [==============================] - 1s 10ms/step - loss: 0.5982 - accuracy: 0.6870 - val_loss: 0.6312 - val_accuracy: 0.6747\n",
      "Epoch 77/500\n",
      "62/62 [==============================] - 1s 10ms/step - loss: 0.6071 - accuracy: 0.6790 - val_loss: 0.6266 - val_accuracy: 0.6849\n",
      "Epoch 78/500\n",
      "62/62 [==============================] - 1s 10ms/step - loss: 0.6034 - accuracy: 0.6847 - val_loss: 0.6364 - val_accuracy: 0.6709\n",
      "Epoch 79/500\n",
      "62/62 [==============================] - 1s 10ms/step - loss: 0.6022 - accuracy: 0.6813 - val_loss: 0.6316 - val_accuracy: 0.6735\n",
      "Epoch 80/500\n",
      "62/62 [==============================] - 1s 10ms/step - loss: 0.6017 - accuracy: 0.6882 - val_loss: 0.6293 - val_accuracy: 0.6658\n",
      "Epoch 81/500\n",
      "62/62 [==============================] - 1s 10ms/step - loss: 0.5992 - accuracy: 0.6884 - val_loss: 0.6352 - val_accuracy: 0.6760\n",
      "Epoch 82/500\n",
      "62/62 [==============================] - 1s 10ms/step - loss: 0.6009 - accuracy: 0.6823 - val_loss: 0.6342 - val_accuracy: 0.6696\n",
      "Epoch 83/500\n",
      "62/62 [==============================] - 1s 10ms/step - loss: 0.5969 - accuracy: 0.6829 - val_loss: 0.6273 - val_accuracy: 0.6837\n",
      "Epoch 84/500\n",
      "62/62 [==============================] - 1s 10ms/step - loss: 0.5985 - accuracy: 0.6839 - val_loss: 0.6288 - val_accuracy: 0.6786\n",
      "Epoch 85/500\n",
      "62/62 [==============================] - 1s 11ms/step - loss: 0.5990 - accuracy: 0.6839 - val_loss: 0.6391 - val_accuracy: 0.6671\n",
      "Epoch 86/500\n",
      "62/62 [==============================] - 1s 13ms/step - loss: 0.6019 - accuracy: 0.6891 - val_loss: 0.6323 - val_accuracy: 0.6722\n",
      "Epoch 87/500\n",
      "62/62 [==============================] - 1s 11ms/step - loss: 0.5944 - accuracy: 0.6858 - val_loss: 0.6224 - val_accuracy: 0.6811\n",
      "Epoch 88/500\n",
      "62/62 [==============================] - 1s 10ms/step - loss: 0.5975 - accuracy: 0.6862 - val_loss: 0.6239 - val_accuracy: 0.6811\n",
      "Epoch 89/500\n",
      "62/62 [==============================] - 1s 10ms/step - loss: 0.6020 - accuracy: 0.6924 - val_loss: 0.6330 - val_accuracy: 0.6722\n",
      "Epoch 90/500\n",
      "62/62 [==============================] - 1s 13ms/step - loss: 0.6006 - accuracy: 0.6885 - val_loss: 0.6255 - val_accuracy: 0.6722\n",
      "Epoch 91/500\n",
      "62/62 [==============================] - 1s 15ms/step - loss: 0.5968 - accuracy: 0.6914 - val_loss: 0.6376 - val_accuracy: 0.6594\n",
      "Epoch 92/500\n",
      "62/62 [==============================] - 1s 12ms/step - loss: 0.5924 - accuracy: 0.6915 - val_loss: 0.6311 - val_accuracy: 0.6722\n",
      "Epoch 93/500\n",
      "62/62 [==============================] - 1s 12ms/step - loss: 0.5965 - accuracy: 0.6866 - val_loss: 0.6332 - val_accuracy: 0.6696\n",
      "Epoch 94/500\n",
      "62/62 [==============================] - 1s 10ms/step - loss: 0.5893 - accuracy: 0.6964 - val_loss: 0.6303 - val_accuracy: 0.6735\n",
      "Epoch 95/500\n",
      "62/62 [==============================] - 1s 10ms/step - loss: 0.5888 - accuracy: 0.6958 - val_loss: 0.6219 - val_accuracy: 0.6760\n",
      "Epoch 96/500\n",
      "62/62 [==============================] - 1s 10ms/step - loss: 0.5921 - accuracy: 0.6897 - val_loss: 0.6317 - val_accuracy: 0.6722\n",
      "Epoch 97/500\n",
      "62/62 [==============================] - 1s 11ms/step - loss: 0.5929 - accuracy: 0.6919 - val_loss: 0.6335 - val_accuracy: 0.6620\n",
      "Epoch 98/500\n",
      "62/62 [==============================] - 1s 11ms/step - loss: 0.6002 - accuracy: 0.6905 - val_loss: 0.6374 - val_accuracy: 0.6658\n",
      "Epoch 99/500\n",
      "62/62 [==============================] - 1s 11ms/step - loss: 0.5966 - accuracy: 0.6890 - val_loss: 0.6312 - val_accuracy: 0.6671\n",
      "Epoch 100/500\n",
      "62/62 [==============================] - 1s 9ms/step - loss: 0.5960 - accuracy: 0.6882 - val_loss: 0.6332 - val_accuracy: 0.6722\n",
      "Epoch 101/500\n",
      "62/62 [==============================] - 1s 9ms/step - loss: 0.5943 - accuracy: 0.6938 - val_loss: 0.6275 - val_accuracy: 0.6671\n",
      "Epoch 102/500\n",
      "62/62 [==============================] - 1s 10ms/step - loss: 0.5976 - accuracy: 0.6857 - val_loss: 0.6327 - val_accuracy: 0.6684\n",
      "Epoch 103/500\n",
      "62/62 [==============================] - 1s 10ms/step - loss: 0.5941 - accuracy: 0.6897 - val_loss: 0.6329 - val_accuracy: 0.6658\n",
      "Epoch 104/500\n",
      "62/62 [==============================] - 1s 10ms/step - loss: 0.5978 - accuracy: 0.6901 - val_loss: 0.6307 - val_accuracy: 0.6696\n",
      "Epoch 105/500\n",
      "62/62 [==============================] - 1s 10ms/step - loss: 0.5914 - accuracy: 0.6918 - val_loss: 0.6298 - val_accuracy: 0.6709\n",
      "Epoch 106/500\n",
      "62/62 [==============================] - 1s 11ms/step - loss: 0.5957 - accuracy: 0.6907 - val_loss: 0.6280 - val_accuracy: 0.6696\n",
      "Epoch 107/500\n",
      "62/62 [==============================] - 1s 10ms/step - loss: 0.5919 - accuracy: 0.6991 - val_loss: 0.6265 - val_accuracy: 0.6633\n",
      "Epoch 108/500\n",
      "62/62 [==============================] - 1s 11ms/step - loss: 0.5888 - accuracy: 0.6970 - val_loss: 0.6289 - val_accuracy: 0.6747\n",
      "Epoch 109/500\n",
      "62/62 [==============================] - 1s 13ms/step - loss: 0.5922 - accuracy: 0.6918 - val_loss: 0.6302 - val_accuracy: 0.6798\n",
      "Epoch 110/500\n",
      "62/62 [==============================] - 1s 14ms/step - loss: 0.5980 - accuracy: 0.6965 - val_loss: 0.6314 - val_accuracy: 0.6798\n",
      "Epoch 111/500\n",
      "62/62 [==============================] - 1s 10ms/step - loss: 0.5841 - accuracy: 0.6992 - val_loss: 0.6284 - val_accuracy: 0.6722\n",
      "Epoch 112/500\n",
      "62/62 [==============================] - 1s 10ms/step - loss: 0.5941 - accuracy: 0.6945 - val_loss: 0.6245 - val_accuracy: 0.6773\n",
      "Epoch 113/500\n",
      "62/62 [==============================] - 1s 11ms/step - loss: 0.5902 - accuracy: 0.6993 - val_loss: 0.6270 - val_accuracy: 0.6735\n",
      "Epoch 114/500\n",
      "62/62 [==============================] - 1s 10ms/step - loss: 0.6013 - accuracy: 0.6896 - val_loss: 0.6348 - val_accuracy: 0.6684\n",
      "Epoch 115/500\n",
      "62/62 [==============================] - 1s 10ms/step - loss: 0.5923 - accuracy: 0.6949 - val_loss: 0.6304 - val_accuracy: 0.6722\n",
      "Epoch 116/500\n",
      "62/62 [==============================] - 1s 11ms/step - loss: 0.5937 - accuracy: 0.6904 - val_loss: 0.6283 - val_accuracy: 0.6747\n",
      "Epoch 117/500\n",
      "62/62 [==============================] - 1s 10ms/step - loss: 0.5928 - accuracy: 0.6959 - val_loss: 0.6275 - val_accuracy: 0.6722\n",
      "Epoch 118/500\n",
      "62/62 [==============================] - 1s 10ms/step - loss: 0.5898 - accuracy: 0.6949 - val_loss: 0.6289 - val_accuracy: 0.6760\n",
      "Epoch 119/500\n",
      "62/62 [==============================] - 1s 11ms/step - loss: 0.5920 - accuracy: 0.6926 - val_loss: 0.6295 - val_accuracy: 0.6735\n",
      "Epoch 120/500\n",
      "62/62 [==============================] - 1s 11ms/step - loss: 0.5842 - accuracy: 0.6996 - val_loss: 0.6227 - val_accuracy: 0.6862\n",
      "Epoch 121/500\n",
      "62/62 [==============================] - 1s 10ms/step - loss: 0.5883 - accuracy: 0.6965 - val_loss: 0.6322 - val_accuracy: 0.6773\n",
      "Epoch 122/500\n",
      "62/62 [==============================] - 1s 10ms/step - loss: 0.5844 - accuracy: 0.6988 - val_loss: 0.6328 - val_accuracy: 0.6747\n",
      "Epoch 123/500\n",
      "62/62 [==============================] - 1s 11ms/step - loss: 0.5884 - accuracy: 0.7023 - val_loss: 0.6328 - val_accuracy: 0.6811\n",
      "Epoch 124/500\n",
      "62/62 [==============================] - 1s 11ms/step - loss: 0.5908 - accuracy: 0.6968 - val_loss: 0.6319 - val_accuracy: 0.6760\n",
      "Epoch 125/500\n",
      "62/62 [==============================] - 1s 10ms/step - loss: 0.5938 - accuracy: 0.6920 - val_loss: 0.6319 - val_accuracy: 0.6722\n",
      "Epoch 126/500\n",
      "62/62 [==============================] - 1s 11ms/step - loss: 0.5884 - accuracy: 0.6934 - val_loss: 0.6282 - val_accuracy: 0.6849\n",
      "Epoch 127/500\n",
      "62/62 [==============================] - 1s 11ms/step - loss: 0.5901 - accuracy: 0.6926 - val_loss: 0.6314 - val_accuracy: 0.6722\n",
      "Epoch 128/500\n",
      "62/62 [==============================] - 1s 10ms/step - loss: 0.5870 - accuracy: 0.6991 - val_loss: 0.6356 - val_accuracy: 0.6709\n",
      "Epoch 129/500\n",
      "62/62 [==============================] - 1s 11ms/step - loss: 0.5894 - accuracy: 0.6925 - val_loss: 0.6319 - val_accuracy: 0.6798\n",
      "Epoch 130/500\n",
      "62/62 [==============================] - 1s 10ms/step - loss: 0.5868 - accuracy: 0.6974 - val_loss: 0.6336 - val_accuracy: 0.6658\n",
      "Epoch 131/500\n",
      "62/62 [==============================] - 1s 11ms/step - loss: 0.5926 - accuracy: 0.6889 - val_loss: 0.6309 - val_accuracy: 0.6798\n",
      "Epoch 132/500\n",
      "62/62 [==============================] - 1s 10ms/step - loss: 0.5976 - accuracy: 0.6934 - val_loss: 0.6292 - val_accuracy: 0.6939\n",
      "Epoch 133/500\n",
      "62/62 [==============================] - 1s 10ms/step - loss: 0.5828 - accuracy: 0.7052 - val_loss: 0.6266 - val_accuracy: 0.6849\n",
      "Epoch 134/500\n",
      "62/62 [==============================] - 1s 11ms/step - loss: 0.5973 - accuracy: 0.6843 - val_loss: 0.6320 - val_accuracy: 0.6773\n",
      "Epoch 135/500\n",
      "62/62 [==============================] - 1s 10ms/step - loss: 0.5850 - accuracy: 0.6993 - val_loss: 0.6358 - val_accuracy: 0.6607\n",
      "Epoch 136/500\n",
      "62/62 [==============================] - 1s 10ms/step - loss: 0.5847 - accuracy: 0.7013 - val_loss: 0.6290 - val_accuracy: 0.6709\n",
      "Epoch 137/500\n",
      "62/62 [==============================] - 1s 11ms/step - loss: 0.5830 - accuracy: 0.7045 - val_loss: 0.6275 - val_accuracy: 0.6798\n",
      "Epoch 138/500\n",
      "62/62 [==============================] - 1s 10ms/step - loss: 0.5913 - accuracy: 0.6905 - val_loss: 0.6272 - val_accuracy: 0.6760\n",
      "Epoch 139/500\n",
      "62/62 [==============================] - 1s 10ms/step - loss: 0.5883 - accuracy: 0.7021 - val_loss: 0.6324 - val_accuracy: 0.6747\n",
      "Epoch 140/500\n",
      "62/62 [==============================] - 1s 11ms/step - loss: 0.5906 - accuracy: 0.6904 - val_loss: 0.6226 - val_accuracy: 0.6875\n",
      "Epoch 141/500\n",
      "62/62 [==============================] - 1s 11ms/step - loss: 0.5907 - accuracy: 0.6905 - val_loss: 0.6357 - val_accuracy: 0.6671\n",
      "Epoch 142/500\n",
      "62/62 [==============================] - 1s 11ms/step - loss: 0.5853 - accuracy: 0.6976 - val_loss: 0.6227 - val_accuracy: 0.6798\n",
      "Epoch 143/500\n",
      "62/62 [==============================] - 1s 12ms/step - loss: 0.5926 - accuracy: 0.6929 - val_loss: 0.6242 - val_accuracy: 0.6849\n",
      "Epoch 144/500\n",
      "62/62 [==============================] - 1s 12ms/step - loss: 0.5838 - accuracy: 0.7016 - val_loss: 0.6276 - val_accuracy: 0.6722\n",
      "Epoch 145/500\n",
      "62/62 [==============================] - 1s 10ms/step - loss: 0.5857 - accuracy: 0.6999 - val_loss: 0.6228 - val_accuracy: 0.6824\n",
      "Epoch 146/500\n",
      "62/62 [==============================] - 1s 10ms/step - loss: 0.5880 - accuracy: 0.6984 - val_loss: 0.6239 - val_accuracy: 0.6824\n",
      "Epoch 147/500\n",
      "62/62 [==============================] - 1s 11ms/step - loss: 0.5890 - accuracy: 0.6938 - val_loss: 0.6261 - val_accuracy: 0.6849\n",
      "Epoch 148/500\n",
      "62/62 [==============================] - 1s 11ms/step - loss: 0.5880 - accuracy: 0.7015 - val_loss: 0.6276 - val_accuracy: 0.6824\n",
      "Epoch 149/500\n",
      "62/62 [==============================] - 1s 11ms/step - loss: 0.5828 - accuracy: 0.6988 - val_loss: 0.6288 - val_accuracy: 0.6798\n",
      "Epoch 150/500\n",
      "62/62 [==============================] - 1s 11ms/step - loss: 0.5865 - accuracy: 0.6994 - val_loss: 0.6331 - val_accuracy: 0.6798\n",
      "Epoch 151/500\n",
      "62/62 [==============================] - 1s 11ms/step - loss: 0.5798 - accuracy: 0.7007 - val_loss: 0.6355 - val_accuracy: 0.6684\n",
      "Epoch 152/500\n",
      "62/62 [==============================] - 1s 11ms/step - loss: 0.5847 - accuracy: 0.6953 - val_loss: 0.6312 - val_accuracy: 0.6901\n",
      "Epoch 153/500\n",
      "62/62 [==============================] - 1s 11ms/step - loss: 0.5830 - accuracy: 0.7023 - val_loss: 0.6314 - val_accuracy: 0.6862\n",
      "Epoch 154/500\n",
      "62/62 [==============================] - 1s 11ms/step - loss: 0.5838 - accuracy: 0.6973 - val_loss: 0.6315 - val_accuracy: 0.6747\n",
      "Epoch 155/500\n",
      "62/62 [==============================] - 1s 11ms/step - loss: 0.5875 - accuracy: 0.6931 - val_loss: 0.6292 - val_accuracy: 0.6798\n",
      "Epoch 156/500\n",
      "62/62 [==============================] - 1s 11ms/step - loss: 0.5841 - accuracy: 0.7017 - val_loss: 0.6268 - val_accuracy: 0.6849\n",
      "Epoch 157/500\n",
      "62/62 [==============================] - 1s 11ms/step - loss: 0.5909 - accuracy: 0.6911 - val_loss: 0.6304 - val_accuracy: 0.6811\n",
      "Epoch 158/500\n",
      "62/62 [==============================] - 1s 11ms/step - loss: 0.5856 - accuracy: 0.7037 - val_loss: 0.6257 - val_accuracy: 0.6837\n",
      "Epoch 159/500\n",
      "62/62 [==============================] - 1s 14ms/step - loss: 0.5866 - accuracy: 0.7022 - val_loss: 0.6280 - val_accuracy: 0.6862\n",
      "Epoch 160/500\n",
      "62/62 [==============================] - 1s 12ms/step - loss: 0.5927 - accuracy: 0.6931 - val_loss: 0.6312 - val_accuracy: 0.6875\n",
      "Epoch 161/500\n",
      "62/62 [==============================] - 1s 10ms/step - loss: 0.5835 - accuracy: 0.6977 - val_loss: 0.6282 - val_accuracy: 0.6786\n",
      "Epoch 162/500\n",
      "62/62 [==============================] - 1s 11ms/step - loss: 0.5933 - accuracy: 0.6915 - val_loss: 0.6300 - val_accuracy: 0.6901\n",
      "Epoch 163/500\n",
      "62/62 [==============================] - 1s 10ms/step - loss: 0.5857 - accuracy: 0.6935 - val_loss: 0.6341 - val_accuracy: 0.6773\n",
      "Epoch 164/500\n",
      "62/62 [==============================] - 1s 13ms/step - loss: 0.5830 - accuracy: 0.7015 - val_loss: 0.6305 - val_accuracy: 0.6837\n",
      "Epoch 165/500\n",
      "62/62 [==============================] - 1s 10ms/step - loss: 0.5873 - accuracy: 0.7001 - val_loss: 0.6290 - val_accuracy: 0.6735\n",
      "Epoch 166/500\n",
      "62/62 [==============================] - 1s 11ms/step - loss: 0.5855 - accuracy: 0.6973 - val_loss: 0.6272 - val_accuracy: 0.6735\n",
      "Epoch 167/500\n",
      "62/62 [==============================] - 1s 10ms/step - loss: 0.5857 - accuracy: 0.6929 - val_loss: 0.6352 - val_accuracy: 0.6722\n",
      "Epoch 168/500\n",
      "62/62 [==============================] - 1s 10ms/step - loss: 0.5858 - accuracy: 0.6984 - val_loss: 0.6296 - val_accuracy: 0.6849\n",
      "Epoch 169/500\n",
      "62/62 [==============================] - 1s 11ms/step - loss: 0.5827 - accuracy: 0.7022 - val_loss: 0.6325 - val_accuracy: 0.6671\n",
      "Epoch 170/500\n",
      "62/62 [==============================] - 1s 10ms/step - loss: 0.5877 - accuracy: 0.7001 - val_loss: 0.6393 - val_accuracy: 0.6684\n",
      "Epoch 171/500\n",
      "62/62 [==============================] - 1s 11ms/step - loss: 0.5854 - accuracy: 0.6943 - val_loss: 0.6285 - val_accuracy: 0.6824\n",
      "Epoch 172/500\n",
      "62/62 [==============================] - 1s 10ms/step - loss: 0.5820 - accuracy: 0.7020 - val_loss: 0.6301 - val_accuracy: 0.6824\n",
      "Epoch 173/500\n",
      "62/62 [==============================] - 1s 11ms/step - loss: 0.5882 - accuracy: 0.6890 - val_loss: 0.6214 - val_accuracy: 0.6875\n",
      "Epoch 174/500\n",
      "62/62 [==============================] - 1s 10ms/step - loss: 0.5847 - accuracy: 0.7046 - val_loss: 0.6230 - val_accuracy: 0.6798\n",
      "Epoch 175/500\n",
      "62/62 [==============================] - 1s 10ms/step - loss: 0.5822 - accuracy: 0.7083 - val_loss: 0.6250 - val_accuracy: 0.6760\n",
      "Epoch 176/500\n",
      "62/62 [==============================] - 1s 10ms/step - loss: 0.5822 - accuracy: 0.6997 - val_loss: 0.6206 - val_accuracy: 0.6862\n",
      "Epoch 177/500\n",
      "62/62 [==============================] - 1s 10ms/step - loss: 0.5721 - accuracy: 0.7017 - val_loss: 0.6231 - val_accuracy: 0.6926\n",
      "Epoch 178/500\n",
      "62/62 [==============================] - 1s 11ms/step - loss: 0.5890 - accuracy: 0.7012 - val_loss: 0.6244 - val_accuracy: 0.6888\n",
      "Epoch 179/500\n",
      "62/62 [==============================] - 1s 10ms/step - loss: 0.5877 - accuracy: 0.6993 - val_loss: 0.6309 - val_accuracy: 0.6901\n",
      "Epoch 180/500\n",
      "62/62 [==============================] - 1s 10ms/step - loss: 0.5813 - accuracy: 0.7076 - val_loss: 0.6301 - val_accuracy: 0.6696\n",
      "Epoch 181/500\n",
      "62/62 [==============================] - 1s 10ms/step - loss: 0.5891 - accuracy: 0.6948 - val_loss: 0.6297 - val_accuracy: 0.6824\n",
      "Epoch 182/500\n",
      "62/62 [==============================] - 1s 10ms/step - loss: 0.5891 - accuracy: 0.6945 - val_loss: 0.6306 - val_accuracy: 0.6811\n",
      "Epoch 183/500\n",
      "62/62 [==============================] - 1s 10ms/step - loss: 0.5808 - accuracy: 0.7034 - val_loss: 0.6289 - val_accuracy: 0.6888\n",
      "Epoch 184/500\n",
      "62/62 [==============================] - 1s 11ms/step - loss: 0.5797 - accuracy: 0.7057 - val_loss: 0.6277 - val_accuracy: 0.6862\n",
      "Epoch 185/500\n",
      "62/62 [==============================] - 1s 11ms/step - loss: 0.5835 - accuracy: 0.6997 - val_loss: 0.6244 - val_accuracy: 0.6811\n",
      "Epoch 186/500\n",
      "62/62 [==============================] - 1s 11ms/step - loss: 0.5825 - accuracy: 0.7045 - val_loss: 0.6232 - val_accuracy: 0.6837\n",
      "Epoch 187/500\n",
      "62/62 [==============================] - 1s 10ms/step - loss: 0.5810 - accuracy: 0.7002 - val_loss: 0.6284 - val_accuracy: 0.6786\n",
      "Epoch 188/500\n",
      "62/62 [==============================] - 1s 10ms/step - loss: 0.5805 - accuracy: 0.7021 - val_loss: 0.6342 - val_accuracy: 0.6824\n",
      "Epoch 189/500\n",
      "62/62 [==============================] - 1s 10ms/step - loss: 0.5890 - accuracy: 0.6984 - val_loss: 0.6328 - val_accuracy: 0.6760\n",
      "Epoch 190/500\n",
      "62/62 [==============================] - 1s 10ms/step - loss: 0.5818 - accuracy: 0.7007 - val_loss: 0.6270 - val_accuracy: 0.6849\n",
      "Epoch 191/500\n",
      "62/62 [==============================] - 1s 11ms/step - loss: 0.5858 - accuracy: 0.6973 - val_loss: 0.6244 - val_accuracy: 0.6824\n",
      "Epoch 192/500\n",
      "62/62 [==============================] - 1s 11ms/step - loss: 0.5826 - accuracy: 0.7026 - val_loss: 0.6214 - val_accuracy: 0.6811\n",
      "Epoch 193/500\n",
      "62/62 [==============================] - 1s 12ms/step - loss: 0.5803 - accuracy: 0.7042 - val_loss: 0.6321 - val_accuracy: 0.6760\n",
      "Epoch 194/500\n",
      "62/62 [==============================] - 1s 14ms/step - loss: 0.5834 - accuracy: 0.6974 - val_loss: 0.6269 - val_accuracy: 0.6837\n",
      "Epoch 195/500\n",
      "62/62 [==============================] - 1s 12ms/step - loss: 0.5887 - accuracy: 0.6948 - val_loss: 0.6279 - val_accuracy: 0.6849\n",
      "Epoch 196/500\n",
      "62/62 [==============================] - 1s 12ms/step - loss: 0.5867 - accuracy: 0.6965 - val_loss: 0.6260 - val_accuracy: 0.6760\n",
      "Epoch 197/500\n",
      "62/62 [==============================] - 1s 12ms/step - loss: 0.5797 - accuracy: 0.7016 - val_loss: 0.6259 - val_accuracy: 0.6837\n",
      "Epoch 198/500\n",
      "62/62 [==============================] - 1s 12ms/step - loss: 0.5883 - accuracy: 0.6954 - val_loss: 0.6303 - val_accuracy: 0.6722\n",
      "Epoch 199/500\n",
      "62/62 [==============================] - 1s 11ms/step - loss: 0.5823 - accuracy: 0.7031 - val_loss: 0.6217 - val_accuracy: 0.6811\n",
      "Epoch 200/500\n",
      "62/62 [==============================] - 1s 13ms/step - loss: 0.5788 - accuracy: 0.7081 - val_loss: 0.6259 - val_accuracy: 0.6811\n",
      "Epoch 201/500\n",
      "62/62 [==============================] - 1s 11ms/step - loss: 0.5778 - accuracy: 0.6987 - val_loss: 0.6292 - val_accuracy: 0.6773\n",
      "Epoch 202/500\n",
      "62/62 [==============================] - 1s 10ms/step - loss: 0.5851 - accuracy: 0.7042 - val_loss: 0.6308 - val_accuracy: 0.6760\n",
      "Epoch 203/500\n",
      "62/62 [==============================] - 1s 10ms/step - loss: 0.5773 - accuracy: 0.7049 - val_loss: 0.6279 - val_accuracy: 0.6709\n",
      "Epoch 204/500\n",
      "62/62 [==============================] - 1s 10ms/step - loss: 0.5809 - accuracy: 0.7010 - val_loss: 0.6255 - val_accuracy: 0.6760\n",
      "Epoch 205/500\n",
      "62/62 [==============================] - 1s 10ms/step - loss: 0.5840 - accuracy: 0.6969 - val_loss: 0.6248 - val_accuracy: 0.6824\n",
      "Epoch 206/500\n",
      "62/62 [==============================] - 1s 11ms/step - loss: 0.5802 - accuracy: 0.6994 - val_loss: 0.6131 - val_accuracy: 0.6875\n",
      "Epoch 207/500\n",
      "62/62 [==============================] - 1s 11ms/step - loss: 0.5845 - accuracy: 0.7016 - val_loss: 0.6347 - val_accuracy: 0.6709\n",
      "Epoch 208/500\n",
      "62/62 [==============================] - 1s 11ms/step - loss: 0.5812 - accuracy: 0.7049 - val_loss: 0.6220 - val_accuracy: 0.6811\n",
      "Epoch 209/500\n",
      "62/62 [==============================] - 1s 10ms/step - loss: 0.5766 - accuracy: 0.7092 - val_loss: 0.6328 - val_accuracy: 0.6696\n",
      "Epoch 210/500\n",
      "62/62 [==============================] - 1s 10ms/step - loss: 0.5781 - accuracy: 0.7013 - val_loss: 0.6285 - val_accuracy: 0.6735\n",
      "Epoch 211/500\n",
      "62/62 [==============================] - 1s 11ms/step - loss: 0.5823 - accuracy: 0.7049 - val_loss: 0.6231 - val_accuracy: 0.6773\n",
      "Epoch 212/500\n",
      "62/62 [==============================] - 1s 10ms/step - loss: 0.5828 - accuracy: 0.7003 - val_loss: 0.6276 - val_accuracy: 0.6735\n",
      "Epoch 213/500\n",
      "62/62 [==============================] - 1s 10ms/step - loss: 0.5810 - accuracy: 0.7042 - val_loss: 0.6300 - val_accuracy: 0.6786\n",
      "Epoch 214/500\n",
      "62/62 [==============================] - 1s 11ms/step - loss: 0.5785 - accuracy: 0.7031 - val_loss: 0.6279 - val_accuracy: 0.6786\n",
      "Epoch 215/500\n",
      "62/62 [==============================] - 1s 10ms/step - loss: 0.5832 - accuracy: 0.7012 - val_loss: 0.6275 - val_accuracy: 0.6747\n",
      "Epoch 216/500\n",
      "62/62 [==============================] - 1s 10ms/step - loss: 0.5852 - accuracy: 0.7068 - val_loss: 0.6343 - val_accuracy: 0.6633\n",
      "Epoch 217/500\n",
      "62/62 [==============================] - 1s 10ms/step - loss: 0.5807 - accuracy: 0.7040 - val_loss: 0.6250 - val_accuracy: 0.6811\n",
      "Epoch 218/500\n",
      "62/62 [==============================] - 1s 12ms/step - loss: 0.5831 - accuracy: 0.7066 - val_loss: 0.6269 - val_accuracy: 0.6747\n",
      "Epoch 219/500\n",
      "62/62 [==============================] - 1s 11ms/step - loss: 0.5823 - accuracy: 0.7001 - val_loss: 0.6248 - val_accuracy: 0.6786\n",
      "Epoch 220/500\n",
      "62/62 [==============================] - 1s 10ms/step - loss: 0.5810 - accuracy: 0.7006 - val_loss: 0.6253 - val_accuracy: 0.6786\n",
      "Epoch 221/500\n",
      "62/62 [==============================] - 1s 10ms/step - loss: 0.5854 - accuracy: 0.6997 - val_loss: 0.6253 - val_accuracy: 0.6786\n",
      "Epoch 222/500\n",
      "62/62 [==============================] - 1s 10ms/step - loss: 0.5767 - accuracy: 0.7027 - val_loss: 0.6235 - val_accuracy: 0.6786\n",
      "Epoch 223/500\n",
      "62/62 [==============================] - 1s 11ms/step - loss: 0.5795 - accuracy: 0.7042 - val_loss: 0.6245 - val_accuracy: 0.6760\n",
      "Epoch 224/500\n",
      "62/62 [==============================] - 1s 10ms/step - loss: 0.5837 - accuracy: 0.7015 - val_loss: 0.6230 - val_accuracy: 0.6811\n",
      "Epoch 225/500\n",
      "62/62 [==============================] - 1s 11ms/step - loss: 0.5831 - accuracy: 0.7039 - val_loss: 0.6245 - val_accuracy: 0.6849\n",
      "Epoch 226/500\n",
      "62/62 [==============================] - 1s 11ms/step - loss: 0.5798 - accuracy: 0.6997 - val_loss: 0.6189 - val_accuracy: 0.6875\n",
      "Epoch 227/500\n",
      "62/62 [==============================] - 1s 11ms/step - loss: 0.5756 - accuracy: 0.7031 - val_loss: 0.6217 - val_accuracy: 0.6760\n",
      "Epoch 228/500\n",
      "62/62 [==============================] - 1s 11ms/step - loss: 0.5790 - accuracy: 0.6972 - val_loss: 0.6356 - val_accuracy: 0.6811\n",
      "Epoch 229/500\n",
      "62/62 [==============================] - 1s 11ms/step - loss: 0.5828 - accuracy: 0.7013 - val_loss: 0.6224 - val_accuracy: 0.6952\n",
      "Epoch 230/500\n",
      "62/62 [==============================] - 1s 11ms/step - loss: 0.5815 - accuracy: 0.6997 - val_loss: 0.6234 - val_accuracy: 0.6952\n",
      "Epoch 231/500\n",
      "62/62 [==============================] - 1s 10ms/step - loss: 0.5801 - accuracy: 0.7063 - val_loss: 0.6274 - val_accuracy: 0.6798\n",
      "Epoch 232/500\n",
      "62/62 [==============================] - 1s 10ms/step - loss: 0.5761 - accuracy: 0.7063 - val_loss: 0.6243 - val_accuracy: 0.6862\n",
      "Epoch 233/500\n",
      "62/62 [==============================] - 1s 11ms/step - loss: 0.5779 - accuracy: 0.7042 - val_loss: 0.6168 - val_accuracy: 0.6939\n",
      "Epoch 234/500\n",
      "62/62 [==============================] - 1s 11ms/step - loss: 0.5822 - accuracy: 0.7070 - val_loss: 0.6189 - val_accuracy: 0.6888\n",
      "Epoch 235/500\n",
      "62/62 [==============================] - 1s 11ms/step - loss: 0.5847 - accuracy: 0.6982 - val_loss: 0.6263 - val_accuracy: 0.6901\n",
      "Epoch 236/500\n",
      "62/62 [==============================] - 1s 11ms/step - loss: 0.5785 - accuracy: 0.7080 - val_loss: 0.6276 - val_accuracy: 0.6837\n",
      "Epoch 237/500\n",
      "62/62 [==============================] - 1s 11ms/step - loss: 0.5790 - accuracy: 0.6978 - val_loss: 0.6285 - val_accuracy: 0.6849\n",
      "Epoch 238/500\n",
      "62/62 [==============================] - 1s 10ms/step - loss: 0.5804 - accuracy: 0.7050 - val_loss: 0.6260 - val_accuracy: 0.6862\n",
      "Epoch 239/500\n",
      "62/62 [==============================] - 1s 11ms/step - loss: 0.5772 - accuracy: 0.7035 - val_loss: 0.6263 - val_accuracy: 0.6824\n",
      "Epoch 240/500\n",
      "62/62 [==============================] - 1s 12ms/step - loss: 0.5837 - accuracy: 0.7022 - val_loss: 0.6281 - val_accuracy: 0.6798\n",
      "Epoch 241/500\n",
      "62/62 [==============================] - 1s 10ms/step - loss: 0.5850 - accuracy: 0.6992 - val_loss: 0.6247 - val_accuracy: 0.6786\n",
      "Epoch 242/500\n",
      "62/62 [==============================] - 1s 10ms/step - loss: 0.5788 - accuracy: 0.7078 - val_loss: 0.6236 - val_accuracy: 0.6811\n",
      "Epoch 243/500\n",
      "62/62 [==============================] - 1s 10ms/step - loss: 0.5805 - accuracy: 0.7001 - val_loss: 0.6246 - val_accuracy: 0.6747\n",
      "Epoch 244/500\n",
      "62/62 [==============================] - 1s 10ms/step - loss: 0.5787 - accuracy: 0.6979 - val_loss: 0.6245 - val_accuracy: 0.6849\n",
      "Epoch 245/500\n",
      "62/62 [==============================] - 1s 10ms/step - loss: 0.5810 - accuracy: 0.7036 - val_loss: 0.6278 - val_accuracy: 0.6824\n",
      "Epoch 246/500\n",
      "62/62 [==============================] - 1s 10ms/step - loss: 0.5739 - accuracy: 0.7071 - val_loss: 0.6233 - val_accuracy: 0.6888\n",
      "Epoch 247/500\n",
      "62/62 [==============================] - 1s 11ms/step - loss: 0.5714 - accuracy: 0.7071 - val_loss: 0.6155 - val_accuracy: 0.6939\n",
      "Epoch 248/500\n",
      "62/62 [==============================] - 1s 10ms/step - loss: 0.5867 - accuracy: 0.6997 - val_loss: 0.6254 - val_accuracy: 0.6709\n",
      "Epoch 249/500\n",
      "62/62 [==============================] - 1s 11ms/step - loss: 0.5820 - accuracy: 0.6991 - val_loss: 0.6314 - val_accuracy: 0.6824\n",
      "Epoch 250/500\n",
      "62/62 [==============================] - 1s 11ms/step - loss: 0.5817 - accuracy: 0.6999 - val_loss: 0.6296 - val_accuracy: 0.6952\n",
      "Epoch 251/500\n",
      "62/62 [==============================] - 1s 10ms/step - loss: 0.5852 - accuracy: 0.7008 - val_loss: 0.6283 - val_accuracy: 0.6811\n",
      "Epoch 252/500\n",
      "62/62 [==============================] - 1s 10ms/step - loss: 0.5831 - accuracy: 0.7022 - val_loss: 0.6281 - val_accuracy: 0.6722\n",
      "Epoch 253/500\n",
      "62/62 [==============================] - 1s 10ms/step - loss: 0.5791 - accuracy: 0.7031 - val_loss: 0.6222 - val_accuracy: 0.6735\n",
      "Epoch 254/500\n",
      "62/62 [==============================] - 1s 11ms/step - loss: 0.5821 - accuracy: 0.7020 - val_loss: 0.6354 - val_accuracy: 0.6620\n",
      "Epoch 255/500\n",
      "62/62 [==============================] - 1s 10ms/step - loss: 0.5769 - accuracy: 0.7105 - val_loss: 0.6290 - val_accuracy: 0.6760\n",
      "Epoch 256/500\n",
      "62/62 [==============================] - 1s 10ms/step - loss: 0.5785 - accuracy: 0.7060 - val_loss: 0.6162 - val_accuracy: 0.6837\n",
      "Epoch 257/500\n",
      "62/62 [==============================] - 1s 10ms/step - loss: 0.5810 - accuracy: 0.6994 - val_loss: 0.6229 - val_accuracy: 0.6798\n",
      "Epoch 258/500\n",
      "62/62 [==============================] - 1s 11ms/step - loss: 0.5790 - accuracy: 0.7003 - val_loss: 0.6267 - val_accuracy: 0.6773\n",
      "Epoch 259/500\n",
      "62/62 [==============================] - 1s 10ms/step - loss: 0.5761 - accuracy: 0.7022 - val_loss: 0.6226 - val_accuracy: 0.6837\n",
      "Epoch 260/500\n",
      "62/62 [==============================] - 1s 10ms/step - loss: 0.5834 - accuracy: 0.6920 - val_loss: 0.6277 - val_accuracy: 0.6798\n",
      "Epoch 261/500\n",
      "62/62 [==============================] - 1s 10ms/step - loss: 0.5844 - accuracy: 0.7005 - val_loss: 0.6239 - val_accuracy: 0.6901\n",
      "Epoch 262/500\n",
      "62/62 [==============================] - 1s 10ms/step - loss: 0.5755 - accuracy: 0.7021 - val_loss: 0.6202 - val_accuracy: 0.6862\n",
      "Epoch 263/500\n",
      "62/62 [==============================] - 1s 10ms/step - loss: 0.5764 - accuracy: 0.7035 - val_loss: 0.6227 - val_accuracy: 0.6875\n",
      "Epoch 264/500\n",
      "62/62 [==============================] - 1s 11ms/step - loss: 0.5820 - accuracy: 0.6998 - val_loss: 0.6294 - val_accuracy: 0.6811\n",
      "Epoch 265/500\n",
      "62/62 [==============================] - 1s 11ms/step - loss: 0.5816 - accuracy: 0.7035 - val_loss: 0.6287 - val_accuracy: 0.6862\n",
      "Epoch 266/500\n",
      "62/62 [==============================] - 1s 10ms/step - loss: 0.5806 - accuracy: 0.7039 - val_loss: 0.6287 - val_accuracy: 0.6837\n",
      "Epoch 267/500\n",
      "62/62 [==============================] - 1s 11ms/step - loss: 0.5771 - accuracy: 0.7047 - val_loss: 0.6283 - val_accuracy: 0.6901\n",
      "Epoch 268/500\n",
      "62/62 [==============================] - 1s 10ms/step - loss: 0.5809 - accuracy: 0.7013 - val_loss: 0.6316 - val_accuracy: 0.6773\n",
      "Epoch 269/500\n",
      "62/62 [==============================] - 1s 10ms/step - loss: 0.5809 - accuracy: 0.7017 - val_loss: 0.6304 - val_accuracy: 0.6747\n",
      "Epoch 270/500\n",
      "62/62 [==============================] - 1s 10ms/step - loss: 0.5858 - accuracy: 0.6953 - val_loss: 0.6264 - val_accuracy: 0.6849\n",
      "Epoch 271/500\n",
      "62/62 [==============================] - 1s 11ms/step - loss: 0.5825 - accuracy: 0.7011 - val_loss: 0.6284 - val_accuracy: 0.6824\n",
      "Epoch 272/500\n",
      "62/62 [==============================] - 1s 11ms/step - loss: 0.5718 - accuracy: 0.7142 - val_loss: 0.6329 - val_accuracy: 0.6747\n",
      "Epoch 273/500\n",
      "62/62 [==============================] - 1s 10ms/step - loss: 0.5802 - accuracy: 0.7040 - val_loss: 0.6268 - val_accuracy: 0.6837\n",
      "Epoch 274/500\n",
      "62/62 [==============================] - 1s 10ms/step - loss: 0.5742 - accuracy: 0.7105 - val_loss: 0.6300 - val_accuracy: 0.6773\n",
      "Epoch 275/500\n",
      "62/62 [==============================] - 1s 10ms/step - loss: 0.5781 - accuracy: 0.7083 - val_loss: 0.6344 - val_accuracy: 0.6709\n",
      "Epoch 276/500\n",
      "62/62 [==============================] - 1s 10ms/step - loss: 0.5812 - accuracy: 0.7034 - val_loss: 0.6289 - val_accuracy: 0.6875\n",
      "Epoch 277/500\n",
      "62/62 [==============================] - 1s 10ms/step - loss: 0.5696 - accuracy: 0.7124 - val_loss: 0.6261 - val_accuracy: 0.6747\n",
      "Epoch 278/500\n",
      "62/62 [==============================] - 1s 10ms/step - loss: 0.5814 - accuracy: 0.7069 - val_loss: 0.6316 - val_accuracy: 0.6747\n",
      "Epoch 279/500\n",
      "62/62 [==============================] - 1s 10ms/step - loss: 0.5814 - accuracy: 0.7041 - val_loss: 0.6270 - val_accuracy: 0.6888\n",
      "Epoch 280/500\n",
      "62/62 [==============================] - 1s 10ms/step - loss: 0.5738 - accuracy: 0.7076 - val_loss: 0.6310 - val_accuracy: 0.6786\n",
      "Epoch 281/500\n",
      "62/62 [==============================] - 1s 10ms/step - loss: 0.5804 - accuracy: 0.7039 - val_loss: 0.6315 - val_accuracy: 0.6824\n",
      "Epoch 282/500\n",
      "62/62 [==============================] - 1s 10ms/step - loss: 0.5734 - accuracy: 0.7068 - val_loss: 0.6221 - val_accuracy: 0.6888\n",
      "Epoch 283/500\n",
      "62/62 [==============================] - 1s 11ms/step - loss: 0.5770 - accuracy: 0.7094 - val_loss: 0.6264 - val_accuracy: 0.6747\n",
      "Epoch 284/500\n",
      "62/62 [==============================] - 1s 11ms/step - loss: 0.5764 - accuracy: 0.7060 - val_loss: 0.6281 - val_accuracy: 0.6735\n",
      "Epoch 285/500\n",
      "62/62 [==============================] - 1s 10ms/step - loss: 0.5863 - accuracy: 0.6939 - val_loss: 0.6338 - val_accuracy: 0.7003\n",
      "Epoch 286/500\n",
      "62/62 [==============================] - 1s 10ms/step - loss: 0.5755 - accuracy: 0.7055 - val_loss: 0.6337 - val_accuracy: 0.6888\n",
      "Epoch 287/500\n",
      "62/62 [==============================] - 1s 11ms/step - loss: 0.5797 - accuracy: 0.7074 - val_loss: 0.6370 - val_accuracy: 0.6658\n",
      "Epoch 288/500\n",
      "62/62 [==============================] - 1s 11ms/step - loss: 0.5762 - accuracy: 0.7060 - val_loss: 0.6266 - val_accuracy: 0.6798\n",
      "Epoch 289/500\n",
      "62/62 [==============================] - 1s 10ms/step - loss: 0.5824 - accuracy: 0.7034 - val_loss: 0.6307 - val_accuracy: 0.6735\n",
      "Epoch 290/500\n",
      "62/62 [==============================] - 1s 11ms/step - loss: 0.5799 - accuracy: 0.7039 - val_loss: 0.6262 - val_accuracy: 0.6811\n",
      "Epoch 291/500\n",
      "62/62 [==============================] - 1s 10ms/step - loss: 0.5781 - accuracy: 0.7046 - val_loss: 0.6219 - val_accuracy: 0.6888\n",
      "Epoch 292/500\n",
      "62/62 [==============================] - 1s 10ms/step - loss: 0.5749 - accuracy: 0.7094 - val_loss: 0.6288 - val_accuracy: 0.6849\n",
      "Epoch 293/500\n",
      "62/62 [==============================] - 1s 10ms/step - loss: 0.5723 - accuracy: 0.7119 - val_loss: 0.6351 - val_accuracy: 0.6735\n",
      "Epoch 294/500\n",
      "62/62 [==============================] - 1s 10ms/step - loss: 0.5853 - accuracy: 0.6973 - val_loss: 0.6269 - val_accuracy: 0.6747\n",
      "Epoch 295/500\n",
      "62/62 [==============================] - 1s 11ms/step - loss: 0.5713 - accuracy: 0.7073 - val_loss: 0.6276 - val_accuracy: 0.6849\n",
      "Epoch 296/500\n",
      "62/62 [==============================] - 1s 10ms/step - loss: 0.5783 - accuracy: 0.7071 - val_loss: 0.6298 - val_accuracy: 0.6824\n",
      "Epoch 297/500\n",
      "62/62 [==============================] - 1s 11ms/step - loss: 0.5799 - accuracy: 0.7032 - val_loss: 0.6270 - val_accuracy: 0.6837\n",
      "Epoch 298/500\n",
      "62/62 [==============================] - 1s 10ms/step - loss: 0.5786 - accuracy: 0.7057 - val_loss: 0.6289 - val_accuracy: 0.6760\n",
      "Epoch 299/500\n",
      "62/62 [==============================] - 1s 10ms/step - loss: 0.5831 - accuracy: 0.7006 - val_loss: 0.6280 - val_accuracy: 0.6862\n",
      "Epoch 300/500\n",
      "62/62 [==============================] - 1s 11ms/step - loss: 0.5755 - accuracy: 0.7094 - val_loss: 0.6272 - val_accuracy: 0.6849\n",
      "Epoch 301/500\n",
      "62/62 [==============================] - 1s 10ms/step - loss: 0.5754 - accuracy: 0.7115 - val_loss: 0.6288 - val_accuracy: 0.6811\n",
      "Epoch 302/500\n",
      "62/62 [==============================] - 1s 10ms/step - loss: 0.5752 - accuracy: 0.7044 - val_loss: 0.6332 - val_accuracy: 0.6735\n",
      "Epoch 303/500\n",
      "62/62 [==============================] - 1s 11ms/step - loss: 0.5801 - accuracy: 0.7007 - val_loss: 0.6295 - val_accuracy: 0.6824\n",
      "Epoch 304/500\n",
      "62/62 [==============================] - 1s 10ms/step - loss: 0.5764 - accuracy: 0.7069 - val_loss: 0.6275 - val_accuracy: 0.6875\n",
      "Epoch 305/500\n",
      "62/62 [==============================] - 1s 10ms/step - loss: 0.5738 - accuracy: 0.7093 - val_loss: 0.6246 - val_accuracy: 0.6888\n",
      "Epoch 306/500\n",
      "62/62 [==============================] - 1s 10ms/step - loss: 0.5761 - accuracy: 0.7059 - val_loss: 0.6305 - val_accuracy: 0.6735\n",
      "Epoch 307/500\n",
      "62/62 [==============================] - 1s 11ms/step - loss: 0.5719 - accuracy: 0.7017 - val_loss: 0.6276 - val_accuracy: 0.6798\n",
      "Epoch 308/500\n",
      "62/62 [==============================] - 1s 11ms/step - loss: 0.5730 - accuracy: 0.7039 - val_loss: 0.6267 - val_accuracy: 0.6824\n",
      "Epoch 309/500\n",
      "62/62 [==============================] - 1s 10ms/step - loss: 0.5801 - accuracy: 0.7059 - val_loss: 0.6319 - val_accuracy: 0.6773\n",
      "Epoch 310/500\n",
      "62/62 [==============================] - 1s 10ms/step - loss: 0.5761 - accuracy: 0.7075 - val_loss: 0.6266 - val_accuracy: 0.6913\n",
      "Epoch 311/500\n",
      "62/62 [==============================] - 1s 11ms/step - loss: 0.5808 - accuracy: 0.7081 - val_loss: 0.6341 - val_accuracy: 0.6811\n",
      "Epoch 312/500\n",
      "62/62 [==============================] - 1s 11ms/step - loss: 0.5772 - accuracy: 0.7127 - val_loss: 0.6341 - val_accuracy: 0.6773\n",
      "Epoch 313/500\n",
      "62/62 [==============================] - 1s 10ms/step - loss: 0.5763 - accuracy: 0.7012 - val_loss: 0.6252 - val_accuracy: 0.6824\n",
      "Epoch 314/500\n",
      "62/62 [==============================] - 1s 10ms/step - loss: 0.5803 - accuracy: 0.7054 - val_loss: 0.6272 - val_accuracy: 0.6798\n",
      "Epoch 315/500\n",
      "62/62 [==============================] - 1s 11ms/step - loss: 0.5731 - accuracy: 0.7117 - val_loss: 0.6283 - val_accuracy: 0.6798\n",
      "Epoch 316/500\n",
      "62/62 [==============================] - 1s 10ms/step - loss: 0.5716 - accuracy: 0.7073 - val_loss: 0.6281 - val_accuracy: 0.6824\n",
      "Epoch 317/500\n",
      "62/62 [==============================] - 1s 10ms/step - loss: 0.5689 - accuracy: 0.7138 - val_loss: 0.6400 - val_accuracy: 0.6709\n",
      "Epoch 318/500\n",
      "62/62 [==============================] - 1s 10ms/step - loss: 0.5731 - accuracy: 0.7104 - val_loss: 0.6325 - val_accuracy: 0.6722\n",
      "Epoch 319/500\n",
      "62/62 [==============================] - 1s 11ms/step - loss: 0.5734 - accuracy: 0.7054 - val_loss: 0.6235 - val_accuracy: 0.6824\n",
      "Epoch 320/500\n",
      "62/62 [==============================] - 1s 10ms/step - loss: 0.5768 - accuracy: 0.7098 - val_loss: 0.6274 - val_accuracy: 0.6862\n",
      "Epoch 321/500\n",
      "62/62 [==============================] - 1s 10ms/step - loss: 0.5839 - accuracy: 0.7022 - val_loss: 0.6369 - val_accuracy: 0.6773\n",
      "Epoch 322/500\n",
      "62/62 [==============================] - 1s 10ms/step - loss: 0.5759 - accuracy: 0.7095 - val_loss: 0.6277 - val_accuracy: 0.6747\n",
      "Epoch 323/500\n",
      "62/62 [==============================] - 1s 11ms/step - loss: 0.5767 - accuracy: 0.7051 - val_loss: 0.6238 - val_accuracy: 0.6926\n",
      "Epoch 324/500\n",
      "62/62 [==============================] - 1s 11ms/step - loss: 0.5739 - accuracy: 0.7126 - val_loss: 0.6287 - val_accuracy: 0.6798\n",
      "Epoch 325/500\n",
      "62/62 [==============================] - 1s 10ms/step - loss: 0.5777 - accuracy: 0.7022 - val_loss: 0.6345 - val_accuracy: 0.6798\n",
      "Epoch 326/500\n",
      "62/62 [==============================] - 1s 11ms/step - loss: 0.5763 - accuracy: 0.7064 - val_loss: 0.6334 - val_accuracy: 0.6747\n",
      "Epoch 327/500\n",
      "62/62 [==============================] - 1s 10ms/step - loss: 0.5698 - accuracy: 0.7104 - val_loss: 0.6215 - val_accuracy: 0.6849\n",
      "Epoch 328/500\n",
      "62/62 [==============================] - 1s 10ms/step - loss: 0.5769 - accuracy: 0.7036 - val_loss: 0.6287 - val_accuracy: 0.6811\n",
      "Epoch 329/500\n",
      "62/62 [==============================] - 1s 10ms/step - loss: 0.5765 - accuracy: 0.7083 - val_loss: 0.6309 - val_accuracy: 0.6786\n",
      "Epoch 330/500\n",
      "62/62 [==============================] - 1s 11ms/step - loss: 0.5772 - accuracy: 0.7097 - val_loss: 0.6336 - val_accuracy: 0.6760\n",
      "Epoch 331/500\n",
      "62/62 [==============================] - 1s 11ms/step - loss: 0.5711 - accuracy: 0.7168 - val_loss: 0.6328 - val_accuracy: 0.6786\n",
      "Epoch 332/500\n",
      "62/62 [==============================] - 1s 11ms/step - loss: 0.5753 - accuracy: 0.7098 - val_loss: 0.6299 - val_accuracy: 0.6773\n",
      "Epoch 333/500\n",
      "62/62 [==============================] - 1s 10ms/step - loss: 0.5751 - accuracy: 0.7104 - val_loss: 0.6285 - val_accuracy: 0.6849\n",
      "Epoch 334/500\n",
      "62/62 [==============================] - 1s 11ms/step - loss: 0.5771 - accuracy: 0.7078 - val_loss: 0.6288 - val_accuracy: 0.6811\n",
      "Epoch 335/500\n",
      "62/62 [==============================] - 1s 10ms/step - loss: 0.5687 - accuracy: 0.7105 - val_loss: 0.6357 - val_accuracy: 0.6837\n",
      "Epoch 336/500\n",
      "62/62 [==============================] - 1s 11ms/step - loss: 0.5704 - accuracy: 0.7081 - val_loss: 0.6314 - val_accuracy: 0.6837\n",
      "Epoch 337/500\n",
      "62/62 [==============================] - 1s 11ms/step - loss: 0.5676 - accuracy: 0.7097 - val_loss: 0.6301 - val_accuracy: 0.6824\n",
      "Epoch 338/500\n",
      "62/62 [==============================] - 1s 10ms/step - loss: 0.5750 - accuracy: 0.7068 - val_loss: 0.6277 - val_accuracy: 0.6786\n",
      "Epoch 339/500\n",
      "62/62 [==============================] - 1s 10ms/step - loss: 0.5763 - accuracy: 0.7054 - val_loss: 0.6318 - val_accuracy: 0.6786\n",
      "Epoch 340/500\n",
      "62/62 [==============================] - 1s 11ms/step - loss: 0.5756 - accuracy: 0.7054 - val_loss: 0.6291 - val_accuracy: 0.6901\n",
      "Epoch 341/500\n",
      "62/62 [==============================] - 1s 10ms/step - loss: 0.5707 - accuracy: 0.7064 - val_loss: 0.6295 - val_accuracy: 0.6824\n",
      "Epoch 342/500\n",
      "62/62 [==============================] - 1s 11ms/step - loss: 0.5755 - accuracy: 0.7150 - val_loss: 0.6386 - val_accuracy: 0.6658\n",
      "Epoch 343/500\n",
      "62/62 [==============================] - 1s 10ms/step - loss: 0.5682 - accuracy: 0.7136 - val_loss: 0.6280 - val_accuracy: 0.6798\n",
      "Epoch 344/500\n",
      "62/62 [==============================] - 1s 10ms/step - loss: 0.5773 - accuracy: 0.7005 - val_loss: 0.6277 - val_accuracy: 0.6849\n",
      "Epoch 345/500\n",
      "62/62 [==============================] - 1s 11ms/step - loss: 0.5757 - accuracy: 0.7057 - val_loss: 0.6236 - val_accuracy: 0.6952\n",
      "Epoch 346/500\n",
      "62/62 [==============================] - 1s 10ms/step - loss: 0.5793 - accuracy: 0.7036 - val_loss: 0.6304 - val_accuracy: 0.6837\n",
      "Epoch 347/500\n",
      "62/62 [==============================] - 1s 10ms/step - loss: 0.5761 - accuracy: 0.7073 - val_loss: 0.6283 - val_accuracy: 0.6849\n",
      "Epoch 348/500\n",
      "62/62 [==============================] - 1s 10ms/step - loss: 0.5744 - accuracy: 0.7117 - val_loss: 0.6232 - val_accuracy: 0.6913\n",
      "Epoch 349/500\n",
      "62/62 [==============================] - 1s 10ms/step - loss: 0.5794 - accuracy: 0.7059 - val_loss: 0.6286 - val_accuracy: 0.6875\n",
      "Epoch 350/500\n",
      "62/62 [==============================] - 1s 10ms/step - loss: 0.5754 - accuracy: 0.7083 - val_loss: 0.6251 - val_accuracy: 0.6926\n",
      "Epoch 351/500\n",
      "62/62 [==============================] - 1s 11ms/step - loss: 0.5760 - accuracy: 0.7121 - val_loss: 0.6303 - val_accuracy: 0.6837\n",
      "Epoch 352/500\n",
      "62/62 [==============================] - 1s 12ms/step - loss: 0.5734 - accuracy: 0.7083 - val_loss: 0.6252 - val_accuracy: 0.6862\n",
      "Epoch 353/500\n",
      "62/62 [==============================] - 1s 11ms/step - loss: 0.5826 - accuracy: 0.7011 - val_loss: 0.6303 - val_accuracy: 0.6824\n",
      "Epoch 354/500\n",
      "62/62 [==============================] - 1s 11ms/step - loss: 0.5747 - accuracy: 0.7076 - val_loss: 0.6355 - val_accuracy: 0.6811\n",
      "Epoch 355/500\n",
      "62/62 [==============================] - 1s 10ms/step - loss: 0.5749 - accuracy: 0.7093 - val_loss: 0.6339 - val_accuracy: 0.6773\n",
      "Epoch 356/500\n",
      "62/62 [==============================] - 1s 10ms/step - loss: 0.5699 - accuracy: 0.7099 - val_loss: 0.6254 - val_accuracy: 0.6926\n",
      "Epoch 357/500\n",
      "62/62 [==============================] - 1s 10ms/step - loss: 0.5789 - accuracy: 0.7046 - val_loss: 0.6296 - val_accuracy: 0.6952\n",
      "Epoch 358/500\n",
      "62/62 [==============================] - 1s 12ms/step - loss: 0.5728 - accuracy: 0.7075 - val_loss: 0.6314 - val_accuracy: 0.6798\n",
      "Epoch 359/500\n",
      "62/62 [==============================] - 1s 11ms/step - loss: 0.5763 - accuracy: 0.7073 - val_loss: 0.6306 - val_accuracy: 0.6824\n",
      "Epoch 360/500\n",
      "62/62 [==============================] - 1s 10ms/step - loss: 0.5749 - accuracy: 0.7027 - val_loss: 0.6282 - val_accuracy: 0.6888\n",
      "Epoch 361/500\n",
      "62/62 [==============================] - 1s 10ms/step - loss: 0.5790 - accuracy: 0.7028 - val_loss: 0.6325 - val_accuracy: 0.6747\n",
      "Epoch 362/500\n",
      "62/62 [==============================] - 1s 10ms/step - loss: 0.5674 - accuracy: 0.7093 - val_loss: 0.6281 - val_accuracy: 0.6849\n",
      "Epoch 363/500\n",
      "62/62 [==============================] - 1s 11ms/step - loss: 0.5743 - accuracy: 0.7100 - val_loss: 0.6296 - val_accuracy: 0.6824\n",
      "Epoch 364/500\n",
      "62/62 [==============================] - 1s 10ms/step - loss: 0.5728 - accuracy: 0.7090 - val_loss: 0.6264 - val_accuracy: 0.6837\n",
      "Epoch 365/500\n",
      "62/62 [==============================] - 1s 10ms/step - loss: 0.5782 - accuracy: 0.7065 - val_loss: 0.6378 - val_accuracy: 0.6824\n",
      "Epoch 366/500\n",
      "62/62 [==============================] - 1s 11ms/step - loss: 0.5738 - accuracy: 0.7076 - val_loss: 0.6331 - val_accuracy: 0.6696\n",
      "Epoch 367/500\n",
      "62/62 [==============================] - 1s 10ms/step - loss: 0.5720 - accuracy: 0.7133 - val_loss: 0.6301 - val_accuracy: 0.6798\n",
      "Epoch 368/500\n",
      "62/62 [==============================] - 1s 10ms/step - loss: 0.5736 - accuracy: 0.7046 - val_loss: 0.6273 - val_accuracy: 0.6773\n",
      "Epoch 369/500\n",
      "62/62 [==============================] - 1s 11ms/step - loss: 0.5709 - accuracy: 0.7139 - val_loss: 0.6366 - val_accuracy: 0.6645\n",
      "Epoch 370/500\n",
      "62/62 [==============================] - 1s 10ms/step - loss: 0.5735 - accuracy: 0.7065 - val_loss: 0.6340 - val_accuracy: 0.6722\n",
      "Epoch 371/500\n",
      "62/62 [==============================] - 1s 10ms/step - loss: 0.5724 - accuracy: 0.7107 - val_loss: 0.6249 - val_accuracy: 0.6875\n",
      "Epoch 372/500\n",
      "62/62 [==============================] - 1s 11ms/step - loss: 0.5722 - accuracy: 0.7105 - val_loss: 0.6284 - val_accuracy: 0.6773\n",
      "Epoch 373/500\n",
      "62/62 [==============================] - 1s 10ms/step - loss: 0.5754 - accuracy: 0.7110 - val_loss: 0.6325 - val_accuracy: 0.6760\n",
      "Epoch 374/500\n",
      "62/62 [==============================] - 1s 11ms/step - loss: 0.5753 - accuracy: 0.7063 - val_loss: 0.6262 - val_accuracy: 0.6837\n",
      "Epoch 375/500\n",
      "62/62 [==============================] - 1s 10ms/step - loss: 0.5769 - accuracy: 0.7051 - val_loss: 0.6286 - val_accuracy: 0.6811\n",
      "Epoch 376/500\n",
      "62/62 [==============================] - 1s 11ms/step - loss: 0.5814 - accuracy: 0.7083 - val_loss: 0.6308 - val_accuracy: 0.6837\n",
      "Epoch 377/500\n",
      "62/62 [==============================] - 1s 10ms/step - loss: 0.5761 - accuracy: 0.7042 - val_loss: 0.6315 - val_accuracy: 0.6798\n",
      "Epoch 378/500\n",
      "62/62 [==============================] - 1s 11ms/step - loss: 0.5726 - accuracy: 0.7098 - val_loss: 0.6339 - val_accuracy: 0.6747\n",
      "Epoch 379/500\n",
      "62/62 [==============================] - 1s 11ms/step - loss: 0.5717 - accuracy: 0.7089 - val_loss: 0.6259 - val_accuracy: 0.6760\n",
      "Epoch 380/500\n",
      "62/62 [==============================] - 1s 10ms/step - loss: 0.5731 - accuracy: 0.7136 - val_loss: 0.6262 - val_accuracy: 0.6747\n",
      "Epoch 381/500\n",
      "62/62 [==============================] - 1s 11ms/step - loss: 0.5718 - accuracy: 0.7110 - val_loss: 0.6267 - val_accuracy: 0.6786\n",
      "Epoch 382/500\n",
      "62/62 [==============================] - 1s 10ms/step - loss: 0.5716 - accuracy: 0.7080 - val_loss: 0.6251 - val_accuracy: 0.6773\n",
      "Epoch 383/500\n",
      "62/62 [==============================] - 1s 11ms/step - loss: 0.5678 - accuracy: 0.7108 - val_loss: 0.6336 - val_accuracy: 0.6773\n",
      "Epoch 384/500\n",
      "62/62 [==============================] - 1s 11ms/step - loss: 0.5750 - accuracy: 0.7119 - val_loss: 0.6315 - val_accuracy: 0.6786\n",
      "Epoch 385/500\n",
      "62/62 [==============================] - 1s 10ms/step - loss: 0.5693 - accuracy: 0.7121 - val_loss: 0.6301 - val_accuracy: 0.6824\n",
      "Epoch 386/500\n",
      "62/62 [==============================] - 1s 10ms/step - loss: 0.5780 - accuracy: 0.6994 - val_loss: 0.6349 - val_accuracy: 0.6760\n",
      "Epoch 387/500\n",
      "62/62 [==============================] - 1s 10ms/step - loss: 0.5781 - accuracy: 0.7002 - val_loss: 0.6395 - val_accuracy: 0.6773\n",
      "Epoch 388/500\n",
      "62/62 [==============================] - 1s 10ms/step - loss: 0.5778 - accuracy: 0.7035 - val_loss: 0.6265 - val_accuracy: 0.6773\n",
      "Epoch 389/500\n",
      "62/62 [==============================] - 1s 10ms/step - loss: 0.5779 - accuracy: 0.7061 - val_loss: 0.6294 - val_accuracy: 0.6824\n",
      "Epoch 390/500\n",
      "62/62 [==============================] - 1s 11ms/step - loss: 0.5673 - accuracy: 0.7075 - val_loss: 0.6360 - val_accuracy: 0.6735\n",
      "Epoch 391/500\n",
      "62/62 [==============================] - 1s 11ms/step - loss: 0.5784 - accuracy: 0.7042 - val_loss: 0.6292 - val_accuracy: 0.6747\n",
      "Epoch 392/500\n",
      "62/62 [==============================] - 1s 10ms/step - loss: 0.5661 - accuracy: 0.7097 - val_loss: 0.6273 - val_accuracy: 0.6952\n",
      "Epoch 393/500\n",
      "62/62 [==============================] - 1s 10ms/step - loss: 0.5636 - accuracy: 0.7122 - val_loss: 0.6328 - val_accuracy: 0.6837\n",
      "Epoch 394/500\n",
      "62/62 [==============================] - 1s 10ms/step - loss: 0.5741 - accuracy: 0.7052 - val_loss: 0.6326 - val_accuracy: 0.6875\n",
      "Epoch 395/500\n",
      "62/62 [==============================] - 1s 10ms/step - loss: 0.5706 - accuracy: 0.7084 - val_loss: 0.6316 - val_accuracy: 0.6964\n",
      "Epoch 396/500\n",
      "62/62 [==============================] - 1s 10ms/step - loss: 0.5789 - accuracy: 0.7056 - val_loss: 0.6355 - val_accuracy: 0.6709\n",
      "Epoch 397/500\n",
      "62/62 [==============================] - 1s 10ms/step - loss: 0.5736 - accuracy: 0.7124 - val_loss: 0.6315 - val_accuracy: 0.6837\n",
      "Epoch 398/500\n",
      "62/62 [==============================] - 1s 11ms/step - loss: 0.5796 - accuracy: 0.7023 - val_loss: 0.6341 - val_accuracy: 0.6875\n",
      "Epoch 399/500\n",
      "62/62 [==============================] - 1s 10ms/step - loss: 0.5748 - accuracy: 0.7107 - val_loss: 0.6259 - val_accuracy: 0.6811\n",
      "Epoch 400/500\n",
      "62/62 [==============================] - 1s 10ms/step - loss: 0.5754 - accuracy: 0.7071 - val_loss: 0.6271 - val_accuracy: 0.6722\n",
      "Epoch 401/500\n",
      "62/62 [==============================] - 1s 11ms/step - loss: 0.5728 - accuracy: 0.7047 - val_loss: 0.6364 - val_accuracy: 0.6684\n",
      "Epoch 402/500\n",
      "62/62 [==============================] - 1s 11ms/step - loss: 0.5735 - accuracy: 0.7035 - val_loss: 0.6295 - val_accuracy: 0.6722\n",
      "Epoch 403/500\n",
      "62/62 [==============================] - 1s 11ms/step - loss: 0.5718 - accuracy: 0.7083 - val_loss: 0.6298 - val_accuracy: 0.6773\n",
      "Epoch 404/500\n",
      "62/62 [==============================] - 1s 11ms/step - loss: 0.5817 - accuracy: 0.7054 - val_loss: 0.6307 - val_accuracy: 0.6824\n",
      "Epoch 405/500\n",
      "62/62 [==============================] - 1s 11ms/step - loss: 0.5677 - accuracy: 0.7098 - val_loss: 0.6314 - val_accuracy: 0.6786\n",
      "Epoch 406/500\n",
      "62/62 [==============================] - 1s 10ms/step - loss: 0.5732 - accuracy: 0.7080 - val_loss: 0.6251 - val_accuracy: 0.6798\n",
      "Epoch 407/500\n",
      "62/62 [==============================] - 1s 10ms/step - loss: 0.5690 - accuracy: 0.7166 - val_loss: 0.6326 - val_accuracy: 0.6773\n",
      "Epoch 408/500\n",
      "62/62 [==============================] - 1s 11ms/step - loss: 0.5777 - accuracy: 0.6991 - val_loss: 0.6354 - val_accuracy: 0.6735\n",
      "Epoch 409/500\n",
      "62/62 [==============================] - 1s 10ms/step - loss: 0.5810 - accuracy: 0.7030 - val_loss: 0.6290 - val_accuracy: 0.6888\n",
      "Epoch 410/500\n",
      "62/62 [==============================] - 1s 10ms/step - loss: 0.5731 - accuracy: 0.7068 - val_loss: 0.6266 - val_accuracy: 0.6862\n",
      "Epoch 411/500\n",
      "62/62 [==============================] - 1s 11ms/step - loss: 0.5698 - accuracy: 0.7148 - val_loss: 0.6246 - val_accuracy: 0.6786\n",
      "Epoch 412/500\n",
      "62/62 [==============================] - 1s 10ms/step - loss: 0.5782 - accuracy: 0.7039 - val_loss: 0.6288 - val_accuracy: 0.6760\n",
      "Epoch 413/500\n",
      "62/62 [==============================] - 1s 10ms/step - loss: 0.5801 - accuracy: 0.7041 - val_loss: 0.6358 - val_accuracy: 0.6671\n",
      "Epoch 414/500\n",
      "62/62 [==============================] - 1s 11ms/step - loss: 0.5753 - accuracy: 0.7063 - val_loss: 0.6354 - val_accuracy: 0.6722\n",
      "Epoch 415/500\n",
      "62/62 [==============================] - 1s 11ms/step - loss: 0.5706 - accuracy: 0.7126 - val_loss: 0.6305 - val_accuracy: 0.6696\n",
      "Epoch 416/500\n",
      "62/62 [==============================] - 1s 10ms/step - loss: 0.5691 - accuracy: 0.7157 - val_loss: 0.6324 - val_accuracy: 0.6747\n",
      "Epoch 417/500\n",
      "62/62 [==============================] - 1s 11ms/step - loss: 0.5663 - accuracy: 0.7108 - val_loss: 0.6321 - val_accuracy: 0.6735\n",
      "Epoch 418/500\n",
      "62/62 [==============================] - 1s 10ms/step - loss: 0.5665 - accuracy: 0.7153 - val_loss: 0.6384 - val_accuracy: 0.6645\n",
      "Epoch 419/500\n",
      "62/62 [==============================] - 1s 10ms/step - loss: 0.5787 - accuracy: 0.7040 - val_loss: 0.6321 - val_accuracy: 0.6760\n",
      "Epoch 420/500\n",
      "62/62 [==============================] - 1s 10ms/step - loss: 0.5748 - accuracy: 0.7108 - val_loss: 0.6371 - val_accuracy: 0.6811\n",
      "Epoch 421/500\n",
      "62/62 [==============================] - 1s 11ms/step - loss: 0.5725 - accuracy: 0.7086 - val_loss: 0.6323 - val_accuracy: 0.6811\n",
      "Epoch 422/500\n",
      "62/62 [==============================] - 1s 11ms/step - loss: 0.5668 - accuracy: 0.7114 - val_loss: 0.6325 - val_accuracy: 0.6824\n",
      "Epoch 423/500\n",
      "62/62 [==============================] - 1s 10ms/step - loss: 0.5692 - accuracy: 0.7137 - val_loss: 0.6266 - val_accuracy: 0.6913\n",
      "Epoch 424/500\n",
      "62/62 [==============================] - 1s 11ms/step - loss: 0.5732 - accuracy: 0.7073 - val_loss: 0.6348 - val_accuracy: 0.6709\n",
      "Epoch 425/500\n",
      "62/62 [==============================] - 1s 11ms/step - loss: 0.5810 - accuracy: 0.7030 - val_loss: 0.6266 - val_accuracy: 0.6901\n",
      "Epoch 426/500\n",
      "62/62 [==============================] - 1s 11ms/step - loss: 0.5673 - accuracy: 0.7094 - val_loss: 0.6341 - val_accuracy: 0.6747\n",
      "Epoch 427/500\n",
      "62/62 [==============================] - 1s 11ms/step - loss: 0.5740 - accuracy: 0.7110 - val_loss: 0.6295 - val_accuracy: 0.6862\n",
      "Epoch 428/500\n",
      "62/62 [==============================] - 1s 10ms/step - loss: 0.5736 - accuracy: 0.7105 - val_loss: 0.6298 - val_accuracy: 0.6747\n",
      "Epoch 429/500\n",
      "62/62 [==============================] - 1s 11ms/step - loss: 0.5756 - accuracy: 0.7089 - val_loss: 0.6296 - val_accuracy: 0.6862\n",
      "Epoch 430/500\n",
      "62/62 [==============================] - 1s 11ms/step - loss: 0.5705 - accuracy: 0.7075 - val_loss: 0.6265 - val_accuracy: 0.6786\n",
      "Epoch 431/500\n",
      "62/62 [==============================] - 1s 10ms/step - loss: 0.5747 - accuracy: 0.7118 - val_loss: 0.6369 - val_accuracy: 0.6633\n",
      "Epoch 432/500\n",
      "62/62 [==============================] - 1s 10ms/step - loss: 0.5750 - accuracy: 0.7081 - val_loss: 0.6313 - val_accuracy: 0.6760\n",
      "Epoch 433/500\n",
      "62/62 [==============================] - 1s 11ms/step - loss: 0.5740 - accuracy: 0.7118 - val_loss: 0.6361 - val_accuracy: 0.6658\n",
      "Epoch 434/500\n",
      "62/62 [==============================] - 1s 10ms/step - loss: 0.5787 - accuracy: 0.6998 - val_loss: 0.6395 - val_accuracy: 0.6684\n",
      "Epoch 435/500\n",
      "62/62 [==============================] - 1s 10ms/step - loss: 0.5693 - accuracy: 0.7105 - val_loss: 0.6321 - val_accuracy: 0.6773\n",
      "Epoch 436/500\n",
      "62/62 [==============================] - 1s 11ms/step - loss: 0.5700 - accuracy: 0.7095 - val_loss: 0.6345 - val_accuracy: 0.6684\n",
      "Epoch 437/500\n",
      "62/62 [==============================] - 1s 10ms/step - loss: 0.5706 - accuracy: 0.7115 - val_loss: 0.6266 - val_accuracy: 0.6837\n",
      "Epoch 438/500\n",
      "62/62 [==============================] - 1s 10ms/step - loss: 0.5714 - accuracy: 0.7115 - val_loss: 0.6378 - val_accuracy: 0.6747\n",
      "Epoch 439/500\n",
      "62/62 [==============================] - 1s 10ms/step - loss: 0.5761 - accuracy: 0.7098 - val_loss: 0.6228 - val_accuracy: 0.6901\n",
      "Epoch 440/500\n",
      "62/62 [==============================] - 1s 11ms/step - loss: 0.5744 - accuracy: 0.7076 - val_loss: 0.6309 - val_accuracy: 0.6798\n",
      "Epoch 441/500\n",
      "62/62 [==============================] - 1s 10ms/step - loss: 0.5793 - accuracy: 0.7002 - val_loss: 0.6305 - val_accuracy: 0.6824\n",
      "Epoch 442/500\n",
      "62/62 [==============================] - 1s 10ms/step - loss: 0.5736 - accuracy: 0.7129 - val_loss: 0.6264 - val_accuracy: 0.6837\n",
      "Epoch 443/500\n",
      "62/62 [==============================] - 1s 11ms/step - loss: 0.5707 - accuracy: 0.7080 - val_loss: 0.6274 - val_accuracy: 0.6696\n",
      "Epoch 444/500\n",
      "62/62 [==============================] - 1s 11ms/step - loss: 0.5693 - accuracy: 0.7144 - val_loss: 0.6267 - val_accuracy: 0.6824\n",
      "Epoch 445/500\n",
      "62/62 [==============================] - 1s 10ms/step - loss: 0.5700 - accuracy: 0.7095 - val_loss: 0.6376 - val_accuracy: 0.6735\n",
      "Epoch 446/500\n",
      "62/62 [==============================] - 1s 10ms/step - loss: 0.5751 - accuracy: 0.7070 - val_loss: 0.6387 - val_accuracy: 0.6607\n",
      "Epoch 447/500\n",
      "62/62 [==============================] - 1s 11ms/step - loss: 0.5748 - accuracy: 0.7085 - val_loss: 0.6375 - val_accuracy: 0.6658\n",
      "Epoch 448/500\n",
      "62/62 [==============================] - 1s 11ms/step - loss: 0.5730 - accuracy: 0.7071 - val_loss: 0.6274 - val_accuracy: 0.6811\n",
      "Epoch 449/500\n",
      "62/62 [==============================] - 1s 11ms/step - loss: 0.5680 - accuracy: 0.7176 - val_loss: 0.6360 - val_accuracy: 0.6684\n",
      "Epoch 450/500\n",
      "62/62 [==============================] - 1s 10ms/step - loss: 0.5650 - accuracy: 0.7141 - val_loss: 0.6393 - val_accuracy: 0.6747\n",
      "Epoch 451/500\n",
      "62/62 [==============================] - 1s 12ms/step - loss: 0.5721 - accuracy: 0.7104 - val_loss: 0.6281 - val_accuracy: 0.6773\n",
      "Epoch 452/500\n",
      "62/62 [==============================] - 1s 10ms/step - loss: 0.5784 - accuracy: 0.7039 - val_loss: 0.6289 - val_accuracy: 0.6811\n",
      "Epoch 453/500\n",
      "62/62 [==============================] - 1s 10ms/step - loss: 0.5675 - accuracy: 0.7153 - val_loss: 0.6285 - val_accuracy: 0.6798\n",
      "Epoch 454/500\n",
      "62/62 [==============================] - 1s 11ms/step - loss: 0.5707 - accuracy: 0.7065 - val_loss: 0.6352 - val_accuracy: 0.6658\n",
      "Epoch 455/500\n",
      "62/62 [==============================] - 1s 10ms/step - loss: 0.5688 - accuracy: 0.7139 - val_loss: 0.6390 - val_accuracy: 0.6684\n",
      "Epoch 456/500\n",
      "62/62 [==============================] - 1s 10ms/step - loss: 0.5711 - accuracy: 0.7110 - val_loss: 0.6356 - val_accuracy: 0.6684\n",
      "Epoch 457/500\n",
      "62/62 [==============================] - 1s 10ms/step - loss: 0.5706 - accuracy: 0.7083 - val_loss: 0.6286 - val_accuracy: 0.6696\n",
      "Epoch 458/500\n",
      "62/62 [==============================] - 1s 11ms/step - loss: 0.5713 - accuracy: 0.7108 - val_loss: 0.6287 - val_accuracy: 0.6684\n",
      "Epoch 459/500\n",
      "62/62 [==============================] - 1s 10ms/step - loss: 0.5653 - accuracy: 0.7137 - val_loss: 0.6323 - val_accuracy: 0.6798\n",
      "Epoch 460/500\n",
      "62/62 [==============================] - 1s 10ms/step - loss: 0.5726 - accuracy: 0.7113 - val_loss: 0.6366 - val_accuracy: 0.6786\n",
      "Epoch 461/500\n",
      "62/62 [==============================] - 1s 11ms/step - loss: 0.5735 - accuracy: 0.7079 - val_loss: 0.6365 - val_accuracy: 0.6658\n",
      "Epoch 462/500\n",
      "62/62 [==============================] - 1s 11ms/step - loss: 0.5759 - accuracy: 0.7129 - val_loss: 0.6336 - val_accuracy: 0.6658\n",
      "Epoch 463/500\n",
      "62/62 [==============================] - 1s 10ms/step - loss: 0.5692 - accuracy: 0.7095 - val_loss: 0.6304 - val_accuracy: 0.6709\n",
      "Epoch 464/500\n",
      "62/62 [==============================] - 1s 10ms/step - loss: 0.5707 - accuracy: 0.7175 - val_loss: 0.6261 - val_accuracy: 0.6952\n",
      "Epoch 465/500\n",
      "62/62 [==============================] - 1s 11ms/step - loss: 0.5708 - accuracy: 0.7170 - val_loss: 0.6349 - val_accuracy: 0.6684\n",
      "Epoch 466/500\n",
      "62/62 [==============================] - 1s 10ms/step - loss: 0.5707 - accuracy: 0.7066 - val_loss: 0.6377 - val_accuracy: 0.6658\n",
      "Epoch 467/500\n",
      "62/62 [==============================] - 1s 11ms/step - loss: 0.5690 - accuracy: 0.7148 - val_loss: 0.6274 - val_accuracy: 0.6773\n",
      "Epoch 468/500\n",
      "62/62 [==============================] - 1s 10ms/step - loss: 0.5756 - accuracy: 0.7042 - val_loss: 0.6379 - val_accuracy: 0.6582\n",
      "Epoch 469/500\n",
      "62/62 [==============================] - 1s 11ms/step - loss: 0.5719 - accuracy: 0.7155 - val_loss: 0.6310 - val_accuracy: 0.6709\n",
      "Epoch 470/500\n",
      "62/62 [==============================] - 1s 11ms/step - loss: 0.5667 - accuracy: 0.7123 - val_loss: 0.6343 - val_accuracy: 0.6658\n",
      "Epoch 471/500\n",
      "62/62 [==============================] - 1s 10ms/step - loss: 0.5748 - accuracy: 0.7086 - val_loss: 0.6358 - val_accuracy: 0.6684\n",
      "Epoch 472/500\n",
      "62/62 [==============================] - 1s 11ms/step - loss: 0.5662 - accuracy: 0.7121 - val_loss: 0.6381 - val_accuracy: 0.6735\n",
      "Epoch 473/500\n",
      "62/62 [==============================] - 1s 10ms/step - loss: 0.5781 - accuracy: 0.7083 - val_loss: 0.6258 - val_accuracy: 0.6901\n",
      "Epoch 474/500\n",
      "62/62 [==============================] - 1s 10ms/step - loss: 0.5732 - accuracy: 0.7099 - val_loss: 0.6355 - val_accuracy: 0.6735\n",
      "Epoch 475/500\n",
      "62/62 [==============================] - 1s 10ms/step - loss: 0.5720 - accuracy: 0.7092 - val_loss: 0.6287 - val_accuracy: 0.6709\n",
      "Epoch 476/500\n",
      "62/62 [==============================] - 1s 11ms/step - loss: 0.5762 - accuracy: 0.7076 - val_loss: 0.6358 - val_accuracy: 0.6811\n",
      "Epoch 477/500\n",
      "62/62 [==============================] - 1s 10ms/step - loss: 0.5708 - accuracy: 0.7054 - val_loss: 0.6372 - val_accuracy: 0.6786\n",
      "Epoch 478/500\n",
      "62/62 [==============================] - 1s 10ms/step - loss: 0.5686 - accuracy: 0.7184 - val_loss: 0.6397 - val_accuracy: 0.6773\n",
      "Epoch 479/500\n",
      "62/62 [==============================] - 1s 11ms/step - loss: 0.5729 - accuracy: 0.7158 - val_loss: 0.6258 - val_accuracy: 0.6837\n",
      "Epoch 480/500\n",
      "62/62 [==============================] - 1s 10ms/step - loss: 0.5716 - accuracy: 0.7110 - val_loss: 0.6308 - val_accuracy: 0.6837\n",
      "Epoch 481/500\n",
      "62/62 [==============================] - 1s 11ms/step - loss: 0.5655 - accuracy: 0.7100 - val_loss: 0.6375 - val_accuracy: 0.6786\n",
      "Epoch 482/500\n",
      "62/62 [==============================] - 1s 10ms/step - loss: 0.5691 - accuracy: 0.7151 - val_loss: 0.6331 - val_accuracy: 0.6709\n",
      "Epoch 483/500\n",
      "62/62 [==============================] - 1s 11ms/step - loss: 0.5711 - accuracy: 0.7066 - val_loss: 0.6321 - val_accuracy: 0.6786\n",
      "Epoch 484/500\n",
      "62/62 [==============================] - 1s 11ms/step - loss: 0.5799 - accuracy: 0.7032 - val_loss: 0.6404 - val_accuracy: 0.6658\n",
      "Epoch 485/500\n",
      "62/62 [==============================] - 1s 10ms/step - loss: 0.5758 - accuracy: 0.7045 - val_loss: 0.6375 - val_accuracy: 0.6684\n",
      "Epoch 486/500\n",
      "62/62 [==============================] - 1s 10ms/step - loss: 0.5720 - accuracy: 0.7127 - val_loss: 0.6375 - val_accuracy: 0.6684\n",
      "Epoch 487/500\n",
      "62/62 [==============================] - 1s 11ms/step - loss: 0.5634 - accuracy: 0.7134 - val_loss: 0.6398 - val_accuracy: 0.6645\n",
      "Epoch 488/500\n",
      "62/62 [==============================] - 1s 10ms/step - loss: 0.5800 - accuracy: 0.7100 - val_loss: 0.6440 - val_accuracy: 0.6607\n",
      "Epoch 489/500\n",
      "62/62 [==============================] - 1s 10ms/step - loss: 0.5792 - accuracy: 0.7097 - val_loss: 0.6416 - val_accuracy: 0.6556\n",
      "Epoch 490/500\n",
      "62/62 [==============================] - 1s 11ms/step - loss: 0.5734 - accuracy: 0.7046 - val_loss: 0.6356 - val_accuracy: 0.6645\n",
      "Epoch 491/500\n",
      "62/62 [==============================] - 1s 10ms/step - loss: 0.5723 - accuracy: 0.7113 - val_loss: 0.6307 - val_accuracy: 0.6798\n",
      "Epoch 492/500\n",
      "62/62 [==============================] - 1s 10ms/step - loss: 0.5712 - accuracy: 0.7110 - val_loss: 0.6363 - val_accuracy: 0.6722\n",
      "Epoch 493/500\n",
      "62/62 [==============================] - 1s 11ms/step - loss: 0.5658 - accuracy: 0.7122 - val_loss: 0.6316 - val_accuracy: 0.6824\n",
      "Epoch 494/500\n",
      "62/62 [==============================] - 1s 11ms/step - loss: 0.5728 - accuracy: 0.7107 - val_loss: 0.6359 - val_accuracy: 0.6671\n",
      "Epoch 495/500\n",
      "62/62 [==============================] - 1s 11ms/step - loss: 0.5633 - accuracy: 0.7133 - val_loss: 0.6363 - val_accuracy: 0.6747\n",
      "Epoch 496/500\n",
      "62/62 [==============================] - 1s 10ms/step - loss: 0.5683 - accuracy: 0.7112 - val_loss: 0.6412 - val_accuracy: 0.6594\n",
      "Epoch 497/500\n",
      "62/62 [==============================] - 1s 10ms/step - loss: 0.5728 - accuracy: 0.7081 - val_loss: 0.6292 - val_accuracy: 0.6875\n",
      "Epoch 498/500\n",
      "62/62 [==============================] - 1s 10ms/step - loss: 0.5683 - accuracy: 0.7141 - val_loss: 0.6346 - val_accuracy: 0.6709\n",
      "Epoch 499/500\n",
      "62/62 [==============================] - 1s 11ms/step - loss: 0.5675 - accuracy: 0.7167 - val_loss: 0.6371 - val_accuracy: 0.6671\n",
      "Epoch 500/500\n",
      "62/62 [==============================] - 1s 10ms/step - loss: 0.5684 - accuracy: 0.7142 - val_loss: 0.6420 - val_accuracy: 0.6607\n",
      "Epoch 1/500\n",
      "62/62 [==============================] - 2s 16ms/step - loss: 0.6598 - accuracy: 0.6251 - val_loss: 0.6662 - val_accuracy: 0.6122\n",
      "Epoch 2/500\n",
      "62/62 [==============================] - 1s 12ms/step - loss: 0.6511 - accuracy: 0.6277 - val_loss: 0.6539 - val_accuracy: 0.6416\n",
      "Epoch 3/500\n",
      "62/62 [==============================] - 1s 13ms/step - loss: 0.6474 - accuracy: 0.6290 - val_loss: 0.6456 - val_accuracy: 0.6645\n",
      "Epoch 4/500\n",
      "62/62 [==============================] - 1s 12ms/step - loss: 0.6432 - accuracy: 0.6341 - val_loss: 0.6413 - val_accuracy: 0.6684\n",
      "Epoch 5/500\n",
      "62/62 [==============================] - 1s 12ms/step - loss: 0.6407 - accuracy: 0.6423 - val_loss: 0.6384 - val_accuracy: 0.6722\n",
      "Epoch 6/500\n",
      "62/62 [==============================] - 1s 13ms/step - loss: 0.6420 - accuracy: 0.6288 - val_loss: 0.6369 - val_accuracy: 0.6696\n",
      "Epoch 7/500\n",
      "62/62 [==============================] - 1s 12ms/step - loss: 0.6411 - accuracy: 0.6329 - val_loss: 0.6337 - val_accuracy: 0.6684\n",
      "Epoch 8/500\n",
      "62/62 [==============================] - 1s 12ms/step - loss: 0.6432 - accuracy: 0.6384 - val_loss: 0.6339 - val_accuracy: 0.6633\n",
      "Epoch 9/500\n",
      "62/62 [==============================] - 1s 12ms/step - loss: 0.6367 - accuracy: 0.6451 - val_loss: 0.6312 - val_accuracy: 0.6658\n",
      "Epoch 10/500\n",
      "62/62 [==============================] - 1s 12ms/step - loss: 0.6365 - accuracy: 0.6437 - val_loss: 0.6310 - val_accuracy: 0.6594\n",
      "Epoch 11/500\n",
      "62/62 [==============================] - 1s 12ms/step - loss: 0.6400 - accuracy: 0.6425 - val_loss: 0.6314 - val_accuracy: 0.6658\n",
      "Epoch 12/500\n",
      "62/62 [==============================] - 1s 12ms/step - loss: 0.6355 - accuracy: 0.6421 - val_loss: 0.6275 - val_accuracy: 0.6684\n",
      "Epoch 13/500\n",
      "62/62 [==============================] - 1s 13ms/step - loss: 0.6362 - accuracy: 0.6452 - val_loss: 0.6276 - val_accuracy: 0.6696\n",
      "Epoch 14/500\n",
      "62/62 [==============================] - 1s 12ms/step - loss: 0.6341 - accuracy: 0.6469 - val_loss: 0.6276 - val_accuracy: 0.6709\n",
      "Epoch 15/500\n",
      "62/62 [==============================] - 1s 12ms/step - loss: 0.6341 - accuracy: 0.6436 - val_loss: 0.6261 - val_accuracy: 0.6696\n",
      "Epoch 16/500\n",
      "62/62 [==============================] - 1s 13ms/step - loss: 0.6350 - accuracy: 0.6442 - val_loss: 0.6279 - val_accuracy: 0.6684\n",
      "Epoch 17/500\n",
      "62/62 [==============================] - 1s 12ms/step - loss: 0.6342 - accuracy: 0.6485 - val_loss: 0.6274 - val_accuracy: 0.6696\n",
      "Epoch 18/500\n",
      "62/62 [==============================] - 1s 13ms/step - loss: 0.6336 - accuracy: 0.6533 - val_loss: 0.6291 - val_accuracy: 0.6645\n",
      "Epoch 19/500\n",
      "62/62 [==============================] - 1s 12ms/step - loss: 0.6310 - accuracy: 0.6523 - val_loss: 0.6281 - val_accuracy: 0.6696\n",
      "Epoch 20/500\n",
      "62/62 [==============================] - 1s 13ms/step - loss: 0.6289 - accuracy: 0.6523 - val_loss: 0.6270 - val_accuracy: 0.6696\n",
      "Epoch 21/500\n",
      "62/62 [==============================] - 1s 13ms/step - loss: 0.6314 - accuracy: 0.6498 - val_loss: 0.6269 - val_accuracy: 0.6696\n",
      "Epoch 22/500\n",
      "62/62 [==============================] - 1s 12ms/step - loss: 0.6263 - accuracy: 0.6549 - val_loss: 0.6257 - val_accuracy: 0.6658\n",
      "Epoch 23/500\n",
      "62/62 [==============================] - 1s 12ms/step - loss: 0.6295 - accuracy: 0.6529 - val_loss: 0.6266 - val_accuracy: 0.6658\n",
      "Epoch 24/500\n",
      "62/62 [==============================] - 1s 12ms/step - loss: 0.6300 - accuracy: 0.6525 - val_loss: 0.6255 - val_accuracy: 0.6645\n",
      "Epoch 25/500\n",
      "62/62 [==============================] - 1s 13ms/step - loss: 0.6256 - accuracy: 0.6554 - val_loss: 0.6244 - val_accuracy: 0.6645\n",
      "Epoch 26/500\n",
      "62/62 [==============================] - 1s 12ms/step - loss: 0.6288 - accuracy: 0.6519 - val_loss: 0.6230 - val_accuracy: 0.6722\n",
      "Epoch 27/500\n",
      "62/62 [==============================] - 1s 13ms/step - loss: 0.6231 - accuracy: 0.6533 - val_loss: 0.6221 - val_accuracy: 0.6747\n",
      "Epoch 28/500\n",
      "62/62 [==============================] - 1s 12ms/step - loss: 0.6261 - accuracy: 0.6539 - val_loss: 0.6225 - val_accuracy: 0.6747\n",
      "Epoch 29/500\n",
      "62/62 [==============================] - 1s 12ms/step - loss: 0.6252 - accuracy: 0.6565 - val_loss: 0.6216 - val_accuracy: 0.6709\n",
      "Epoch 30/500\n",
      "62/62 [==============================] - 1s 13ms/step - loss: 0.6310 - accuracy: 0.6517 - val_loss: 0.6221 - val_accuracy: 0.6735\n",
      "Epoch 31/500\n",
      "62/62 [==============================] - 1s 12ms/step - loss: 0.6281 - accuracy: 0.6538 - val_loss: 0.6237 - val_accuracy: 0.6709\n",
      "Epoch 32/500\n",
      "62/62 [==============================] - 1s 12ms/step - loss: 0.6294 - accuracy: 0.6522 - val_loss: 0.6234 - val_accuracy: 0.6735\n",
      "Epoch 33/500\n",
      "62/62 [==============================] - 1s 13ms/step - loss: 0.6277 - accuracy: 0.6581 - val_loss: 0.6214 - val_accuracy: 0.6786\n",
      "Epoch 34/500\n",
      "62/62 [==============================] - 1s 12ms/step - loss: 0.6279 - accuracy: 0.6536 - val_loss: 0.6221 - val_accuracy: 0.6811\n",
      "Epoch 35/500\n",
      "62/62 [==============================] - 1s 12ms/step - loss: 0.6264 - accuracy: 0.6570 - val_loss: 0.6245 - val_accuracy: 0.6671\n",
      "Epoch 36/500\n",
      "62/62 [==============================] - 1s 13ms/step - loss: 0.6230 - accuracy: 0.6648 - val_loss: 0.6224 - val_accuracy: 0.6722\n",
      "Epoch 37/500\n",
      "62/62 [==============================] - 1s 13ms/step - loss: 0.6227 - accuracy: 0.6576 - val_loss: 0.6215 - val_accuracy: 0.6735\n",
      "Epoch 38/500\n",
      "62/62 [==============================] - 1s 12ms/step - loss: 0.6208 - accuracy: 0.6619 - val_loss: 0.6209 - val_accuracy: 0.6709\n",
      "Epoch 39/500\n",
      "62/62 [==============================] - 1s 13ms/step - loss: 0.6260 - accuracy: 0.6542 - val_loss: 0.6208 - val_accuracy: 0.6722\n",
      "Epoch 40/500\n",
      "62/62 [==============================] - 1s 12ms/step - loss: 0.6255 - accuracy: 0.6552 - val_loss: 0.6214 - val_accuracy: 0.6696\n",
      "Epoch 41/500\n",
      "62/62 [==============================] - 1s 12ms/step - loss: 0.6242 - accuracy: 0.6590 - val_loss: 0.6216 - val_accuracy: 0.6709\n",
      "Epoch 42/500\n",
      "62/62 [==============================] - 1s 12ms/step - loss: 0.6233 - accuracy: 0.6602 - val_loss: 0.6214 - val_accuracy: 0.6722\n",
      "Epoch 43/500\n",
      "62/62 [==============================] - 1s 12ms/step - loss: 0.6199 - accuracy: 0.6609 - val_loss: 0.6207 - val_accuracy: 0.6671\n",
      "Epoch 44/500\n",
      "62/62 [==============================] - 1s 12ms/step - loss: 0.6147 - accuracy: 0.6691 - val_loss: 0.6225 - val_accuracy: 0.6633\n",
      "Epoch 45/500\n",
      "62/62 [==============================] - 1s 12ms/step - loss: 0.6217 - accuracy: 0.6630 - val_loss: 0.6229 - val_accuracy: 0.6658\n",
      "Epoch 46/500\n",
      "62/62 [==============================] - 1s 12ms/step - loss: 0.6237 - accuracy: 0.6561 - val_loss: 0.6237 - val_accuracy: 0.6607\n",
      "Epoch 47/500\n",
      "62/62 [==============================] - 1s 12ms/step - loss: 0.6158 - accuracy: 0.6674 - val_loss: 0.6244 - val_accuracy: 0.6582\n",
      "Epoch 48/500\n",
      "62/62 [==============================] - 1s 15ms/step - loss: 0.6204 - accuracy: 0.6644 - val_loss: 0.6233 - val_accuracy: 0.6684\n",
      "Epoch 49/500\n",
      "62/62 [==============================] - 1s 13ms/step - loss: 0.6177 - accuracy: 0.6657 - val_loss: 0.6218 - val_accuracy: 0.6645\n",
      "Epoch 50/500\n",
      "62/62 [==============================] - 1s 13ms/step - loss: 0.6220 - accuracy: 0.6610 - val_loss: 0.6214 - val_accuracy: 0.6709\n",
      "Epoch 51/500\n",
      "62/62 [==============================] - 1s 13ms/step - loss: 0.6178 - accuracy: 0.6634 - val_loss: 0.6212 - val_accuracy: 0.6709\n",
      "Epoch 52/500\n",
      "62/62 [==============================] - 1s 13ms/step - loss: 0.6196 - accuracy: 0.6621 - val_loss: 0.6205 - val_accuracy: 0.6735\n",
      "Epoch 53/500\n",
      "62/62 [==============================] - 1s 12ms/step - loss: 0.6161 - accuracy: 0.6684 - val_loss: 0.6197 - val_accuracy: 0.6722\n",
      "Epoch 54/500\n",
      "62/62 [==============================] - 1s 13ms/step - loss: 0.6190 - accuracy: 0.6677 - val_loss: 0.6197 - val_accuracy: 0.6709\n",
      "Epoch 55/500\n",
      "62/62 [==============================] - 1s 13ms/step - loss: 0.6179 - accuracy: 0.6659 - val_loss: 0.6208 - val_accuracy: 0.6735\n",
      "Epoch 56/500\n",
      "62/62 [==============================] - 1s 12ms/step - loss: 0.6200 - accuracy: 0.6591 - val_loss: 0.6211 - val_accuracy: 0.6709\n",
      "Epoch 57/500\n",
      "62/62 [==============================] - 1s 13ms/step - loss: 0.6146 - accuracy: 0.6694 - val_loss: 0.6193 - val_accuracy: 0.6735\n",
      "Epoch 58/500\n",
      "62/62 [==============================] - 1s 12ms/step - loss: 0.6146 - accuracy: 0.6660 - val_loss: 0.6194 - val_accuracy: 0.6696\n",
      "Epoch 59/500\n",
      "62/62 [==============================] - 1s 12ms/step - loss: 0.6175 - accuracy: 0.6614 - val_loss: 0.6216 - val_accuracy: 0.6671\n",
      "Epoch 60/500\n",
      "62/62 [==============================] - 1s 13ms/step - loss: 0.6160 - accuracy: 0.6629 - val_loss: 0.6209 - val_accuracy: 0.6722\n",
      "Epoch 61/500\n",
      "62/62 [==============================] - 1s 12ms/step - loss: 0.6170 - accuracy: 0.6620 - val_loss: 0.6203 - val_accuracy: 0.6709\n",
      "Epoch 62/500\n",
      "62/62 [==============================] - 1s 13ms/step - loss: 0.6155 - accuracy: 0.6667 - val_loss: 0.6199 - val_accuracy: 0.6709\n",
      "Epoch 63/500\n",
      "62/62 [==============================] - 1s 13ms/step - loss: 0.6189 - accuracy: 0.6699 - val_loss: 0.6197 - val_accuracy: 0.6722\n",
      "Epoch 64/500\n",
      "62/62 [==============================] - 1s 13ms/step - loss: 0.6150 - accuracy: 0.6699 - val_loss: 0.6182 - val_accuracy: 0.6658\n",
      "Epoch 65/500\n",
      "62/62 [==============================] - 1s 12ms/step - loss: 0.6129 - accuracy: 0.6716 - val_loss: 0.6193 - val_accuracy: 0.6696\n",
      "Epoch 66/500\n",
      "62/62 [==============================] - 1s 13ms/step - loss: 0.6146 - accuracy: 0.6675 - val_loss: 0.6187 - val_accuracy: 0.6722\n",
      "Epoch 67/500\n",
      "62/62 [==============================] - 1s 12ms/step - loss: 0.6144 - accuracy: 0.6704 - val_loss: 0.6200 - val_accuracy: 0.6722\n",
      "Epoch 68/500\n",
      "62/62 [==============================] - 1s 12ms/step - loss: 0.6119 - accuracy: 0.6732 - val_loss: 0.6197 - val_accuracy: 0.6722\n",
      "Epoch 69/500\n",
      "62/62 [==============================] - 1s 12ms/step - loss: 0.6138 - accuracy: 0.6702 - val_loss: 0.6204 - val_accuracy: 0.6709\n",
      "Epoch 70/500\n",
      "62/62 [==============================] - 1s 12ms/step - loss: 0.6131 - accuracy: 0.6717 - val_loss: 0.6197 - val_accuracy: 0.6722\n",
      "Epoch 71/500\n",
      "62/62 [==============================] - 1s 13ms/step - loss: 0.6166 - accuracy: 0.6721 - val_loss: 0.6209 - val_accuracy: 0.6696\n",
      "Epoch 72/500\n",
      "62/62 [==============================] - 1s 13ms/step - loss: 0.6090 - accuracy: 0.6712 - val_loss: 0.6194 - val_accuracy: 0.6709\n",
      "Epoch 73/500\n",
      "62/62 [==============================] - 1s 13ms/step - loss: 0.6103 - accuracy: 0.6720 - val_loss: 0.6181 - val_accuracy: 0.6747\n",
      "Epoch 74/500\n",
      "62/62 [==============================] - 1s 12ms/step - loss: 0.6095 - accuracy: 0.6770 - val_loss: 0.6172 - val_accuracy: 0.6709\n",
      "Epoch 75/500\n",
      "62/62 [==============================] - 1s 13ms/step - loss: 0.6153 - accuracy: 0.6721 - val_loss: 0.6176 - val_accuracy: 0.6722\n",
      "Epoch 76/500\n",
      "62/62 [==============================] - 1s 12ms/step - loss: 0.6107 - accuracy: 0.6732 - val_loss: 0.6176 - val_accuracy: 0.6735\n",
      "Epoch 77/500\n",
      "62/62 [==============================] - 1s 12ms/step - loss: 0.6067 - accuracy: 0.6775 - val_loss: 0.6168 - val_accuracy: 0.6722\n",
      "Epoch 78/500\n",
      "62/62 [==============================] - 1s 12ms/step - loss: 0.6101 - accuracy: 0.6675 - val_loss: 0.6161 - val_accuracy: 0.6760\n",
      "Epoch 79/500\n",
      "62/62 [==============================] - 1s 12ms/step - loss: 0.6161 - accuracy: 0.6654 - val_loss: 0.6161 - val_accuracy: 0.6747\n",
      "Epoch 80/500\n",
      "62/62 [==============================] - 1s 12ms/step - loss: 0.6091 - accuracy: 0.6755 - val_loss: 0.6178 - val_accuracy: 0.6747\n",
      "Epoch 81/500\n",
      "62/62 [==============================] - 1s 13ms/step - loss: 0.6101 - accuracy: 0.6768 - val_loss: 0.6177 - val_accuracy: 0.6760\n",
      "Epoch 82/500\n",
      "62/62 [==============================] - 1s 13ms/step - loss: 0.6129 - accuracy: 0.6675 - val_loss: 0.6181 - val_accuracy: 0.6735\n",
      "Epoch 83/500\n",
      "62/62 [==============================] - 1s 12ms/step - loss: 0.6083 - accuracy: 0.6768 - val_loss: 0.6188 - val_accuracy: 0.6735\n",
      "Epoch 84/500\n",
      "62/62 [==============================] - 1s 13ms/step - loss: 0.6104 - accuracy: 0.6721 - val_loss: 0.6176 - val_accuracy: 0.6722\n",
      "Epoch 85/500\n",
      "62/62 [==============================] - 1s 12ms/step - loss: 0.6086 - accuracy: 0.6730 - val_loss: 0.6184 - val_accuracy: 0.6722\n",
      "Epoch 86/500\n",
      "62/62 [==============================] - 1s 12ms/step - loss: 0.6094 - accuracy: 0.6737 - val_loss: 0.6189 - val_accuracy: 0.6735\n",
      "Epoch 87/500\n",
      "62/62 [==============================] - 1s 13ms/step - loss: 0.6102 - accuracy: 0.6678 - val_loss: 0.6199 - val_accuracy: 0.6735\n",
      "Epoch 88/500\n",
      "62/62 [==============================] - 1s 12ms/step - loss: 0.6087 - accuracy: 0.6721 - val_loss: 0.6205 - val_accuracy: 0.6722\n",
      "Epoch 89/500\n",
      "62/62 [==============================] - 1s 12ms/step - loss: 0.6119 - accuracy: 0.6693 - val_loss: 0.6201 - val_accuracy: 0.6760\n",
      "Epoch 90/500\n",
      "62/62 [==============================] - 1s 12ms/step - loss: 0.6100 - accuracy: 0.6756 - val_loss: 0.6196 - val_accuracy: 0.6735\n",
      "Epoch 91/500\n",
      "62/62 [==============================] - 1s 13ms/step - loss: 0.6074 - accuracy: 0.6765 - val_loss: 0.6188 - val_accuracy: 0.6747\n",
      "Epoch 92/500\n",
      "62/62 [==============================] - 1s 12ms/step - loss: 0.6117 - accuracy: 0.6718 - val_loss: 0.6176 - val_accuracy: 0.6735\n",
      "Epoch 93/500\n",
      "62/62 [==============================] - 1s 14ms/step - loss: 0.6106 - accuracy: 0.6747 - val_loss: 0.6189 - val_accuracy: 0.6747\n",
      "Epoch 94/500\n",
      "62/62 [==============================] - 1s 12ms/step - loss: 0.6077 - accuracy: 0.6774 - val_loss: 0.6180 - val_accuracy: 0.6735\n",
      "Epoch 95/500\n",
      "62/62 [==============================] - 1s 13ms/step - loss: 0.6128 - accuracy: 0.6730 - val_loss: 0.6174 - val_accuracy: 0.6773\n",
      "Epoch 96/500\n",
      "62/62 [==============================] - 1s 12ms/step - loss: 0.6041 - accuracy: 0.6790 - val_loss: 0.6169 - val_accuracy: 0.6773\n",
      "Epoch 97/500\n",
      "62/62 [==============================] - 1s 13ms/step - loss: 0.6075 - accuracy: 0.6813 - val_loss: 0.6185 - val_accuracy: 0.6760\n",
      "Epoch 98/500\n",
      "62/62 [==============================] - 1s 12ms/step - loss: 0.6068 - accuracy: 0.6742 - val_loss: 0.6173 - val_accuracy: 0.6747\n",
      "Epoch 99/500\n",
      "62/62 [==============================] - 1s 13ms/step - loss: 0.6082 - accuracy: 0.6764 - val_loss: 0.6178 - val_accuracy: 0.6786\n",
      "Epoch 100/500\n",
      "62/62 [==============================] - 1s 12ms/step - loss: 0.6107 - accuracy: 0.6721 - val_loss: 0.6173 - val_accuracy: 0.6760\n",
      "Epoch 101/500\n",
      "62/62 [==============================] - 1s 12ms/step - loss: 0.6061 - accuracy: 0.6771 - val_loss: 0.6170 - val_accuracy: 0.6735\n",
      "Epoch 102/500\n",
      "62/62 [==============================] - 1s 12ms/step - loss: 0.6057 - accuracy: 0.6802 - val_loss: 0.6162 - val_accuracy: 0.6760\n",
      "Epoch 103/500\n",
      "62/62 [==============================] - 1s 12ms/step - loss: 0.6040 - accuracy: 0.6779 - val_loss: 0.6162 - val_accuracy: 0.6798\n",
      "Epoch 104/500\n",
      "62/62 [==============================] - 1s 13ms/step - loss: 0.6037 - accuracy: 0.6774 - val_loss: 0.6163 - val_accuracy: 0.6837\n",
      "Epoch 105/500\n",
      "62/62 [==============================] - 1s 13ms/step - loss: 0.6045 - accuracy: 0.6723 - val_loss: 0.6153 - val_accuracy: 0.6811\n",
      "Epoch 106/500\n",
      "62/62 [==============================] - 1s 12ms/step - loss: 0.6006 - accuracy: 0.6789 - val_loss: 0.6159 - val_accuracy: 0.6824\n",
      "Epoch 107/500\n",
      "62/62 [==============================] - 1s 12ms/step - loss: 0.6026 - accuracy: 0.6771 - val_loss: 0.6161 - val_accuracy: 0.6849\n",
      "Epoch 108/500\n",
      "62/62 [==============================] - 1s 12ms/step - loss: 0.5984 - accuracy: 0.6780 - val_loss: 0.6171 - val_accuracy: 0.6786\n",
      "Epoch 109/500\n",
      "62/62 [==============================] - 1s 12ms/step - loss: 0.6078 - accuracy: 0.6769 - val_loss: 0.6177 - val_accuracy: 0.6773\n",
      "Epoch 110/500\n",
      "62/62 [==============================] - 1s 13ms/step - loss: 0.6076 - accuracy: 0.6770 - val_loss: 0.6183 - val_accuracy: 0.6760\n",
      "Epoch 111/500\n",
      "62/62 [==============================] - 1s 12ms/step - loss: 0.6043 - accuracy: 0.6770 - val_loss: 0.6166 - val_accuracy: 0.6837\n",
      "Epoch 112/500\n",
      "62/62 [==============================] - 1s 13ms/step - loss: 0.6053 - accuracy: 0.6768 - val_loss: 0.6169 - val_accuracy: 0.6837\n",
      "Epoch 113/500\n",
      "62/62 [==============================] - 1s 12ms/step - loss: 0.6020 - accuracy: 0.6805 - val_loss: 0.6172 - val_accuracy: 0.6798\n",
      "Epoch 114/500\n",
      "62/62 [==============================] - 1s 14ms/step - loss: 0.6017 - accuracy: 0.6800 - val_loss: 0.6166 - val_accuracy: 0.6824\n",
      "Epoch 115/500\n",
      "62/62 [==============================] - 1s 12ms/step - loss: 0.6029 - accuracy: 0.6776 - val_loss: 0.6159 - val_accuracy: 0.6786\n",
      "Epoch 116/500\n",
      "62/62 [==============================] - 1s 12ms/step - loss: 0.5997 - accuracy: 0.6809 - val_loss: 0.6141 - val_accuracy: 0.6824\n",
      "Epoch 117/500\n",
      "62/62 [==============================] - 1s 13ms/step - loss: 0.6066 - accuracy: 0.6793 - val_loss: 0.6150 - val_accuracy: 0.6824\n",
      "Epoch 118/500\n",
      "62/62 [==============================] - 1s 12ms/step - loss: 0.6030 - accuracy: 0.6851 - val_loss: 0.6154 - val_accuracy: 0.6798\n",
      "Epoch 119/500\n",
      "62/62 [==============================] - 1s 12ms/step - loss: 0.6056 - accuracy: 0.6755 - val_loss: 0.6161 - val_accuracy: 0.6811\n",
      "Epoch 120/500\n",
      "62/62 [==============================] - 1s 12ms/step - loss: 0.6013 - accuracy: 0.6786 - val_loss: 0.6141 - val_accuracy: 0.6811\n",
      "Epoch 121/500\n",
      "62/62 [==============================] - 1s 12ms/step - loss: 0.5987 - accuracy: 0.6823 - val_loss: 0.6151 - val_accuracy: 0.6811\n",
      "Epoch 122/500\n",
      "62/62 [==============================] - 1s 12ms/step - loss: 0.5973 - accuracy: 0.6839 - val_loss: 0.6151 - val_accuracy: 0.6798\n",
      "Epoch 123/500\n",
      "62/62 [==============================] - 1s 13ms/step - loss: 0.6029 - accuracy: 0.6832 - val_loss: 0.6164 - val_accuracy: 0.6798\n",
      "Epoch 124/500\n",
      "62/62 [==============================] - 1s 12ms/step - loss: 0.6005 - accuracy: 0.6863 - val_loss: 0.6157 - val_accuracy: 0.6811\n",
      "Epoch 125/500\n",
      "62/62 [==============================] - 1s 13ms/step - loss: 0.6048 - accuracy: 0.6836 - val_loss: 0.6167 - val_accuracy: 0.6824\n",
      "Epoch 126/500\n",
      "62/62 [==============================] - 1s 14ms/step - loss: 0.6035 - accuracy: 0.6838 - val_loss: 0.6181 - val_accuracy: 0.6760\n",
      "Epoch 127/500\n",
      "62/62 [==============================] - 1s 13ms/step - loss: 0.6015 - accuracy: 0.6843 - val_loss: 0.6176 - val_accuracy: 0.6786\n",
      "Epoch 128/500\n",
      "62/62 [==============================] - 1s 12ms/step - loss: 0.5980 - accuracy: 0.6866 - val_loss: 0.6166 - val_accuracy: 0.6811\n",
      "Epoch 129/500\n",
      "62/62 [==============================] - 1s 13ms/step - loss: 0.5989 - accuracy: 0.6857 - val_loss: 0.6164 - val_accuracy: 0.6786\n",
      "Epoch 130/500\n",
      "62/62 [==============================] - 1s 12ms/step - loss: 0.6052 - accuracy: 0.6761 - val_loss: 0.6177 - val_accuracy: 0.6786\n",
      "Epoch 131/500\n",
      "62/62 [==============================] - 1s 12ms/step - loss: 0.5995 - accuracy: 0.6855 - val_loss: 0.6174 - val_accuracy: 0.6786\n",
      "Epoch 132/500\n",
      "62/62 [==============================] - 1s 13ms/step - loss: 0.6058 - accuracy: 0.6749 - val_loss: 0.6178 - val_accuracy: 0.6798\n",
      "Epoch 133/500\n",
      "62/62 [==============================] - 1s 12ms/step - loss: 0.5985 - accuracy: 0.6829 - val_loss: 0.6165 - val_accuracy: 0.6811\n",
      "Epoch 134/500\n",
      "62/62 [==============================] - 1s 13ms/step - loss: 0.6002 - accuracy: 0.6822 - val_loss: 0.6160 - val_accuracy: 0.6811\n",
      "Epoch 135/500\n",
      "62/62 [==============================] - 1s 12ms/step - loss: 0.5950 - accuracy: 0.6900 - val_loss: 0.6159 - val_accuracy: 0.6811\n",
      "Epoch 136/500\n",
      "62/62 [==============================] - 1s 12ms/step - loss: 0.6006 - accuracy: 0.6764 - val_loss: 0.6162 - val_accuracy: 0.6811\n",
      "Epoch 137/500\n",
      "62/62 [==============================] - 1s 12ms/step - loss: 0.5970 - accuracy: 0.6913 - val_loss: 0.6150 - val_accuracy: 0.6824\n",
      "Epoch 138/500\n",
      "62/62 [==============================] - 1s 13ms/step - loss: 0.5987 - accuracy: 0.6860 - val_loss: 0.6148 - val_accuracy: 0.6811\n",
      "Epoch 139/500\n",
      "62/62 [==============================] - 1s 12ms/step - loss: 0.5987 - accuracy: 0.6832 - val_loss: 0.6157 - val_accuracy: 0.6811\n",
      "Epoch 140/500\n",
      "62/62 [==============================] - 1s 12ms/step - loss: 0.5956 - accuracy: 0.6928 - val_loss: 0.6155 - val_accuracy: 0.6837\n",
      "Epoch 141/500\n",
      "62/62 [==============================] - 1s 12ms/step - loss: 0.5953 - accuracy: 0.6916 - val_loss: 0.6145 - val_accuracy: 0.6849\n",
      "Epoch 142/500\n",
      "62/62 [==============================] - 1s 12ms/step - loss: 0.6025 - accuracy: 0.6842 - val_loss: 0.6153 - val_accuracy: 0.6837\n",
      "Epoch 143/500\n",
      "62/62 [==============================] - 1s 12ms/step - loss: 0.5971 - accuracy: 0.6842 - val_loss: 0.6172 - val_accuracy: 0.6798\n",
      "Epoch 144/500\n",
      "62/62 [==============================] - 1s 13ms/step - loss: 0.5964 - accuracy: 0.6858 - val_loss: 0.6161 - val_accuracy: 0.6837\n",
      "Epoch 145/500\n",
      "62/62 [==============================] - 1s 13ms/step - loss: 0.5934 - accuracy: 0.6957 - val_loss: 0.6157 - val_accuracy: 0.6824\n",
      "Epoch 146/500\n",
      "62/62 [==============================] - 1s 12ms/step - loss: 0.5954 - accuracy: 0.6905 - val_loss: 0.6164 - val_accuracy: 0.6837\n",
      "Epoch 147/500\n",
      "62/62 [==============================] - 1s 13ms/step - loss: 0.5955 - accuracy: 0.6822 - val_loss: 0.6162 - val_accuracy: 0.6837\n",
      "Epoch 148/500\n",
      "62/62 [==============================] - 1s 13ms/step - loss: 0.5952 - accuracy: 0.6818 - val_loss: 0.6164 - val_accuracy: 0.6824\n",
      "Epoch 149/500\n",
      "62/62 [==============================] - 1s 13ms/step - loss: 0.5974 - accuracy: 0.6841 - val_loss: 0.6179 - val_accuracy: 0.6824\n",
      "Epoch 150/500\n",
      "62/62 [==============================] - 1s 13ms/step - loss: 0.5964 - accuracy: 0.6852 - val_loss: 0.6162 - val_accuracy: 0.6875\n",
      "Epoch 151/500\n",
      "62/62 [==============================] - 1s 12ms/step - loss: 0.5958 - accuracy: 0.6846 - val_loss: 0.6170 - val_accuracy: 0.6849\n",
      "Epoch 152/500\n",
      "62/62 [==============================] - 1s 13ms/step - loss: 0.5933 - accuracy: 0.6895 - val_loss: 0.6169 - val_accuracy: 0.6824\n",
      "Epoch 153/500\n",
      "62/62 [==============================] - 1s 13ms/step - loss: 0.5962 - accuracy: 0.6841 - val_loss: 0.6159 - val_accuracy: 0.6811\n",
      "Epoch 154/500\n",
      "62/62 [==============================] - 1s 13ms/step - loss: 0.6024 - accuracy: 0.6822 - val_loss: 0.6151 - val_accuracy: 0.6875\n",
      "Epoch 155/500\n",
      "62/62 [==============================] - 1s 12ms/step - loss: 0.5949 - accuracy: 0.6836 - val_loss: 0.6143 - val_accuracy: 0.6901\n",
      "Epoch 156/500\n",
      "62/62 [==============================] - 1s 13ms/step - loss: 0.5956 - accuracy: 0.6921 - val_loss: 0.6132 - val_accuracy: 0.6888\n",
      "Epoch 157/500\n",
      "62/62 [==============================] - 1s 12ms/step - loss: 0.5954 - accuracy: 0.6866 - val_loss: 0.6147 - val_accuracy: 0.6811\n",
      "Epoch 158/500\n",
      "62/62 [==============================] - 1s 13ms/step - loss: 0.5925 - accuracy: 0.6881 - val_loss: 0.6139 - val_accuracy: 0.6862\n",
      "Epoch 159/500\n",
      "62/62 [==============================] - 1s 12ms/step - loss: 0.5954 - accuracy: 0.6852 - val_loss: 0.6142 - val_accuracy: 0.6888\n",
      "Epoch 160/500\n",
      "62/62 [==============================] - 1s 13ms/step - loss: 0.5930 - accuracy: 0.6907 - val_loss: 0.6163 - val_accuracy: 0.6888\n",
      "Epoch 161/500\n",
      "62/62 [==============================] - 1s 12ms/step - loss: 0.5907 - accuracy: 0.6920 - val_loss: 0.6161 - val_accuracy: 0.6913\n",
      "Epoch 162/500\n",
      "62/62 [==============================] - 1s 13ms/step - loss: 0.5907 - accuracy: 0.6959 - val_loss: 0.6162 - val_accuracy: 0.6901\n",
      "Epoch 163/500\n",
      "62/62 [==============================] - 1s 13ms/step - loss: 0.5953 - accuracy: 0.6920 - val_loss: 0.6156 - val_accuracy: 0.6862\n",
      "Epoch 164/500\n",
      "62/62 [==============================] - 1s 12ms/step - loss: 0.5894 - accuracy: 0.6923 - val_loss: 0.6150 - val_accuracy: 0.6875\n",
      "Epoch 165/500\n",
      "62/62 [==============================] - 1s 13ms/step - loss: 0.5882 - accuracy: 0.6924 - val_loss: 0.6164 - val_accuracy: 0.6888\n",
      "Epoch 166/500\n",
      "62/62 [==============================] - 1s 12ms/step - loss: 0.5864 - accuracy: 0.6916 - val_loss: 0.6169 - val_accuracy: 0.6901\n",
      "Epoch 167/500\n",
      "62/62 [==============================] - 1s 13ms/step - loss: 0.5927 - accuracy: 0.6866 - val_loss: 0.6157 - val_accuracy: 0.6913\n",
      "Epoch 168/500\n",
      "62/62 [==============================] - 1s 12ms/step - loss: 0.5922 - accuracy: 0.6834 - val_loss: 0.6158 - val_accuracy: 0.6875\n",
      "Epoch 169/500\n",
      "62/62 [==============================] - 1s 12ms/step - loss: 0.5944 - accuracy: 0.6853 - val_loss: 0.6132 - val_accuracy: 0.6862\n",
      "Epoch 170/500\n",
      "62/62 [==============================] - 1s 12ms/step - loss: 0.5946 - accuracy: 0.6886 - val_loss: 0.6140 - val_accuracy: 0.6888\n",
      "Epoch 171/500\n",
      "62/62 [==============================] - 1s 13ms/step - loss: 0.5910 - accuracy: 0.6886 - val_loss: 0.6138 - val_accuracy: 0.6875\n",
      "Epoch 172/500\n",
      "62/62 [==============================] - 1s 12ms/step - loss: 0.5875 - accuracy: 0.6994 - val_loss: 0.6153 - val_accuracy: 0.6875\n",
      "Epoch 173/500\n",
      "62/62 [==============================] - 1s 13ms/step - loss: 0.5913 - accuracy: 0.6896 - val_loss: 0.6151 - val_accuracy: 0.6875\n",
      "Epoch 174/500\n",
      "62/62 [==============================] - 1s 12ms/step - loss: 0.5888 - accuracy: 0.6902 - val_loss: 0.6162 - val_accuracy: 0.6926\n",
      "Epoch 175/500\n",
      "62/62 [==============================] - 1s 13ms/step - loss: 0.5896 - accuracy: 0.6916 - val_loss: 0.6149 - val_accuracy: 0.6837\n",
      "Epoch 176/500\n",
      "62/62 [==============================] - 1s 12ms/step - loss: 0.5946 - accuracy: 0.6863 - val_loss: 0.6163 - val_accuracy: 0.6849\n",
      "Epoch 177/500\n",
      "62/62 [==============================] - 1s 12ms/step - loss: 0.5942 - accuracy: 0.6865 - val_loss: 0.6169 - val_accuracy: 0.6824\n",
      "Epoch 178/500\n",
      "62/62 [==============================] - 1s 12ms/step - loss: 0.5849 - accuracy: 0.6982 - val_loss: 0.6140 - val_accuracy: 0.6862\n",
      "Epoch 179/500\n",
      "62/62 [==============================] - 1s 13ms/step - loss: 0.5880 - accuracy: 0.6934 - val_loss: 0.6140 - val_accuracy: 0.6875\n",
      "Epoch 180/500\n",
      "62/62 [==============================] - 1s 12ms/step - loss: 0.5905 - accuracy: 0.6944 - val_loss: 0.6127 - val_accuracy: 0.6875\n",
      "Epoch 181/500\n",
      "62/62 [==============================] - 1s 13ms/step - loss: 0.5878 - accuracy: 0.6902 - val_loss: 0.6134 - val_accuracy: 0.6849\n",
      "Epoch 182/500\n",
      "62/62 [==============================] - 1s 13ms/step - loss: 0.5916 - accuracy: 0.6925 - val_loss: 0.6148 - val_accuracy: 0.6862\n",
      "Epoch 183/500\n",
      "62/62 [==============================] - 1s 13ms/step - loss: 0.5847 - accuracy: 0.6984 - val_loss: 0.6172 - val_accuracy: 0.6849\n",
      "Epoch 184/500\n",
      "62/62 [==============================] - 1s 12ms/step - loss: 0.5880 - accuracy: 0.6926 - val_loss: 0.6186 - val_accuracy: 0.6811\n",
      "Epoch 185/500\n",
      "62/62 [==============================] - 1s 13ms/step - loss: 0.5835 - accuracy: 0.6913 - val_loss: 0.6177 - val_accuracy: 0.6862\n",
      "Epoch 186/500\n",
      "62/62 [==============================] - 1s 12ms/step - loss: 0.5917 - accuracy: 0.6865 - val_loss: 0.6189 - val_accuracy: 0.6798\n",
      "Epoch 187/500\n",
      "62/62 [==============================] - 1s 12ms/step - loss: 0.5933 - accuracy: 0.6815 - val_loss: 0.6180 - val_accuracy: 0.6786\n",
      "Epoch 188/500\n",
      "62/62 [==============================] - 1s 12ms/step - loss: 0.5894 - accuracy: 0.6901 - val_loss: 0.6163 - val_accuracy: 0.6849\n",
      "Epoch 189/500\n",
      "62/62 [==============================] - 1s 13ms/step - loss: 0.5921 - accuracy: 0.6892 - val_loss: 0.6166 - val_accuracy: 0.6824\n",
      "Epoch 190/500\n",
      "62/62 [==============================] - 1s 13ms/step - loss: 0.5877 - accuracy: 0.6969 - val_loss: 0.6148 - val_accuracy: 0.6811\n",
      "Epoch 191/500\n",
      "62/62 [==============================] - 1s 13ms/step - loss: 0.5879 - accuracy: 0.6981 - val_loss: 0.6162 - val_accuracy: 0.6811\n",
      "Epoch 192/500\n",
      "62/62 [==============================] - 1s 13ms/step - loss: 0.5900 - accuracy: 0.6919 - val_loss: 0.6164 - val_accuracy: 0.6837\n",
      "Epoch 193/500\n",
      "62/62 [==============================] - 1s 12ms/step - loss: 0.5863 - accuracy: 0.6969 - val_loss: 0.6157 - val_accuracy: 0.6849\n",
      "Epoch 194/500\n",
      "62/62 [==============================] - 1s 13ms/step - loss: 0.5891 - accuracy: 0.6936 - val_loss: 0.6147 - val_accuracy: 0.6798\n",
      "Epoch 195/500\n",
      "62/62 [==============================] - 1s 12ms/step - loss: 0.5867 - accuracy: 0.6978 - val_loss: 0.6160 - val_accuracy: 0.6837\n",
      "Epoch 196/500\n",
      "62/62 [==============================] - 1s 13ms/step - loss: 0.5888 - accuracy: 0.6894 - val_loss: 0.6132 - val_accuracy: 0.6875\n",
      "Epoch 197/500\n",
      "62/62 [==============================] - 1s 13ms/step - loss: 0.5835 - accuracy: 0.6958 - val_loss: 0.6158 - val_accuracy: 0.6811\n",
      "Epoch 198/500\n",
      "62/62 [==============================] - 1s 12ms/step - loss: 0.5861 - accuracy: 0.6977 - val_loss: 0.6162 - val_accuracy: 0.6824\n",
      "Epoch 199/500\n",
      "62/62 [==============================] - 1s 12ms/step - loss: 0.5910 - accuracy: 0.6914 - val_loss: 0.6155 - val_accuracy: 0.6824\n",
      "Epoch 200/500\n",
      "62/62 [==============================] - 1s 13ms/step - loss: 0.5876 - accuracy: 0.6918 - val_loss: 0.6152 - val_accuracy: 0.6824\n",
      "Epoch 201/500\n",
      "62/62 [==============================] - 1s 13ms/step - loss: 0.5855 - accuracy: 0.6887 - val_loss: 0.6137 - val_accuracy: 0.6824\n",
      "Epoch 202/500\n",
      "62/62 [==============================] - 1s 12ms/step - loss: 0.5909 - accuracy: 0.6920 - val_loss: 0.6154 - val_accuracy: 0.6837\n",
      "Epoch 203/500\n",
      "62/62 [==============================] - 1s 13ms/step - loss: 0.5835 - accuracy: 0.6919 - val_loss: 0.6154 - val_accuracy: 0.6862\n",
      "Epoch 204/500\n",
      "62/62 [==============================] - 1s 12ms/step - loss: 0.5884 - accuracy: 0.6900 - val_loss: 0.6152 - val_accuracy: 0.6824\n",
      "Epoch 205/500\n",
      "62/62 [==============================] - 1s 13ms/step - loss: 0.5845 - accuracy: 0.6916 - val_loss: 0.6167 - val_accuracy: 0.6837\n",
      "Epoch 206/500\n",
      "62/62 [==============================] - 1s 12ms/step - loss: 0.5909 - accuracy: 0.6899 - val_loss: 0.6160 - val_accuracy: 0.6824\n",
      "Epoch 207/500\n",
      "62/62 [==============================] - 1s 13ms/step - loss: 0.5866 - accuracy: 0.6938 - val_loss: 0.6150 - val_accuracy: 0.6837\n",
      "Epoch 208/500\n",
      "62/62 [==============================] - 1s 12ms/step - loss: 0.5802 - accuracy: 0.6969 - val_loss: 0.6160 - val_accuracy: 0.6849\n",
      "Epoch 209/500\n",
      "62/62 [==============================] - 1s 13ms/step - loss: 0.5792 - accuracy: 0.6989 - val_loss: 0.6169 - val_accuracy: 0.6837\n",
      "Epoch 210/500\n",
      "62/62 [==============================] - 1s 13ms/step - loss: 0.5874 - accuracy: 0.6981 - val_loss: 0.6172 - val_accuracy: 0.6824\n",
      "Epoch 211/500\n",
      "62/62 [==============================] - 1s 13ms/step - loss: 0.5823 - accuracy: 0.6983 - val_loss: 0.6163 - val_accuracy: 0.6849\n",
      "Epoch 212/500\n",
      "62/62 [==============================] - 1s 12ms/step - loss: 0.5851 - accuracy: 0.6931 - val_loss: 0.6167 - val_accuracy: 0.6824\n",
      "Epoch 213/500\n",
      "62/62 [==============================] - 1s 13ms/step - loss: 0.5846 - accuracy: 0.6950 - val_loss: 0.6158 - val_accuracy: 0.6824\n",
      "Epoch 214/500\n",
      "62/62 [==============================] - 1s 12ms/step - loss: 0.5783 - accuracy: 0.6996 - val_loss: 0.6169 - val_accuracy: 0.6798\n",
      "Epoch 215/500\n",
      "62/62 [==============================] - 1s 13ms/step - loss: 0.5813 - accuracy: 0.6955 - val_loss: 0.6159 - val_accuracy: 0.6798\n",
      "Epoch 216/500\n",
      "62/62 [==============================] - 1s 13ms/step - loss: 0.5816 - accuracy: 0.7023 - val_loss: 0.6164 - val_accuracy: 0.6786\n",
      "Epoch 217/500\n",
      "62/62 [==============================] - 1s 13ms/step - loss: 0.5795 - accuracy: 0.6976 - val_loss: 0.6161 - val_accuracy: 0.6811\n",
      "Epoch 218/500\n",
      "62/62 [==============================] - 1s 13ms/step - loss: 0.5815 - accuracy: 0.6978 - val_loss: 0.6175 - val_accuracy: 0.6837\n",
      "Epoch 219/500\n",
      "62/62 [==============================] - 1s 13ms/step - loss: 0.5784 - accuracy: 0.7034 - val_loss: 0.6156 - val_accuracy: 0.6798\n",
      "Epoch 220/500\n",
      "62/62 [==============================] - 1s 13ms/step - loss: 0.5885 - accuracy: 0.6925 - val_loss: 0.6163 - val_accuracy: 0.6811\n",
      "Epoch 221/500\n",
      "62/62 [==============================] - 1s 13ms/step - loss: 0.5862 - accuracy: 0.6949 - val_loss: 0.6143 - val_accuracy: 0.6875\n",
      "Epoch 222/500\n",
      "62/62 [==============================] - 1s 13ms/step - loss: 0.5841 - accuracy: 0.6986 - val_loss: 0.6161 - val_accuracy: 0.6824\n",
      "Epoch 223/500\n",
      "62/62 [==============================] - 1s 12ms/step - loss: 0.5874 - accuracy: 0.6926 - val_loss: 0.6154 - val_accuracy: 0.6824\n",
      "Epoch 224/500\n",
      "62/62 [==============================] - 1s 12ms/step - loss: 0.5808 - accuracy: 0.7031 - val_loss: 0.6154 - val_accuracy: 0.6849\n",
      "Epoch 225/500\n",
      "62/62 [==============================] - 1s 13ms/step - loss: 0.5875 - accuracy: 0.6921 - val_loss: 0.6159 - val_accuracy: 0.6837\n",
      "Epoch 226/500\n",
      "62/62 [==============================] - 1s 12ms/step - loss: 0.5817 - accuracy: 0.6958 - val_loss: 0.6142 - val_accuracy: 0.6862\n",
      "Epoch 227/500\n",
      "62/62 [==============================] - 1s 12ms/step - loss: 0.5811 - accuracy: 0.7013 - val_loss: 0.6152 - val_accuracy: 0.6849\n",
      "Epoch 228/500\n",
      "62/62 [==============================] - 1s 13ms/step - loss: 0.5799 - accuracy: 0.7002 - val_loss: 0.6158 - val_accuracy: 0.6837\n",
      "Epoch 229/500\n",
      "62/62 [==============================] - 1s 12ms/step - loss: 0.5787 - accuracy: 0.6989 - val_loss: 0.6158 - val_accuracy: 0.6849\n",
      "Epoch 230/500\n",
      "62/62 [==============================] - 1s 13ms/step - loss: 0.5791 - accuracy: 0.6967 - val_loss: 0.6167 - val_accuracy: 0.6798\n",
      "Epoch 231/500\n",
      "62/62 [==============================] - 1s 12ms/step - loss: 0.5832 - accuracy: 0.6978 - val_loss: 0.6180 - val_accuracy: 0.6798\n",
      "Epoch 232/500\n",
      "62/62 [==============================] - 1s 13ms/step - loss: 0.5829 - accuracy: 0.6936 - val_loss: 0.6171 - val_accuracy: 0.6811\n",
      "Epoch 233/500\n",
      "62/62 [==============================] - 1s 13ms/step - loss: 0.5816 - accuracy: 0.6952 - val_loss: 0.6152 - val_accuracy: 0.6862\n",
      "Epoch 234/500\n",
      "62/62 [==============================] - 1s 13ms/step - loss: 0.5768 - accuracy: 0.6992 - val_loss: 0.6159 - val_accuracy: 0.6849\n",
      "Epoch 235/500\n",
      "62/62 [==============================] - 1s 12ms/step - loss: 0.5812 - accuracy: 0.6967 - val_loss: 0.6171 - val_accuracy: 0.6875\n",
      "Epoch 236/500\n",
      "62/62 [==============================] - 1s 13ms/step - loss: 0.5807 - accuracy: 0.6984 - val_loss: 0.6161 - val_accuracy: 0.6837\n",
      "Epoch 237/500\n",
      "62/62 [==============================] - 1s 12ms/step - loss: 0.5827 - accuracy: 0.6965 - val_loss: 0.6181 - val_accuracy: 0.6849\n",
      "Epoch 238/500\n",
      "62/62 [==============================] - 1s 12ms/step - loss: 0.5810 - accuracy: 0.6981 - val_loss: 0.6172 - val_accuracy: 0.6849\n",
      "Epoch 239/500\n",
      "62/62 [==============================] - 1s 13ms/step - loss: 0.5794 - accuracy: 0.6963 - val_loss: 0.6162 - val_accuracy: 0.6798\n",
      "Epoch 240/500\n",
      "62/62 [==============================] - 1s 12ms/step - loss: 0.5793 - accuracy: 0.6957 - val_loss: 0.6163 - val_accuracy: 0.6837\n",
      "Epoch 241/500\n",
      "62/62 [==============================] - 1s 12ms/step - loss: 0.5801 - accuracy: 0.6976 - val_loss: 0.6162 - val_accuracy: 0.6773\n",
      "Epoch 242/500\n",
      "62/62 [==============================] - 1s 13ms/step - loss: 0.5815 - accuracy: 0.6991 - val_loss: 0.6163 - val_accuracy: 0.6786\n",
      "Epoch 243/500\n",
      "62/62 [==============================] - 1s 14ms/step - loss: 0.5781 - accuracy: 0.7045 - val_loss: 0.6177 - val_accuracy: 0.6798\n",
      "Epoch 244/500\n",
      "62/62 [==============================] - 1s 13ms/step - loss: 0.5797 - accuracy: 0.7017 - val_loss: 0.6169 - val_accuracy: 0.6798\n",
      "Epoch 245/500\n",
      "62/62 [==============================] - 1s 14ms/step - loss: 0.5772 - accuracy: 0.7083 - val_loss: 0.6179 - val_accuracy: 0.6824\n",
      "Epoch 246/500\n",
      "62/62 [==============================] - 1s 12ms/step - loss: 0.5790 - accuracy: 0.7023 - val_loss: 0.6164 - val_accuracy: 0.6811\n",
      "Epoch 247/500\n",
      "62/62 [==============================] - 1s 12ms/step - loss: 0.5795 - accuracy: 0.6953 - val_loss: 0.6160 - val_accuracy: 0.6811\n",
      "Epoch 248/500\n",
      "62/62 [==============================] - 1s 13ms/step - loss: 0.5776 - accuracy: 0.6972 - val_loss: 0.6180 - val_accuracy: 0.6760\n",
      "Epoch 249/500\n",
      "62/62 [==============================] - 1s 12ms/step - loss: 0.5753 - accuracy: 0.7042 - val_loss: 0.6172 - val_accuracy: 0.6824\n",
      "Epoch 250/500\n",
      "62/62 [==============================] - 1s 12ms/step - loss: 0.5815 - accuracy: 0.7027 - val_loss: 0.6158 - val_accuracy: 0.6811\n",
      "Epoch 251/500\n",
      "62/62 [==============================] - 1s 13ms/step - loss: 0.5784 - accuracy: 0.7015 - val_loss: 0.6158 - val_accuracy: 0.6773\n",
      "Epoch 252/500\n",
      "62/62 [==============================] - 1s 13ms/step - loss: 0.5790 - accuracy: 0.6938 - val_loss: 0.6163 - val_accuracy: 0.6811\n",
      "Epoch 253/500\n",
      "62/62 [==============================] - 1s 12ms/step - loss: 0.5817 - accuracy: 0.6960 - val_loss: 0.6153 - val_accuracy: 0.6837\n",
      "Epoch 254/500\n",
      "62/62 [==============================] - 1s 13ms/step - loss: 0.5773 - accuracy: 0.6970 - val_loss: 0.6173 - val_accuracy: 0.6773\n",
      "Epoch 255/500\n",
      "62/62 [==============================] - 1s 12ms/step - loss: 0.5744 - accuracy: 0.7049 - val_loss: 0.6170 - val_accuracy: 0.6786\n",
      "Epoch 256/500\n",
      "62/62 [==============================] - 1s 12ms/step - loss: 0.5754 - accuracy: 0.7030 - val_loss: 0.6190 - val_accuracy: 0.6798\n",
      "Epoch 257/500\n",
      "62/62 [==============================] - 1s 12ms/step - loss: 0.5805 - accuracy: 0.6965 - val_loss: 0.6193 - val_accuracy: 0.6773\n",
      "Epoch 258/500\n",
      "62/62 [==============================] - 1s 13ms/step - loss: 0.5747 - accuracy: 0.7047 - val_loss: 0.6190 - val_accuracy: 0.6773\n",
      "Epoch 259/500\n",
      "62/62 [==============================] - 1s 12ms/step - loss: 0.5784 - accuracy: 0.6968 - val_loss: 0.6172 - val_accuracy: 0.6786\n",
      "Epoch 260/500\n",
      "62/62 [==============================] - 1s 13ms/step - loss: 0.5792 - accuracy: 0.7040 - val_loss: 0.6169 - val_accuracy: 0.6760\n",
      "Epoch 261/500\n",
      "62/62 [==============================] - 1s 12ms/step - loss: 0.5780 - accuracy: 0.7032 - val_loss: 0.6180 - val_accuracy: 0.6824\n",
      "Epoch 262/500\n",
      "62/62 [==============================] - 1s 13ms/step - loss: 0.5765 - accuracy: 0.7031 - val_loss: 0.6178 - val_accuracy: 0.6811\n",
      "Epoch 263/500\n",
      "62/62 [==============================] - 1s 13ms/step - loss: 0.5726 - accuracy: 0.7090 - val_loss: 0.6193 - val_accuracy: 0.6811\n",
      "Epoch 264/500\n",
      "62/62 [==============================] - 1s 12ms/step - loss: 0.5812 - accuracy: 0.6982 - val_loss: 0.6184 - val_accuracy: 0.6811\n",
      "Epoch 265/500\n",
      "62/62 [==============================] - 1s 13ms/step - loss: 0.5728 - accuracy: 0.7092 - val_loss: 0.6182 - val_accuracy: 0.6786\n",
      "Epoch 266/500\n",
      "62/62 [==============================] - 1s 12ms/step - loss: 0.5781 - accuracy: 0.7010 - val_loss: 0.6172 - val_accuracy: 0.6760\n",
      "Epoch 267/500\n",
      "62/62 [==============================] - 1s 12ms/step - loss: 0.5801 - accuracy: 0.7013 - val_loss: 0.6181 - val_accuracy: 0.6786\n",
      "Epoch 268/500\n",
      "62/62 [==============================] - 1s 12ms/step - loss: 0.5774 - accuracy: 0.7023 - val_loss: 0.6208 - val_accuracy: 0.6786\n",
      "Epoch 269/500\n",
      "62/62 [==============================] - 1s 14ms/step - loss: 0.5720 - accuracy: 0.7079 - val_loss: 0.6207 - val_accuracy: 0.6735\n",
      "Epoch 270/500\n",
      "62/62 [==============================] - 1s 13ms/step - loss: 0.5765 - accuracy: 0.7044 - val_loss: 0.6202 - val_accuracy: 0.6722\n",
      "Epoch 271/500\n",
      "62/62 [==============================] - 1s 12ms/step - loss: 0.5761 - accuracy: 0.6994 - val_loss: 0.6196 - val_accuracy: 0.6747\n",
      "Epoch 272/500\n",
      "62/62 [==============================] - 1s 13ms/step - loss: 0.5782 - accuracy: 0.7007 - val_loss: 0.6185 - val_accuracy: 0.6735\n",
      "Epoch 273/500\n",
      "62/62 [==============================] - 1s 12ms/step - loss: 0.5747 - accuracy: 0.7086 - val_loss: 0.6178 - val_accuracy: 0.6760\n",
      "Epoch 274/500\n",
      "62/62 [==============================] - 1s 13ms/step - loss: 0.5762 - accuracy: 0.7011 - val_loss: 0.6183 - val_accuracy: 0.6760\n",
      "Epoch 275/500\n",
      "62/62 [==============================] - 1s 12ms/step - loss: 0.5738 - accuracy: 0.7012 - val_loss: 0.6184 - val_accuracy: 0.6773\n",
      "Epoch 276/500\n",
      "62/62 [==============================] - 1s 13ms/step - loss: 0.5777 - accuracy: 0.7006 - val_loss: 0.6188 - val_accuracy: 0.6773\n",
      "Epoch 277/500\n",
      "62/62 [==============================] - 1s 12ms/step - loss: 0.5721 - accuracy: 0.7042 - val_loss: 0.6202 - val_accuracy: 0.6786\n",
      "Epoch 278/500\n",
      "62/62 [==============================] - 1s 13ms/step - loss: 0.5773 - accuracy: 0.7012 - val_loss: 0.6208 - val_accuracy: 0.6811\n",
      "Epoch 279/500\n",
      "62/62 [==============================] - 1s 12ms/step - loss: 0.5772 - accuracy: 0.6997 - val_loss: 0.6207 - val_accuracy: 0.6811\n",
      "Epoch 280/500\n",
      "62/62 [==============================] - 1s 12ms/step - loss: 0.5747 - accuracy: 0.6968 - val_loss: 0.6188 - val_accuracy: 0.6811\n",
      "Epoch 281/500\n",
      "62/62 [==============================] - 1s 13ms/step - loss: 0.5800 - accuracy: 0.6991 - val_loss: 0.6171 - val_accuracy: 0.6760\n",
      "Epoch 282/500\n",
      "62/62 [==============================] - 1s 12ms/step - loss: 0.5743 - accuracy: 0.6999 - val_loss: 0.6175 - val_accuracy: 0.6760\n",
      "Epoch 283/500\n",
      "62/62 [==============================] - 1s 13ms/step - loss: 0.5695 - accuracy: 0.7054 - val_loss: 0.6173 - val_accuracy: 0.6786\n",
      "Epoch 284/500\n",
      "62/62 [==============================] - 1s 12ms/step - loss: 0.5721 - accuracy: 0.7100 - val_loss: 0.6181 - val_accuracy: 0.6811\n",
      "Epoch 285/500\n",
      "62/62 [==============================] - 1s 13ms/step - loss: 0.5746 - accuracy: 0.7075 - val_loss: 0.6180 - val_accuracy: 0.6773\n",
      "Epoch 286/500\n",
      "62/62 [==============================] - 1s 13ms/step - loss: 0.5736 - accuracy: 0.7075 - val_loss: 0.6181 - val_accuracy: 0.6811\n",
      "Epoch 287/500\n",
      "62/62 [==============================] - 1s 13ms/step - loss: 0.5719 - accuracy: 0.7092 - val_loss: 0.6169 - val_accuracy: 0.6773\n",
      "Epoch 288/500\n",
      "62/62 [==============================] - 1s 13ms/step - loss: 0.5723 - accuracy: 0.7056 - val_loss: 0.6172 - val_accuracy: 0.6798\n",
      "Epoch 289/500\n",
      "62/62 [==============================] - 1s 12ms/step - loss: 0.5775 - accuracy: 0.7039 - val_loss: 0.6170 - val_accuracy: 0.6773\n",
      "Epoch 290/500\n",
      "62/62 [==============================] - 1s 13ms/step - loss: 0.5730 - accuracy: 0.7030 - val_loss: 0.6160 - val_accuracy: 0.6837\n",
      "Epoch 291/500\n",
      "62/62 [==============================] - 1s 12ms/step - loss: 0.5742 - accuracy: 0.7030 - val_loss: 0.6159 - val_accuracy: 0.6798\n",
      "Epoch 292/500\n",
      "62/62 [==============================] - 1s 12ms/step - loss: 0.5746 - accuracy: 0.7013 - val_loss: 0.6178 - val_accuracy: 0.6773\n",
      "Epoch 293/500\n",
      "62/62 [==============================] - 1s 13ms/step - loss: 0.5749 - accuracy: 0.7060 - val_loss: 0.6178 - val_accuracy: 0.6786\n",
      "Epoch 294/500\n",
      "62/62 [==============================] - 1s 12ms/step - loss: 0.5693 - accuracy: 0.7089 - val_loss: 0.6180 - val_accuracy: 0.6798\n",
      "Epoch 295/500\n",
      "62/62 [==============================] - 1s 12ms/step - loss: 0.5710 - accuracy: 0.7080 - val_loss: 0.6172 - val_accuracy: 0.6811\n",
      "Epoch 296/500\n",
      "62/62 [==============================] - 1s 13ms/step - loss: 0.5732 - accuracy: 0.7005 - val_loss: 0.6188 - val_accuracy: 0.6811\n",
      "Epoch 297/500\n",
      "62/62 [==============================] - 1s 12ms/step - loss: 0.5675 - accuracy: 0.7060 - val_loss: 0.6193 - val_accuracy: 0.6786\n",
      "Epoch 298/500\n",
      "62/62 [==============================] - 1s 12ms/step - loss: 0.5692 - accuracy: 0.7065 - val_loss: 0.6200 - val_accuracy: 0.6760\n",
      "Epoch 299/500\n",
      "62/62 [==============================] - 1s 13ms/step - loss: 0.5702 - accuracy: 0.7065 - val_loss: 0.6188 - val_accuracy: 0.6786\n",
      "Epoch 300/500\n",
      "62/62 [==============================] - 1s 13ms/step - loss: 0.5720 - accuracy: 0.7083 - val_loss: 0.6189 - val_accuracy: 0.6862\n",
      "Epoch 301/500\n",
      "62/62 [==============================] - 1s 12ms/step - loss: 0.5666 - accuracy: 0.7098 - val_loss: 0.6189 - val_accuracy: 0.6875\n",
      "Epoch 302/500\n",
      "62/62 [==============================] - 1s 14ms/step - loss: 0.5672 - accuracy: 0.7138 - val_loss: 0.6195 - val_accuracy: 0.6824\n",
      "Epoch 303/500\n",
      "62/62 [==============================] - 1s 12ms/step - loss: 0.5726 - accuracy: 0.7032 - val_loss: 0.6173 - val_accuracy: 0.6824\n",
      "Epoch 304/500\n",
      "62/62 [==============================] - 1s 13ms/step - loss: 0.5671 - accuracy: 0.7076 - val_loss: 0.6182 - val_accuracy: 0.6862\n",
      "Epoch 305/500\n",
      "62/62 [==============================] - 1s 12ms/step - loss: 0.5659 - accuracy: 0.7123 - val_loss: 0.6197 - val_accuracy: 0.6773\n",
      "Epoch 306/500\n",
      "62/62 [==============================] - 1s 12ms/step - loss: 0.5669 - accuracy: 0.7128 - val_loss: 0.6188 - val_accuracy: 0.6862\n",
      "Epoch 307/500\n",
      "62/62 [==============================] - 1s 12ms/step - loss: 0.5738 - accuracy: 0.7005 - val_loss: 0.6179 - val_accuracy: 0.6849\n",
      "Epoch 308/500\n",
      "62/62 [==============================] - 1s 13ms/step - loss: 0.5658 - accuracy: 0.7105 - val_loss: 0.6200 - val_accuracy: 0.6798\n",
      "Epoch 309/500\n",
      "62/62 [==============================] - 1s 13ms/step - loss: 0.5702 - accuracy: 0.7074 - val_loss: 0.6197 - val_accuracy: 0.6798\n",
      "Epoch 310/500\n",
      "62/62 [==============================] - 1s 12ms/step - loss: 0.5758 - accuracy: 0.7035 - val_loss: 0.6184 - val_accuracy: 0.6862\n",
      "Epoch 311/500\n",
      "62/62 [==============================] - 1s 13ms/step - loss: 0.5726 - accuracy: 0.7060 - val_loss: 0.6172 - val_accuracy: 0.6837\n",
      "Epoch 312/500\n",
      "62/62 [==============================] - 1s 12ms/step - loss: 0.5689 - accuracy: 0.7071 - val_loss: 0.6191 - val_accuracy: 0.6760\n",
      "Epoch 313/500\n",
      "62/62 [==============================] - 1s 12ms/step - loss: 0.5660 - accuracy: 0.7144 - val_loss: 0.6186 - val_accuracy: 0.6735\n",
      "Epoch 314/500\n",
      "62/62 [==============================] - 1s 12ms/step - loss: 0.5693 - accuracy: 0.7105 - val_loss: 0.6179 - val_accuracy: 0.6747\n",
      "Epoch 315/500\n",
      "62/62 [==============================] - 1s 13ms/step - loss: 0.5690 - accuracy: 0.7063 - val_loss: 0.6195 - val_accuracy: 0.6811\n",
      "Epoch 316/500\n",
      "62/62 [==============================] - 1s 13ms/step - loss: 0.5685 - accuracy: 0.7084 - val_loss: 0.6194 - val_accuracy: 0.6760\n",
      "Epoch 317/500\n",
      "62/62 [==============================] - 1s 13ms/step - loss: 0.5623 - accuracy: 0.7105 - val_loss: 0.6197 - val_accuracy: 0.6747\n",
      "Epoch 318/500\n",
      "62/62 [==============================] - 1s 13ms/step - loss: 0.5663 - accuracy: 0.7100 - val_loss: 0.6211 - val_accuracy: 0.6722\n",
      "Epoch 319/500\n",
      "62/62 [==============================] - 1s 12ms/step - loss: 0.5683 - accuracy: 0.7102 - val_loss: 0.6204 - val_accuracy: 0.6709\n",
      "Epoch 320/500\n",
      "62/62 [==============================] - 1s 13ms/step - loss: 0.5659 - accuracy: 0.7146 - val_loss: 0.6186 - val_accuracy: 0.6747\n",
      "Epoch 321/500\n",
      "62/62 [==============================] - 1s 13ms/step - loss: 0.5684 - accuracy: 0.7090 - val_loss: 0.6172 - val_accuracy: 0.6786\n",
      "Epoch 322/500\n",
      "62/62 [==============================] - 1s 12ms/step - loss: 0.5686 - accuracy: 0.7115 - val_loss: 0.6180 - val_accuracy: 0.6811\n",
      "Epoch 323/500\n",
      "62/62 [==============================] - 1s 13ms/step - loss: 0.5642 - accuracy: 0.7132 - val_loss: 0.6182 - val_accuracy: 0.6786\n",
      "Epoch 324/500\n",
      "62/62 [==============================] - 1s 12ms/step - loss: 0.5768 - accuracy: 0.7026 - val_loss: 0.6174 - val_accuracy: 0.6786\n",
      "Epoch 325/500\n",
      "62/62 [==============================] - 1s 12ms/step - loss: 0.5719 - accuracy: 0.7055 - val_loss: 0.6167 - val_accuracy: 0.6786\n",
      "Epoch 326/500\n",
      "62/62 [==============================] - 1s 13ms/step - loss: 0.5712 - accuracy: 0.7078 - val_loss: 0.6168 - val_accuracy: 0.6786\n",
      "Epoch 327/500\n",
      "62/62 [==============================] - 1s 12ms/step - loss: 0.5715 - accuracy: 0.7045 - val_loss: 0.6170 - val_accuracy: 0.6760\n",
      "Epoch 328/500\n",
      "62/62 [==============================] - 1s 12ms/step - loss: 0.5672 - accuracy: 0.7113 - val_loss: 0.6180 - val_accuracy: 0.6747\n",
      "Epoch 329/500\n",
      "62/62 [==============================] - 1s 13ms/step - loss: 0.5673 - accuracy: 0.7079 - val_loss: 0.6174 - val_accuracy: 0.6798\n",
      "Epoch 330/500\n",
      "62/62 [==============================] - 1s 13ms/step - loss: 0.5672 - accuracy: 0.7129 - val_loss: 0.6180 - val_accuracy: 0.6773\n",
      "Epoch 331/500\n",
      "62/62 [==============================] - 1s 13ms/step - loss: 0.5705 - accuracy: 0.7100 - val_loss: 0.6195 - val_accuracy: 0.6760\n",
      "Epoch 332/500\n",
      "62/62 [==============================] - 1s 12ms/step - loss: 0.5666 - accuracy: 0.7093 - val_loss: 0.6207 - val_accuracy: 0.6747\n",
      "Epoch 333/500\n",
      "62/62 [==============================] - 1s 12ms/step - loss: 0.5696 - accuracy: 0.7099 - val_loss: 0.6192 - val_accuracy: 0.6722\n",
      "Epoch 334/500\n",
      "62/62 [==============================] - 1s 12ms/step - loss: 0.5714 - accuracy: 0.7050 - val_loss: 0.6184 - val_accuracy: 0.6722\n",
      "Epoch 335/500\n",
      "62/62 [==============================] - 1s 13ms/step - loss: 0.5652 - accuracy: 0.7099 - val_loss: 0.6196 - val_accuracy: 0.6760\n",
      "Epoch 336/500\n",
      "62/62 [==============================] - 1s 13ms/step - loss: 0.5737 - accuracy: 0.7064 - val_loss: 0.6180 - val_accuracy: 0.6798\n",
      "Epoch 337/500\n",
      "62/62 [==============================] - 1s 12ms/step - loss: 0.5618 - accuracy: 0.7146 - val_loss: 0.6191 - val_accuracy: 0.6709\n",
      "Epoch 338/500\n",
      "62/62 [==============================] - 1s 13ms/step - loss: 0.5697 - accuracy: 0.7078 - val_loss: 0.6185 - val_accuracy: 0.6773\n",
      "Epoch 339/500\n",
      "62/62 [==============================] - 1s 13ms/step - loss: 0.5721 - accuracy: 0.7054 - val_loss: 0.6179 - val_accuracy: 0.6798\n",
      "Epoch 340/500\n",
      "62/62 [==============================] - 1s 12ms/step - loss: 0.5707 - accuracy: 0.7023 - val_loss: 0.6173 - val_accuracy: 0.6773\n",
      "Epoch 341/500\n",
      "62/62 [==============================] - 1s 13ms/step - loss: 0.5696 - accuracy: 0.7078 - val_loss: 0.6189 - val_accuracy: 0.6760\n",
      "Epoch 342/500\n",
      "62/62 [==============================] - 1s 12ms/step - loss: 0.5651 - accuracy: 0.7090 - val_loss: 0.6188 - val_accuracy: 0.6760\n",
      "Epoch 343/500\n",
      "62/62 [==============================] - 1s 12ms/step - loss: 0.5617 - accuracy: 0.7105 - val_loss: 0.6212 - val_accuracy: 0.6798\n",
      "Epoch 344/500\n",
      "62/62 [==============================] - 1s 13ms/step - loss: 0.5676 - accuracy: 0.7078 - val_loss: 0.6198 - val_accuracy: 0.6811\n",
      "Epoch 345/500\n",
      "62/62 [==============================] - 1s 12ms/step - loss: 0.5631 - accuracy: 0.7134 - val_loss: 0.6200 - val_accuracy: 0.6760\n",
      "Epoch 346/500\n",
      "62/62 [==============================] - 1s 13ms/step - loss: 0.5669 - accuracy: 0.7088 - val_loss: 0.6191 - val_accuracy: 0.6786\n",
      "Epoch 347/500\n",
      "62/62 [==============================] - 1s 14ms/step - loss: 0.5660 - accuracy: 0.7132 - val_loss: 0.6210 - val_accuracy: 0.6798\n",
      "Epoch 348/500\n",
      "62/62 [==============================] - 1s 12ms/step - loss: 0.5613 - accuracy: 0.7118 - val_loss: 0.6202 - val_accuracy: 0.6773\n",
      "Epoch 349/500\n",
      "62/62 [==============================] - 1s 13ms/step - loss: 0.5667 - accuracy: 0.7088 - val_loss: 0.6183 - val_accuracy: 0.6760\n",
      "Epoch 350/500\n",
      "62/62 [==============================] - 1s 13ms/step - loss: 0.5631 - accuracy: 0.7138 - val_loss: 0.6190 - val_accuracy: 0.6786\n",
      "Epoch 351/500\n",
      "62/62 [==============================] - 1s 12ms/step - loss: 0.5664 - accuracy: 0.7094 - val_loss: 0.6203 - val_accuracy: 0.6722\n",
      "Epoch 352/500\n",
      "62/62 [==============================] - 1s 13ms/step - loss: 0.5652 - accuracy: 0.7075 - val_loss: 0.6177 - val_accuracy: 0.6735\n",
      "Epoch 353/500\n",
      "62/62 [==============================] - 1s 13ms/step - loss: 0.5650 - accuracy: 0.7113 - val_loss: 0.6190 - val_accuracy: 0.6760\n",
      "Epoch 354/500\n",
      "62/62 [==============================] - 1s 13ms/step - loss: 0.5572 - accuracy: 0.7185 - val_loss: 0.6189 - val_accuracy: 0.6773\n",
      "Epoch 355/500\n",
      "62/62 [==============================] - 1s 13ms/step - loss: 0.5679 - accuracy: 0.7069 - val_loss: 0.6183 - val_accuracy: 0.6824\n",
      "Epoch 356/500\n",
      "62/62 [==============================] - 1s 13ms/step - loss: 0.5647 - accuracy: 0.7052 - val_loss: 0.6188 - val_accuracy: 0.6760\n",
      "Epoch 357/500\n",
      "62/62 [==============================] - 1s 13ms/step - loss: 0.5605 - accuracy: 0.7179 - val_loss: 0.6191 - val_accuracy: 0.6786\n",
      "Epoch 358/500\n",
      "62/62 [==============================] - 1s 12ms/step - loss: 0.5608 - accuracy: 0.7153 - val_loss: 0.6205 - val_accuracy: 0.6824\n",
      "Epoch 359/500\n",
      "62/62 [==============================] - 1s 13ms/step - loss: 0.5611 - accuracy: 0.7175 - val_loss: 0.6196 - val_accuracy: 0.6786\n",
      "Epoch 360/500\n",
      "62/62 [==============================] - 1s 12ms/step - loss: 0.5602 - accuracy: 0.7148 - val_loss: 0.6196 - val_accuracy: 0.6786\n",
      "Epoch 361/500\n",
      "62/62 [==============================] - 1s 12ms/step - loss: 0.5661 - accuracy: 0.7144 - val_loss: 0.6196 - val_accuracy: 0.6786\n",
      "Epoch 362/500\n",
      "62/62 [==============================] - 1s 13ms/step - loss: 0.5636 - accuracy: 0.7089 - val_loss: 0.6170 - val_accuracy: 0.6773\n",
      "Epoch 363/500\n",
      "62/62 [==============================] - 1s 12ms/step - loss: 0.5662 - accuracy: 0.7160 - val_loss: 0.6170 - val_accuracy: 0.6760\n",
      "Epoch 364/500\n",
      "62/62 [==============================] - 1s 13ms/step - loss: 0.5654 - accuracy: 0.7104 - val_loss: 0.6165 - val_accuracy: 0.6786\n",
      "Epoch 365/500\n",
      "62/62 [==============================] - 1s 13ms/step - loss: 0.5645 - accuracy: 0.7117 - val_loss: 0.6175 - val_accuracy: 0.6786\n",
      "Epoch 366/500\n",
      "62/62 [==============================] - 1s 12ms/step - loss: 0.5608 - accuracy: 0.7104 - val_loss: 0.6177 - val_accuracy: 0.6773\n",
      "Epoch 367/500\n",
      "62/62 [==============================] - 1s 13ms/step - loss: 0.5658 - accuracy: 0.7113 - val_loss: 0.6175 - val_accuracy: 0.6773\n",
      "Epoch 368/500\n",
      "62/62 [==============================] - 1s 12ms/step - loss: 0.5578 - accuracy: 0.7143 - val_loss: 0.6194 - val_accuracy: 0.6722\n",
      "Epoch 369/500\n",
      "62/62 [==============================] - 1s 13ms/step - loss: 0.5593 - accuracy: 0.7133 - val_loss: 0.6191 - val_accuracy: 0.6735\n",
      "Epoch 370/500\n",
      "62/62 [==============================] - 1s 13ms/step - loss: 0.5592 - accuracy: 0.7139 - val_loss: 0.6185 - val_accuracy: 0.6709\n",
      "Epoch 371/500\n",
      "62/62 [==============================] - 1s 13ms/step - loss: 0.5640 - accuracy: 0.7114 - val_loss: 0.6185 - val_accuracy: 0.6722\n",
      "Epoch 372/500\n",
      "62/62 [==============================] - 1s 13ms/step - loss: 0.5558 - accuracy: 0.7176 - val_loss: 0.6196 - val_accuracy: 0.6735\n",
      "Epoch 373/500\n",
      "62/62 [==============================] - 1s 13ms/step - loss: 0.5571 - accuracy: 0.7162 - val_loss: 0.6216 - val_accuracy: 0.6735\n",
      "Epoch 374/500\n",
      "62/62 [==============================] - 1s 13ms/step - loss: 0.5587 - accuracy: 0.7097 - val_loss: 0.6218 - val_accuracy: 0.6684\n",
      "Epoch 375/500\n",
      "62/62 [==============================] - 1s 13ms/step - loss: 0.5620 - accuracy: 0.7109 - val_loss: 0.6198 - val_accuracy: 0.6709\n",
      "Epoch 376/500\n",
      "62/62 [==============================] - 1s 12ms/step - loss: 0.5637 - accuracy: 0.7094 - val_loss: 0.6202 - val_accuracy: 0.6696\n",
      "Epoch 377/500\n",
      "62/62 [==============================] - 1s 13ms/step - loss: 0.5663 - accuracy: 0.7150 - val_loss: 0.6202 - val_accuracy: 0.6735\n",
      "Epoch 378/500\n",
      "62/62 [==============================] - 1s 13ms/step - loss: 0.5645 - accuracy: 0.7139 - val_loss: 0.6204 - val_accuracy: 0.6773\n",
      "Epoch 379/500\n",
      "62/62 [==============================] - 1s 14ms/step - loss: 0.5597 - accuracy: 0.7163 - val_loss: 0.6211 - val_accuracy: 0.6747\n",
      "Epoch 380/500\n",
      "62/62 [==============================] - 1s 14ms/step - loss: 0.5616 - accuracy: 0.7152 - val_loss: 0.6204 - val_accuracy: 0.6773\n",
      "Epoch 381/500\n",
      "62/62 [==============================] - 1s 14ms/step - loss: 0.5655 - accuracy: 0.7153 - val_loss: 0.6180 - val_accuracy: 0.6837\n",
      "Epoch 382/500\n",
      "62/62 [==============================] - 1s 13ms/step - loss: 0.5660 - accuracy: 0.7175 - val_loss: 0.6196 - val_accuracy: 0.6760\n",
      "Epoch 383/500\n",
      "62/62 [==============================] - 1s 13ms/step - loss: 0.5575 - accuracy: 0.7161 - val_loss: 0.6214 - val_accuracy: 0.6684\n",
      "Epoch 384/500\n",
      "62/62 [==============================] - 1s 12ms/step - loss: 0.5586 - accuracy: 0.7152 - val_loss: 0.6195 - val_accuracy: 0.6735\n",
      "Epoch 385/500\n",
      "62/62 [==============================] - 1s 13ms/step - loss: 0.5630 - accuracy: 0.7124 - val_loss: 0.6227 - val_accuracy: 0.6760\n",
      "Epoch 386/500\n",
      "62/62 [==============================] - 1s 13ms/step - loss: 0.5587 - accuracy: 0.7147 - val_loss: 0.6214 - val_accuracy: 0.6696\n",
      "Epoch 387/500\n",
      "62/62 [==============================] - 1s 12ms/step - loss: 0.5605 - accuracy: 0.7098 - val_loss: 0.6209 - val_accuracy: 0.6696\n",
      "Epoch 388/500\n",
      "62/62 [==============================] - 1s 13ms/step - loss: 0.5530 - accuracy: 0.7209 - val_loss: 0.6194 - val_accuracy: 0.6735\n",
      "Epoch 389/500\n",
      "62/62 [==============================] - 1s 13ms/step - loss: 0.5580 - accuracy: 0.7182 - val_loss: 0.6195 - val_accuracy: 0.6824\n",
      "Epoch 390/500\n",
      "62/62 [==============================] - 1s 12ms/step - loss: 0.5617 - accuracy: 0.7184 - val_loss: 0.6226 - val_accuracy: 0.6684\n",
      "Epoch 391/500\n",
      "62/62 [==============================] - 1s 13ms/step - loss: 0.5578 - accuracy: 0.7181 - val_loss: 0.6218 - val_accuracy: 0.6658\n",
      "Epoch 392/500\n",
      "62/62 [==============================] - 1s 13ms/step - loss: 0.5592 - accuracy: 0.7165 - val_loss: 0.6224 - val_accuracy: 0.6684\n",
      "Epoch 393/500\n",
      "62/62 [==============================] - 1s 12ms/step - loss: 0.5573 - accuracy: 0.7151 - val_loss: 0.6224 - val_accuracy: 0.6722\n",
      "Epoch 394/500\n",
      "62/62 [==============================] - 1s 13ms/step - loss: 0.5611 - accuracy: 0.7155 - val_loss: 0.6204 - val_accuracy: 0.6709\n",
      "Epoch 395/500\n",
      "62/62 [==============================] - 1s 12ms/step - loss: 0.5579 - accuracy: 0.7187 - val_loss: 0.6212 - val_accuracy: 0.6735\n",
      "Epoch 396/500\n",
      "62/62 [==============================] - 1s 12ms/step - loss: 0.5603 - accuracy: 0.7170 - val_loss: 0.6225 - val_accuracy: 0.6722\n",
      "Epoch 397/500\n",
      "62/62 [==============================] - 1s 12ms/step - loss: 0.5608 - accuracy: 0.7187 - val_loss: 0.6220 - val_accuracy: 0.6747\n",
      "Epoch 398/500\n",
      "62/62 [==============================] - 1s 13ms/step - loss: 0.5594 - accuracy: 0.7171 - val_loss: 0.6206 - val_accuracy: 0.6811\n",
      "Epoch 399/500\n",
      "62/62 [==============================] - 1s 13ms/step - loss: 0.5589 - accuracy: 0.7143 - val_loss: 0.6211 - val_accuracy: 0.6760\n",
      "Epoch 400/500\n",
      "62/62 [==============================] - 1s 12ms/step - loss: 0.5579 - accuracy: 0.7184 - val_loss: 0.6202 - val_accuracy: 0.6798\n",
      "Epoch 401/500\n",
      "62/62 [==============================] - 1s 12ms/step - loss: 0.5556 - accuracy: 0.7180 - val_loss: 0.6220 - val_accuracy: 0.6735\n",
      "Epoch 402/500\n",
      "62/62 [==============================] - 1s 13ms/step - loss: 0.5603 - accuracy: 0.7137 - val_loss: 0.6228 - val_accuracy: 0.6696\n",
      "Epoch 403/500\n",
      "62/62 [==============================] - 1s 13ms/step - loss: 0.5622 - accuracy: 0.7143 - val_loss: 0.6230 - val_accuracy: 0.6696\n",
      "Epoch 404/500\n",
      "62/62 [==============================] - 1s 13ms/step - loss: 0.5606 - accuracy: 0.7132 - val_loss: 0.6224 - val_accuracy: 0.6722\n",
      "Epoch 405/500\n",
      "62/62 [==============================] - 1s 13ms/step - loss: 0.5572 - accuracy: 0.7205 - val_loss: 0.6221 - val_accuracy: 0.6760\n",
      "Epoch 406/500\n",
      "62/62 [==============================] - 1s 13ms/step - loss: 0.5563 - accuracy: 0.7189 - val_loss: 0.6238 - val_accuracy: 0.6760\n",
      "Epoch 407/500\n",
      "62/62 [==============================] - 1s 13ms/step - loss: 0.5568 - accuracy: 0.7171 - val_loss: 0.6233 - val_accuracy: 0.6722\n",
      "Epoch 408/500\n",
      "62/62 [==============================] - 1s 13ms/step - loss: 0.5599 - accuracy: 0.7190 - val_loss: 0.6231 - val_accuracy: 0.6735\n",
      "Epoch 409/500\n",
      "62/62 [==============================] - 1s 13ms/step - loss: 0.5564 - accuracy: 0.7186 - val_loss: 0.6223 - val_accuracy: 0.6747\n",
      "Epoch 410/500\n",
      "62/62 [==============================] - 1s 13ms/step - loss: 0.5614 - accuracy: 0.7191 - val_loss: 0.6218 - val_accuracy: 0.6709\n",
      "Epoch 411/500\n",
      "62/62 [==============================] - 1s 13ms/step - loss: 0.5556 - accuracy: 0.7147 - val_loss: 0.6228 - val_accuracy: 0.6773\n",
      "Epoch 412/500\n",
      "62/62 [==============================] - 1s 13ms/step - loss: 0.5579 - accuracy: 0.7138 - val_loss: 0.6247 - val_accuracy: 0.6773\n",
      "Epoch 413/500\n",
      "62/62 [==============================] - 1s 12ms/step - loss: 0.5609 - accuracy: 0.7126 - val_loss: 0.6205 - val_accuracy: 0.6773\n",
      "Epoch 414/500\n",
      "62/62 [==============================] - 1s 13ms/step - loss: 0.5559 - accuracy: 0.7172 - val_loss: 0.6203 - val_accuracy: 0.6722\n",
      "Epoch 415/500\n",
      "62/62 [==============================] - 1s 13ms/step - loss: 0.5486 - accuracy: 0.7223 - val_loss: 0.6220 - val_accuracy: 0.6735\n",
      "Epoch 416/500\n",
      "62/62 [==============================] - 1s 13ms/step - loss: 0.5530 - accuracy: 0.7216 - val_loss: 0.6239 - val_accuracy: 0.6747\n",
      "Epoch 417/500\n",
      "62/62 [==============================] - 1s 12ms/step - loss: 0.5593 - accuracy: 0.7182 - val_loss: 0.6215 - val_accuracy: 0.6722\n",
      "Epoch 418/500\n",
      "62/62 [==============================] - 1s 13ms/step - loss: 0.5571 - accuracy: 0.7186 - val_loss: 0.6218 - val_accuracy: 0.6747\n",
      "Epoch 419/500\n",
      "62/62 [==============================] - 1s 13ms/step - loss: 0.5535 - accuracy: 0.7233 - val_loss: 0.6217 - val_accuracy: 0.6658\n",
      "Epoch 420/500\n",
      "62/62 [==============================] - 1s 12ms/step - loss: 0.5557 - accuracy: 0.7196 - val_loss: 0.6244 - val_accuracy: 0.6735\n",
      "Epoch 421/500\n",
      "62/62 [==============================] - 1s 13ms/step - loss: 0.5571 - accuracy: 0.7186 - val_loss: 0.6260 - val_accuracy: 0.6696\n",
      "Epoch 422/500\n",
      "62/62 [==============================] - 1s 13ms/step - loss: 0.5524 - accuracy: 0.7201 - val_loss: 0.6232 - val_accuracy: 0.6722\n",
      "Epoch 423/500\n",
      "62/62 [==============================] - 1s 13ms/step - loss: 0.5564 - accuracy: 0.7138 - val_loss: 0.6234 - val_accuracy: 0.6747\n",
      "Epoch 424/500\n",
      "62/62 [==============================] - 1s 13ms/step - loss: 0.5527 - accuracy: 0.7238 - val_loss: 0.6255 - val_accuracy: 0.6722\n",
      "Epoch 425/500\n",
      "62/62 [==============================] - 1s 13ms/step - loss: 0.5546 - accuracy: 0.7167 - val_loss: 0.6236 - val_accuracy: 0.6760\n",
      "Epoch 426/500\n",
      "62/62 [==============================] - 1s 13ms/step - loss: 0.5512 - accuracy: 0.7177 - val_loss: 0.6242 - val_accuracy: 0.6696\n",
      "Epoch 427/500\n",
      "62/62 [==============================] - 1s 13ms/step - loss: 0.5599 - accuracy: 0.7157 - val_loss: 0.6222 - val_accuracy: 0.6760\n",
      "Epoch 428/500\n",
      "62/62 [==============================] - 1s 12ms/step - loss: 0.5534 - accuracy: 0.7235 - val_loss: 0.6212 - val_accuracy: 0.6747\n",
      "Epoch 429/500\n",
      "62/62 [==============================] - 1s 13ms/step - loss: 0.5576 - accuracy: 0.7242 - val_loss: 0.6215 - val_accuracy: 0.6747\n",
      "Epoch 430/500\n",
      "62/62 [==============================] - 1s 13ms/step - loss: 0.5595 - accuracy: 0.7201 - val_loss: 0.6206 - val_accuracy: 0.6786\n",
      "Epoch 431/500\n",
      "62/62 [==============================] - 1s 13ms/step - loss: 0.5550 - accuracy: 0.7237 - val_loss: 0.6205 - val_accuracy: 0.6735\n",
      "Epoch 432/500\n",
      "62/62 [==============================] - 1s 13ms/step - loss: 0.5564 - accuracy: 0.7139 - val_loss: 0.6204 - val_accuracy: 0.6696\n",
      "Epoch 433/500\n",
      "62/62 [==============================] - 1s 13ms/step - loss: 0.5571 - accuracy: 0.7139 - val_loss: 0.6188 - val_accuracy: 0.6786\n",
      "Epoch 434/500\n",
      "62/62 [==============================] - 1s 12ms/step - loss: 0.5579 - accuracy: 0.7186 - val_loss: 0.6192 - val_accuracy: 0.6760\n",
      "Epoch 435/500\n",
      "62/62 [==============================] - 1s 13ms/step - loss: 0.5581 - accuracy: 0.7156 - val_loss: 0.6210 - val_accuracy: 0.6709\n",
      "Epoch 436/500\n",
      "62/62 [==============================] - 1s 13ms/step - loss: 0.5508 - accuracy: 0.7266 - val_loss: 0.6230 - val_accuracy: 0.6696\n",
      "Epoch 437/500\n",
      "62/62 [==============================] - 1s 13ms/step - loss: 0.5607 - accuracy: 0.7146 - val_loss: 0.6236 - val_accuracy: 0.6735\n",
      "Epoch 438/500\n",
      "62/62 [==============================] - 1s 12ms/step - loss: 0.5507 - accuracy: 0.7242 - val_loss: 0.6219 - val_accuracy: 0.6811\n",
      "Epoch 439/500\n",
      "62/62 [==============================] - 1s 13ms/step - loss: 0.5550 - accuracy: 0.7199 - val_loss: 0.6211 - val_accuracy: 0.6773\n",
      "Epoch 440/500\n",
      "62/62 [==============================] - 1s 12ms/step - loss: 0.5536 - accuracy: 0.7262 - val_loss: 0.6221 - val_accuracy: 0.6811\n",
      "Epoch 441/500\n",
      "62/62 [==============================] - 1s 12ms/step - loss: 0.5480 - accuracy: 0.7195 - val_loss: 0.6194 - val_accuracy: 0.6837\n",
      "Epoch 442/500\n",
      "62/62 [==============================] - 1s 14ms/step - loss: 0.5568 - accuracy: 0.7206 - val_loss: 0.6191 - val_accuracy: 0.6760\n",
      "Epoch 443/500\n",
      "62/62 [==============================] - 1s 13ms/step - loss: 0.5553 - accuracy: 0.7184 - val_loss: 0.6213 - val_accuracy: 0.6786\n",
      "Epoch 444/500\n",
      "62/62 [==============================] - 1s 13ms/step - loss: 0.5525 - accuracy: 0.7268 - val_loss: 0.6212 - val_accuracy: 0.6722\n",
      "Epoch 445/500\n",
      "62/62 [==============================] - 1s 13ms/step - loss: 0.5533 - accuracy: 0.7228 - val_loss: 0.6210 - val_accuracy: 0.6735\n",
      "Epoch 446/500\n",
      "62/62 [==============================] - 1s 13ms/step - loss: 0.5516 - accuracy: 0.7197 - val_loss: 0.6218 - val_accuracy: 0.6786\n",
      "Epoch 447/500\n",
      "62/62 [==============================] - 1s 13ms/step - loss: 0.5523 - accuracy: 0.7258 - val_loss: 0.6247 - val_accuracy: 0.6722\n",
      "Epoch 448/500\n",
      "62/62 [==============================] - 1s 12ms/step - loss: 0.5491 - accuracy: 0.7252 - val_loss: 0.6231 - val_accuracy: 0.6735\n",
      "Epoch 449/500\n",
      "62/62 [==============================] - 1s 13ms/step - loss: 0.5534 - accuracy: 0.7214 - val_loss: 0.6227 - val_accuracy: 0.6747\n",
      "Epoch 450/500\n",
      "62/62 [==============================] - 1s 13ms/step - loss: 0.5501 - accuracy: 0.7171 - val_loss: 0.6189 - val_accuracy: 0.6786\n",
      "Epoch 451/500\n",
      "62/62 [==============================] - 1s 12ms/step - loss: 0.5466 - accuracy: 0.7281 - val_loss: 0.6224 - val_accuracy: 0.6786\n",
      "Epoch 452/500\n",
      "62/62 [==============================] - 1s 13ms/step - loss: 0.5530 - accuracy: 0.7231 - val_loss: 0.6222 - val_accuracy: 0.6760\n",
      "Epoch 453/500\n",
      "62/62 [==============================] - 1s 13ms/step - loss: 0.5474 - accuracy: 0.7220 - val_loss: 0.6234 - val_accuracy: 0.6786\n",
      "Epoch 454/500\n",
      "62/62 [==============================] - 1s 13ms/step - loss: 0.5561 - accuracy: 0.7152 - val_loss: 0.6218 - val_accuracy: 0.6696\n",
      "Epoch 455/500\n",
      "62/62 [==============================] - 1s 13ms/step - loss: 0.5467 - accuracy: 0.7242 - val_loss: 0.6216 - val_accuracy: 0.6735\n",
      "Epoch 456/500\n",
      "62/62 [==============================] - 1s 14ms/step - loss: 0.5492 - accuracy: 0.7200 - val_loss: 0.6228 - val_accuracy: 0.6658\n",
      "Epoch 457/500\n",
      "62/62 [==============================] - 1s 13ms/step - loss: 0.5545 - accuracy: 0.7230 - val_loss: 0.6228 - val_accuracy: 0.6722\n",
      "Epoch 458/500\n",
      "62/62 [==============================] - 1s 13ms/step - loss: 0.5537 - accuracy: 0.7165 - val_loss: 0.6230 - val_accuracy: 0.6735\n",
      "Epoch 459/500\n",
      "62/62 [==============================] - 1s 13ms/step - loss: 0.5495 - accuracy: 0.7239 - val_loss: 0.6224 - val_accuracy: 0.6735\n",
      "Epoch 460/500\n",
      "62/62 [==============================] - 1s 13ms/step - loss: 0.5500 - accuracy: 0.7234 - val_loss: 0.6233 - val_accuracy: 0.6684\n",
      "Epoch 461/500\n",
      "62/62 [==============================] - 1s 12ms/step - loss: 0.5513 - accuracy: 0.7267 - val_loss: 0.6235 - val_accuracy: 0.6722\n",
      "Epoch 462/500\n",
      "62/62 [==============================] - 1s 13ms/step - loss: 0.5504 - accuracy: 0.7199 - val_loss: 0.6217 - val_accuracy: 0.6824\n",
      "Epoch 463/500\n",
      "62/62 [==============================] - 1s 13ms/step - loss: 0.5460 - accuracy: 0.7250 - val_loss: 0.6231 - val_accuracy: 0.6773\n",
      "Epoch 464/500\n",
      "62/62 [==============================] - 1s 12ms/step - loss: 0.5559 - accuracy: 0.7202 - val_loss: 0.6240 - val_accuracy: 0.6722\n",
      "Epoch 465/500\n",
      "62/62 [==============================] - 1s 13ms/step - loss: 0.5492 - accuracy: 0.7170 - val_loss: 0.6238 - val_accuracy: 0.6786\n",
      "Epoch 466/500\n",
      "62/62 [==============================] - 1s 13ms/step - loss: 0.5506 - accuracy: 0.7200 - val_loss: 0.6222 - val_accuracy: 0.6696\n",
      "Epoch 467/500\n",
      "62/62 [==============================] - 1s 13ms/step - loss: 0.5505 - accuracy: 0.7230 - val_loss: 0.6232 - val_accuracy: 0.6620\n",
      "Epoch 468/500\n",
      "62/62 [==============================] - 1s 13ms/step - loss: 0.5490 - accuracy: 0.7300 - val_loss: 0.6227 - val_accuracy: 0.6645\n",
      "Epoch 469/500\n",
      "62/62 [==============================] - 1s 13ms/step - loss: 0.5531 - accuracy: 0.7213 - val_loss: 0.6222 - val_accuracy: 0.6684\n",
      "Epoch 470/500\n",
      "62/62 [==============================] - 1s 12ms/step - loss: 0.5504 - accuracy: 0.7258 - val_loss: 0.6245 - val_accuracy: 0.6722\n",
      "Epoch 471/500\n",
      "62/62 [==============================] - 1s 13ms/step - loss: 0.5535 - accuracy: 0.7171 - val_loss: 0.6234 - val_accuracy: 0.6722\n",
      "Epoch 472/500\n",
      "62/62 [==============================] - 1s 12ms/step - loss: 0.5516 - accuracy: 0.7204 - val_loss: 0.6239 - val_accuracy: 0.6747\n",
      "Epoch 473/500\n",
      "62/62 [==============================] - 1s 13ms/step - loss: 0.5474 - accuracy: 0.7234 - val_loss: 0.6230 - val_accuracy: 0.6658\n",
      "Epoch 474/500\n",
      "62/62 [==============================] - 1s 12ms/step - loss: 0.5544 - accuracy: 0.7195 - val_loss: 0.6219 - val_accuracy: 0.6722\n",
      "Epoch 475/500\n",
      "62/62 [==============================] - 1s 13ms/step - loss: 0.5536 - accuracy: 0.7176 - val_loss: 0.6220 - val_accuracy: 0.6696\n",
      "Epoch 476/500\n",
      "62/62 [==============================] - 1s 13ms/step - loss: 0.5521 - accuracy: 0.7229 - val_loss: 0.6218 - val_accuracy: 0.6633\n",
      "Epoch 477/500\n",
      "62/62 [==============================] - 1s 12ms/step - loss: 0.5482 - accuracy: 0.7200 - val_loss: 0.6230 - val_accuracy: 0.6658\n",
      "Epoch 478/500\n",
      "62/62 [==============================] - 1s 13ms/step - loss: 0.5475 - accuracy: 0.7302 - val_loss: 0.6212 - val_accuracy: 0.6760\n",
      "Epoch 479/500\n",
      "62/62 [==============================] - 1s 13ms/step - loss: 0.5529 - accuracy: 0.7230 - val_loss: 0.6199 - val_accuracy: 0.6735\n",
      "Epoch 480/500\n",
      "62/62 [==============================] - 1s 13ms/step - loss: 0.5473 - accuracy: 0.7284 - val_loss: 0.6205 - val_accuracy: 0.6760\n",
      "Epoch 481/500\n",
      "62/62 [==============================] - 1s 12ms/step - loss: 0.5514 - accuracy: 0.7187 - val_loss: 0.6205 - val_accuracy: 0.6747\n",
      "Epoch 482/500\n",
      "62/62 [==============================] - 1s 13ms/step - loss: 0.5473 - accuracy: 0.7234 - val_loss: 0.6218 - val_accuracy: 0.6747\n",
      "Epoch 483/500\n",
      "62/62 [==============================] - 1s 14ms/step - loss: 0.5520 - accuracy: 0.7219 - val_loss: 0.6212 - val_accuracy: 0.6671\n",
      "Epoch 484/500\n",
      "62/62 [==============================] - 1s 13ms/step - loss: 0.5515 - accuracy: 0.7211 - val_loss: 0.6238 - val_accuracy: 0.6722\n",
      "Epoch 485/500\n",
      "62/62 [==============================] - 1s 13ms/step - loss: 0.5456 - accuracy: 0.7289 - val_loss: 0.6242 - val_accuracy: 0.6722\n",
      "Epoch 486/500\n",
      "62/62 [==============================] - 1s 13ms/step - loss: 0.5495 - accuracy: 0.7199 - val_loss: 0.6243 - val_accuracy: 0.6684\n",
      "Epoch 487/500\n",
      "62/62 [==============================] - 1s 12ms/step - loss: 0.5465 - accuracy: 0.7234 - val_loss: 0.6230 - val_accuracy: 0.6760\n",
      "Epoch 488/500\n",
      "62/62 [==============================] - 1s 13ms/step - loss: 0.5473 - accuracy: 0.7271 - val_loss: 0.6253 - val_accuracy: 0.6735\n",
      "Epoch 489/500\n",
      "62/62 [==============================] - 1s 13ms/step - loss: 0.5451 - accuracy: 0.7263 - val_loss: 0.6250 - val_accuracy: 0.6696\n",
      "Epoch 490/500\n",
      "62/62 [==============================] - 1s 13ms/step - loss: 0.5473 - accuracy: 0.7234 - val_loss: 0.6249 - val_accuracy: 0.6709\n",
      "Epoch 491/500\n",
      "62/62 [==============================] - 1s 13ms/step - loss: 0.5448 - accuracy: 0.7289 - val_loss: 0.6245 - val_accuracy: 0.6684\n",
      "Epoch 492/500\n",
      "62/62 [==============================] - 1s 13ms/step - loss: 0.5495 - accuracy: 0.7231 - val_loss: 0.6238 - val_accuracy: 0.6671\n",
      "Epoch 493/500\n",
      "62/62 [==============================] - 1s 12ms/step - loss: 0.5479 - accuracy: 0.7234 - val_loss: 0.6239 - val_accuracy: 0.6696\n",
      "Epoch 494/500\n",
      "62/62 [==============================] - 1s 13ms/step - loss: 0.5502 - accuracy: 0.7176 - val_loss: 0.6225 - val_accuracy: 0.6671\n",
      "Epoch 495/500\n",
      "62/62 [==============================] - 1s 13ms/step - loss: 0.5498 - accuracy: 0.7220 - val_loss: 0.6231 - val_accuracy: 0.6696\n",
      "Epoch 496/500\n",
      "62/62 [==============================] - 1s 13ms/step - loss: 0.5473 - accuracy: 0.7281 - val_loss: 0.6228 - val_accuracy: 0.6696\n",
      "Epoch 497/500\n",
      "62/62 [==============================] - 1s 13ms/step - loss: 0.5420 - accuracy: 0.7296 - val_loss: 0.6244 - val_accuracy: 0.6722\n",
      "Epoch 498/500\n",
      "62/62 [==============================] - 1s 13ms/step - loss: 0.5402 - accuracy: 0.7221 - val_loss: 0.6231 - val_accuracy: 0.6735\n",
      "Epoch 499/500\n",
      "62/62 [==============================] - 1s 12ms/step - loss: 0.5456 - accuracy: 0.7250 - val_loss: 0.6235 - val_accuracy: 0.6786\n",
      "Epoch 500/500\n",
      "62/62 [==============================] - 1s 13ms/step - loss: 0.5509 - accuracy: 0.7200 - val_loss: 0.6239 - val_accuracy: 0.6696\n",
      "Epoch 1/500\n",
      "62/62 [==============================] - 2s 17ms/step - loss: 0.8167 - accuracy: 0.5415 - val_loss: 0.6541 - val_accuracy: 0.6620\n",
      "Epoch 2/500\n",
      "62/62 [==============================] - 1s 12ms/step - loss: 0.7313 - accuracy: 0.5847 - val_loss: 0.6396 - val_accuracy: 0.6735\n",
      "Epoch 3/500\n",
      "62/62 [==============================] - 1s 12ms/step - loss: 0.7023 - accuracy: 0.5877 - val_loss: 0.6346 - val_accuracy: 0.6747\n",
      "Epoch 4/500\n",
      "62/62 [==============================] - 1s 12ms/step - loss: 0.6764 - accuracy: 0.6131 - val_loss: 0.6336 - val_accuracy: 0.6798\n",
      "Epoch 5/500\n",
      "62/62 [==============================] - 1s 12ms/step - loss: 0.6591 - accuracy: 0.6268 - val_loss: 0.6246 - val_accuracy: 0.6824\n",
      "Epoch 6/500\n",
      "62/62 [==============================] - 1s 13ms/step - loss: 0.6547 - accuracy: 0.6236 - val_loss: 0.6200 - val_accuracy: 0.6888\n",
      "Epoch 7/500\n",
      "62/62 [==============================] - 1s 14ms/step - loss: 0.6411 - accuracy: 0.6469 - val_loss: 0.6194 - val_accuracy: 0.6798\n",
      "Epoch 8/500\n",
      "62/62 [==============================] - 1s 14ms/step - loss: 0.6330 - accuracy: 0.6484 - val_loss: 0.6128 - val_accuracy: 0.6926\n",
      "Epoch 9/500\n",
      "62/62 [==============================] - 1s 14ms/step - loss: 0.6264 - accuracy: 0.6562 - val_loss: 0.6121 - val_accuracy: 0.6913\n",
      "Epoch 10/500\n",
      "62/62 [==============================] - 1s 13ms/step - loss: 0.6230 - accuracy: 0.6620 - val_loss: 0.6130 - val_accuracy: 0.6747\n",
      "Epoch 11/500\n",
      "62/62 [==============================] - 1s 13ms/step - loss: 0.6199 - accuracy: 0.6633 - val_loss: 0.6076 - val_accuracy: 0.6952\n",
      "Epoch 12/500\n",
      "62/62 [==============================] - 1s 13ms/step - loss: 0.6154 - accuracy: 0.6665 - val_loss: 0.6089 - val_accuracy: 0.6977\n",
      "Epoch 13/500\n",
      "62/62 [==============================] - 1s 13ms/step - loss: 0.6072 - accuracy: 0.6788 - val_loss: 0.6051 - val_accuracy: 0.6888\n",
      "Epoch 14/500\n",
      "62/62 [==============================] - 1s 12ms/step - loss: 0.6069 - accuracy: 0.6741 - val_loss: 0.6054 - val_accuracy: 0.6939\n",
      "Epoch 15/500\n",
      "62/62 [==============================] - 1s 13ms/step - loss: 0.5991 - accuracy: 0.6812 - val_loss: 0.6118 - val_accuracy: 0.6862\n",
      "Epoch 16/500\n",
      "62/62 [==============================] - 1s 12ms/step - loss: 0.5956 - accuracy: 0.6876 - val_loss: 0.6132 - val_accuracy: 0.6760\n",
      "Epoch 17/500\n",
      "62/62 [==============================] - 1s 12ms/step - loss: 0.5932 - accuracy: 0.6876 - val_loss: 0.6185 - val_accuracy: 0.6671\n",
      "Epoch 18/500\n",
      "62/62 [==============================] - 1s 12ms/step - loss: 0.5845 - accuracy: 0.6964 - val_loss: 0.6080 - val_accuracy: 0.6875\n",
      "Epoch 19/500\n",
      "62/62 [==============================] - 1s 13ms/step - loss: 0.5833 - accuracy: 0.6978 - val_loss: 0.6083 - val_accuracy: 0.6964\n",
      "Epoch 20/500\n",
      "62/62 [==============================] - 1s 12ms/step - loss: 0.5821 - accuracy: 0.6939 - val_loss: 0.6093 - val_accuracy: 0.7041\n",
      "Epoch 21/500\n",
      "62/62 [==============================] - 1s 13ms/step - loss: 0.5784 - accuracy: 0.7040 - val_loss: 0.6070 - val_accuracy: 0.7003\n",
      "Epoch 22/500\n",
      "62/62 [==============================] - 1s 12ms/step - loss: 0.5739 - accuracy: 0.7046 - val_loss: 0.6173 - val_accuracy: 0.6913\n",
      "Epoch 23/500\n",
      "62/62 [==============================] - 1s 13ms/step - loss: 0.5652 - accuracy: 0.7081 - val_loss: 0.6145 - val_accuracy: 0.6875\n",
      "Epoch 24/500\n",
      "62/62 [==============================] - 1s 12ms/step - loss: 0.5689 - accuracy: 0.7059 - val_loss: 0.6064 - val_accuracy: 0.6862\n",
      "Epoch 25/500\n",
      "62/62 [==============================] - 1s 13ms/step - loss: 0.5667 - accuracy: 0.7097 - val_loss: 0.6110 - val_accuracy: 0.6964\n",
      "Epoch 26/500\n",
      "62/62 [==============================] - 1s 13ms/step - loss: 0.5665 - accuracy: 0.7071 - val_loss: 0.6226 - val_accuracy: 0.6964\n",
      "Epoch 27/500\n",
      "62/62 [==============================] - 1s 13ms/step - loss: 0.5564 - accuracy: 0.7205 - val_loss: 0.6296 - val_accuracy: 0.6849\n",
      "Epoch 28/500\n",
      "62/62 [==============================] - 1s 13ms/step - loss: 0.5537 - accuracy: 0.7148 - val_loss: 0.6253 - val_accuracy: 0.6773\n",
      "Epoch 29/500\n",
      "62/62 [==============================] - 1s 13ms/step - loss: 0.5486 - accuracy: 0.7226 - val_loss: 0.6309 - val_accuracy: 0.6837\n",
      "Epoch 30/500\n",
      "62/62 [==============================] - 1s 13ms/step - loss: 0.5489 - accuracy: 0.7235 - val_loss: 0.6274 - val_accuracy: 0.6952\n",
      "Epoch 31/500\n",
      "62/62 [==============================] - 1s 13ms/step - loss: 0.5490 - accuracy: 0.7182 - val_loss: 0.6239 - val_accuracy: 0.6837\n",
      "Epoch 32/500\n",
      "62/62 [==============================] - 1s 13ms/step - loss: 0.5405 - accuracy: 0.7274 - val_loss: 0.6186 - val_accuracy: 0.6849\n",
      "Epoch 33/500\n",
      "62/62 [==============================] - 1s 12ms/step - loss: 0.5400 - accuracy: 0.7264 - val_loss: 0.6222 - val_accuracy: 0.6901\n",
      "Epoch 34/500\n",
      "62/62 [==============================] - 1s 13ms/step - loss: 0.5379 - accuracy: 0.7272 - val_loss: 0.6249 - val_accuracy: 0.6977\n",
      "Epoch 35/500\n",
      "62/62 [==============================] - 1s 13ms/step - loss: 0.5374 - accuracy: 0.7312 - val_loss: 0.6257 - val_accuracy: 0.6901\n",
      "Epoch 36/500\n",
      "62/62 [==============================] - 1s 12ms/step - loss: 0.5316 - accuracy: 0.7336 - val_loss: 0.6165 - val_accuracy: 0.6939\n",
      "Epoch 37/500\n",
      "62/62 [==============================] - 1s 13ms/step - loss: 0.5306 - accuracy: 0.7340 - val_loss: 0.6266 - val_accuracy: 0.6913\n",
      "Epoch 38/500\n",
      "62/62 [==============================] - 1s 12ms/step - loss: 0.5280 - accuracy: 0.7399 - val_loss: 0.6482 - val_accuracy: 0.6849\n",
      "Epoch 39/500\n",
      "62/62 [==============================] - 1s 13ms/step - loss: 0.5279 - accuracy: 0.7313 - val_loss: 0.6344 - val_accuracy: 0.6786\n",
      "Epoch 40/500\n",
      "62/62 [==============================] - 1s 13ms/step - loss: 0.5207 - accuracy: 0.7383 - val_loss: 0.6296 - val_accuracy: 0.6862\n",
      "Epoch 41/500\n",
      "62/62 [==============================] - 1s 13ms/step - loss: 0.5211 - accuracy: 0.7431 - val_loss: 0.6264 - val_accuracy: 0.6964\n",
      "Epoch 42/500\n",
      "62/62 [==============================] - 1s 13ms/step - loss: 0.5194 - accuracy: 0.7379 - val_loss: 0.6302 - val_accuracy: 0.6913\n",
      "Epoch 43/500\n",
      "62/62 [==============================] - 1s 13ms/step - loss: 0.5118 - accuracy: 0.7453 - val_loss: 0.6441 - val_accuracy: 0.6888\n",
      "Epoch 44/500\n",
      "62/62 [==============================] - 1s 13ms/step - loss: 0.5095 - accuracy: 0.7460 - val_loss: 0.6358 - val_accuracy: 0.6798\n",
      "Epoch 45/500\n",
      "62/62 [==============================] - 1s 13ms/step - loss: 0.5088 - accuracy: 0.7506 - val_loss: 0.6293 - val_accuracy: 0.6939\n",
      "Epoch 46/500\n",
      "62/62 [==============================] - 1s 13ms/step - loss: 0.5014 - accuracy: 0.7537 - val_loss: 0.6574 - val_accuracy: 0.6837\n",
      "Epoch 47/500\n",
      "62/62 [==============================] - 1s 13ms/step - loss: 0.5033 - accuracy: 0.7494 - val_loss: 0.6419 - val_accuracy: 0.6913\n",
      "Epoch 48/500\n",
      "62/62 [==============================] - 1s 13ms/step - loss: 0.4975 - accuracy: 0.7564 - val_loss: 0.6541 - val_accuracy: 0.6888\n",
      "Epoch 49/500\n",
      "62/62 [==============================] - 1s 14ms/step - loss: 0.5024 - accuracy: 0.7508 - val_loss: 0.6539 - val_accuracy: 0.6786\n",
      "Epoch 50/500\n",
      "62/62 [==============================] - 1s 13ms/step - loss: 0.5037 - accuracy: 0.7467 - val_loss: 0.6369 - val_accuracy: 0.7003\n",
      "Epoch 51/500\n",
      "62/62 [==============================] - 1s 13ms/step - loss: 0.5028 - accuracy: 0.7530 - val_loss: 0.6474 - val_accuracy: 0.6875\n",
      "Epoch 52/500\n",
      "62/62 [==============================] - 1s 13ms/step - loss: 0.4980 - accuracy: 0.7491 - val_loss: 0.6365 - val_accuracy: 0.6926\n",
      "Epoch 53/500\n",
      "62/62 [==============================] - 1s 13ms/step - loss: 0.4938 - accuracy: 0.7532 - val_loss: 0.6592 - val_accuracy: 0.6747\n",
      "Epoch 54/500\n",
      "62/62 [==============================] - 1s 12ms/step - loss: 0.4901 - accuracy: 0.7532 - val_loss: 0.6517 - val_accuracy: 0.6926\n",
      "Epoch 55/500\n",
      "62/62 [==============================] - 1s 13ms/step - loss: 0.4894 - accuracy: 0.7544 - val_loss: 0.6538 - val_accuracy: 0.6849\n",
      "Epoch 56/500\n",
      "62/62 [==============================] - 1s 13ms/step - loss: 0.4937 - accuracy: 0.7526 - val_loss: 0.6636 - val_accuracy: 0.6862\n",
      "Epoch 57/500\n",
      "62/62 [==============================] - 1s 12ms/step - loss: 0.4872 - accuracy: 0.7645 - val_loss: 0.6662 - val_accuracy: 0.6875\n",
      "Epoch 58/500\n",
      "62/62 [==============================] - 1s 13ms/step - loss: 0.4870 - accuracy: 0.7603 - val_loss: 0.6621 - val_accuracy: 0.6964\n",
      "Epoch 59/500\n",
      "62/62 [==============================] - 1s 13ms/step - loss: 0.4846 - accuracy: 0.7607 - val_loss: 0.6606 - val_accuracy: 0.6964\n",
      "Epoch 60/500\n",
      "62/62 [==============================] - 1s 13ms/step - loss: 0.4871 - accuracy: 0.7601 - val_loss: 0.6711 - val_accuracy: 0.6849\n",
      "Epoch 61/500\n",
      "62/62 [==============================] - 1s 13ms/step - loss: 0.4820 - accuracy: 0.7665 - val_loss: 0.6625 - val_accuracy: 0.6849\n",
      "Epoch 62/500\n",
      "62/62 [==============================] - 1s 13ms/step - loss: 0.4750 - accuracy: 0.7683 - val_loss: 0.6685 - val_accuracy: 0.6926\n",
      "Epoch 63/500\n",
      "62/62 [==============================] - 1s 13ms/step - loss: 0.4775 - accuracy: 0.7675 - val_loss: 0.6718 - val_accuracy: 0.6824\n",
      "Epoch 64/500\n",
      "62/62 [==============================] - 1s 13ms/step - loss: 0.4761 - accuracy: 0.7660 - val_loss: 0.6634 - val_accuracy: 0.6990\n",
      "Epoch 65/500\n",
      "62/62 [==============================] - 1s 12ms/step - loss: 0.4708 - accuracy: 0.7709 - val_loss: 0.6895 - val_accuracy: 0.6837\n",
      "Epoch 66/500\n",
      "62/62 [==============================] - 1s 13ms/step - loss: 0.4737 - accuracy: 0.7640 - val_loss: 0.6845 - val_accuracy: 0.6875\n",
      "Epoch 67/500\n",
      "62/62 [==============================] - 1s 13ms/step - loss: 0.4701 - accuracy: 0.7658 - val_loss: 0.6762 - val_accuracy: 0.6952\n",
      "Epoch 68/500\n",
      "62/62 [==============================] - 1s 13ms/step - loss: 0.4668 - accuracy: 0.7726 - val_loss: 0.6808 - val_accuracy: 0.7066\n",
      "Epoch 69/500\n",
      "62/62 [==============================] - 1s 13ms/step - loss: 0.4576 - accuracy: 0.7748 - val_loss: 0.6849 - val_accuracy: 0.6990\n",
      "Epoch 70/500\n",
      "62/62 [==============================] - 1s 13ms/step - loss: 0.4665 - accuracy: 0.7723 - val_loss: 0.6816 - val_accuracy: 0.6888\n",
      "Epoch 71/500\n",
      "62/62 [==============================] - 1s 12ms/step - loss: 0.4668 - accuracy: 0.7723 - val_loss: 0.6792 - val_accuracy: 0.6875\n",
      "Epoch 72/500\n",
      "62/62 [==============================] - 1s 13ms/step - loss: 0.4657 - accuracy: 0.7714 - val_loss: 0.6910 - val_accuracy: 0.6939\n",
      "Epoch 73/500\n",
      "62/62 [==============================] - 1s 13ms/step - loss: 0.4556 - accuracy: 0.7743 - val_loss: 0.6983 - val_accuracy: 0.6888\n",
      "Epoch 74/500\n",
      "62/62 [==============================] - 1s 13ms/step - loss: 0.4573 - accuracy: 0.7753 - val_loss: 0.6727 - val_accuracy: 0.7028\n",
      "Epoch 75/500\n",
      "62/62 [==============================] - 1s 13ms/step - loss: 0.4639 - accuracy: 0.7774 - val_loss: 0.6869 - val_accuracy: 0.7015\n",
      "Epoch 76/500\n",
      "62/62 [==============================] - 1s 13ms/step - loss: 0.4558 - accuracy: 0.7762 - val_loss: 0.6866 - val_accuracy: 0.6990\n",
      "Epoch 77/500\n",
      "62/62 [==============================] - 1s 13ms/step - loss: 0.4645 - accuracy: 0.7705 - val_loss: 0.6895 - val_accuracy: 0.6901\n",
      "Epoch 78/500\n",
      "62/62 [==============================] - 1s 13ms/step - loss: 0.4512 - accuracy: 0.7811 - val_loss: 0.7071 - val_accuracy: 0.7015\n",
      "Epoch 79/500\n",
      "62/62 [==============================] - 1s 12ms/step - loss: 0.4553 - accuracy: 0.7806 - val_loss: 0.7091 - val_accuracy: 0.7003\n",
      "Epoch 80/500\n",
      "62/62 [==============================] - 1s 13ms/step - loss: 0.4565 - accuracy: 0.7761 - val_loss: 0.6965 - val_accuracy: 0.6913\n",
      "Epoch 81/500\n",
      "62/62 [==============================] - 1s 13ms/step - loss: 0.4587 - accuracy: 0.7738 - val_loss: 0.6935 - val_accuracy: 0.7003\n",
      "Epoch 82/500\n",
      "62/62 [==============================] - 1s 13ms/step - loss: 0.4539 - accuracy: 0.7762 - val_loss: 0.7013 - val_accuracy: 0.7054\n",
      "Epoch 83/500\n",
      "62/62 [==============================] - 1s 13ms/step - loss: 0.4443 - accuracy: 0.7821 - val_loss: 0.7104 - val_accuracy: 0.7003\n",
      "Epoch 84/500\n",
      "62/62 [==============================] - 1s 14ms/step - loss: 0.4497 - accuracy: 0.7770 - val_loss: 0.7141 - val_accuracy: 0.6952\n",
      "Epoch 85/500\n",
      "62/62 [==============================] - 1s 13ms/step - loss: 0.4503 - accuracy: 0.7804 - val_loss: 0.7297 - val_accuracy: 0.6926\n",
      "Epoch 86/500\n",
      "62/62 [==============================] - 1s 14ms/step - loss: 0.4462 - accuracy: 0.7776 - val_loss: 0.7057 - val_accuracy: 0.6939\n",
      "Epoch 87/500\n",
      "62/62 [==============================] - 1s 13ms/step - loss: 0.4472 - accuracy: 0.7823 - val_loss: 0.7008 - val_accuracy: 0.6901\n",
      "Epoch 88/500\n",
      "62/62 [==============================] - 1s 13ms/step - loss: 0.4443 - accuracy: 0.7835 - val_loss: 0.6900 - val_accuracy: 0.6926\n",
      "Epoch 89/500\n",
      "62/62 [==============================] - 1s 13ms/step - loss: 0.4479 - accuracy: 0.7808 - val_loss: 0.6942 - val_accuracy: 0.7066\n",
      "Epoch 90/500\n",
      "62/62 [==============================] - 1s 13ms/step - loss: 0.4456 - accuracy: 0.7837 - val_loss: 0.7130 - val_accuracy: 0.6913\n",
      "Epoch 91/500\n",
      "62/62 [==============================] - 1s 13ms/step - loss: 0.4403 - accuracy: 0.7867 - val_loss: 0.7128 - val_accuracy: 0.6849\n",
      "Epoch 92/500\n",
      "62/62 [==============================] - 1s 13ms/step - loss: 0.4399 - accuracy: 0.7854 - val_loss: 0.7041 - val_accuracy: 0.6952\n",
      "Epoch 93/500\n",
      "62/62 [==============================] - 1s 12ms/step - loss: 0.4435 - accuracy: 0.7854 - val_loss: 0.7263 - val_accuracy: 0.6952\n",
      "Epoch 94/500\n",
      "62/62 [==============================] - 1s 12ms/step - loss: 0.4358 - accuracy: 0.7908 - val_loss: 0.7220 - val_accuracy: 0.7015\n",
      "Epoch 95/500\n",
      "62/62 [==============================] - 1s 13ms/step - loss: 0.4421 - accuracy: 0.7832 - val_loss: 0.7124 - val_accuracy: 0.7054\n",
      "Epoch 96/500\n",
      "62/62 [==============================] - 1s 13ms/step - loss: 0.4347 - accuracy: 0.7936 - val_loss: 0.7210 - val_accuracy: 0.6990\n",
      "Epoch 97/500\n",
      "62/62 [==============================] - 1s 13ms/step - loss: 0.4369 - accuracy: 0.7864 - val_loss: 0.7097 - val_accuracy: 0.7003\n",
      "Epoch 98/500\n",
      "62/62 [==============================] - 1s 13ms/step - loss: 0.4383 - accuracy: 0.7871 - val_loss: 0.7082 - val_accuracy: 0.6913\n",
      "Epoch 99/500\n",
      "62/62 [==============================] - 1s 13ms/step - loss: 0.4382 - accuracy: 0.7890 - val_loss: 0.7403 - val_accuracy: 0.6952\n",
      "Epoch 100/500\n",
      "62/62 [==============================] - 1s 13ms/step - loss: 0.4336 - accuracy: 0.7897 - val_loss: 0.7206 - val_accuracy: 0.6964\n",
      "Epoch 101/500\n",
      "62/62 [==============================] - 1s 15ms/step - loss: 0.4385 - accuracy: 0.7838 - val_loss: 0.7276 - val_accuracy: 0.6977\n",
      "Epoch 102/500\n",
      "62/62 [==============================] - 1s 14ms/step - loss: 0.4359 - accuracy: 0.7924 - val_loss: 0.7306 - val_accuracy: 0.6939\n",
      "Epoch 103/500\n",
      "62/62 [==============================] - 1s 15ms/step - loss: 0.4318 - accuracy: 0.7898 - val_loss: 0.7511 - val_accuracy: 0.6952\n",
      "Epoch 104/500\n",
      "62/62 [==============================] - 1s 14ms/step - loss: 0.4258 - accuracy: 0.7924 - val_loss: 0.7216 - val_accuracy: 0.6977\n",
      "Epoch 105/500\n",
      "62/62 [==============================] - 1s 14ms/step - loss: 0.4303 - accuracy: 0.7948 - val_loss: 0.7268 - val_accuracy: 0.6939\n",
      "Epoch 106/500\n",
      "62/62 [==============================] - 1s 13ms/step - loss: 0.4273 - accuracy: 0.7922 - val_loss: 0.7102 - val_accuracy: 0.6977\n",
      "Epoch 107/500\n",
      "62/62 [==============================] - 1s 13ms/step - loss: 0.4237 - accuracy: 0.7948 - val_loss: 0.7330 - val_accuracy: 0.6977\n",
      "Epoch 108/500\n",
      "62/62 [==============================] - 1s 13ms/step - loss: 0.4132 - accuracy: 0.7948 - val_loss: 0.7790 - val_accuracy: 0.6913\n",
      "Epoch 109/500\n",
      "62/62 [==============================] - 1s 13ms/step - loss: 0.4199 - accuracy: 0.7979 - val_loss: 0.7500 - val_accuracy: 0.6913\n",
      "Epoch 110/500\n",
      "62/62 [==============================] - 1s 13ms/step - loss: 0.4275 - accuracy: 0.7944 - val_loss: 0.7280 - val_accuracy: 0.6990\n",
      "Epoch 111/500\n",
      "62/62 [==============================] - 1s 13ms/step - loss: 0.4211 - accuracy: 0.8002 - val_loss: 0.7467 - val_accuracy: 0.6901\n",
      "Epoch 112/500\n",
      "62/62 [==============================] - 1s 13ms/step - loss: 0.4224 - accuracy: 0.7949 - val_loss: 0.7640 - val_accuracy: 0.6926\n",
      "Epoch 113/500\n",
      "62/62 [==============================] - 1s 13ms/step - loss: 0.4202 - accuracy: 0.7954 - val_loss: 0.7552 - val_accuracy: 0.6875\n",
      "Epoch 114/500\n",
      "62/62 [==============================] - 1s 13ms/step - loss: 0.4243 - accuracy: 0.7911 - val_loss: 0.7543 - val_accuracy: 0.6786\n",
      "Epoch 115/500\n",
      "62/62 [==============================] - 1s 14ms/step - loss: 0.4221 - accuracy: 0.7965 - val_loss: 0.7393 - val_accuracy: 0.6926\n",
      "Epoch 116/500\n",
      "62/62 [==============================] - 1s 13ms/step - loss: 0.4186 - accuracy: 0.7963 - val_loss: 0.7577 - val_accuracy: 0.6824\n",
      "Epoch 117/500\n",
      "62/62 [==============================] - 1s 13ms/step - loss: 0.4184 - accuracy: 0.7958 - val_loss: 0.7565 - val_accuracy: 0.6913\n",
      "Epoch 118/500\n",
      "62/62 [==============================] - 1s 13ms/step - loss: 0.4181 - accuracy: 0.7982 - val_loss: 0.7523 - val_accuracy: 0.6901\n",
      "Epoch 119/500\n",
      "62/62 [==============================] - 1s 13ms/step - loss: 0.4178 - accuracy: 0.7936 - val_loss: 0.7523 - val_accuracy: 0.7028\n",
      "Epoch 120/500\n",
      "62/62 [==============================] - 1s 14ms/step - loss: 0.4144 - accuracy: 0.7961 - val_loss: 0.7392 - val_accuracy: 0.6926\n",
      "Epoch 121/500\n",
      "62/62 [==============================] - 1s 14ms/step - loss: 0.4207 - accuracy: 0.7975 - val_loss: 0.7429 - val_accuracy: 0.6977\n",
      "Epoch 122/500\n",
      "62/62 [==============================] - 1s 13ms/step - loss: 0.4155 - accuracy: 0.7993 - val_loss: 0.7577 - val_accuracy: 0.6939\n",
      "Epoch 123/500\n",
      "62/62 [==============================] - 1s 13ms/step - loss: 0.4151 - accuracy: 0.7917 - val_loss: 0.7457 - val_accuracy: 0.6952\n",
      "Epoch 124/500\n",
      "62/62 [==============================] - 1s 13ms/step - loss: 0.4120 - accuracy: 0.8055 - val_loss: 0.7578 - val_accuracy: 0.6977\n",
      "Epoch 125/500\n",
      "62/62 [==============================] - 1s 13ms/step - loss: 0.4063 - accuracy: 0.7982 - val_loss: 0.7889 - val_accuracy: 0.6939\n",
      "Epoch 126/500\n",
      "62/62 [==============================] - 1s 14ms/step - loss: 0.4129 - accuracy: 0.7995 - val_loss: 0.7524 - val_accuracy: 0.6990\n",
      "Epoch 127/500\n",
      "62/62 [==============================] - 1s 12ms/step - loss: 0.4075 - accuracy: 0.8031 - val_loss: 0.7859 - val_accuracy: 0.6837\n",
      "Epoch 128/500\n",
      "62/62 [==============================] - 1s 13ms/step - loss: 0.4111 - accuracy: 0.8019 - val_loss: 0.7499 - val_accuracy: 0.6990\n",
      "Epoch 129/500\n",
      "62/62 [==============================] - 1s 13ms/step - loss: 0.4084 - accuracy: 0.8071 - val_loss: 0.7791 - val_accuracy: 0.6952\n",
      "Epoch 130/500\n",
      "62/62 [==============================] - 1s 13ms/step - loss: 0.4136 - accuracy: 0.8012 - val_loss: 0.7414 - val_accuracy: 0.7003\n",
      "Epoch 131/500\n",
      "62/62 [==============================] - 1s 13ms/step - loss: 0.4101 - accuracy: 0.8033 - val_loss: 0.7786 - val_accuracy: 0.7028\n",
      "Epoch 132/500\n",
      "62/62 [==============================] - 1s 13ms/step - loss: 0.4059 - accuracy: 0.8009 - val_loss: 0.7885 - val_accuracy: 0.6964\n",
      "Epoch 133/500\n",
      "62/62 [==============================] - 1s 13ms/step - loss: 0.4108 - accuracy: 0.8016 - val_loss: 0.7524 - val_accuracy: 0.6913\n",
      "Epoch 134/500\n",
      "62/62 [==============================] - 1s 13ms/step - loss: 0.4119 - accuracy: 0.8012 - val_loss: 0.7622 - val_accuracy: 0.6990\n",
      "Epoch 135/500\n",
      "62/62 [==============================] - 1s 13ms/step - loss: 0.4195 - accuracy: 0.7924 - val_loss: 0.7426 - val_accuracy: 0.6964\n",
      "Epoch 136/500\n",
      "62/62 [==============================] - 1s 14ms/step - loss: 0.3984 - accuracy: 0.8058 - val_loss: 0.7882 - val_accuracy: 0.7015\n",
      "Epoch 137/500\n",
      "62/62 [==============================] - 1s 13ms/step - loss: 0.4127 - accuracy: 0.7989 - val_loss: 0.7611 - val_accuracy: 0.6952\n",
      "Epoch 138/500\n",
      "62/62 [==============================] - 1s 13ms/step - loss: 0.4013 - accuracy: 0.8023 - val_loss: 0.7938 - val_accuracy: 0.6952\n",
      "Epoch 139/500\n",
      "62/62 [==============================] - 1s 13ms/step - loss: 0.4073 - accuracy: 0.7994 - val_loss: 0.7681 - val_accuracy: 0.6926\n",
      "Epoch 140/500\n",
      "62/62 [==============================] - 1s 13ms/step - loss: 0.4009 - accuracy: 0.8094 - val_loss: 0.8007 - val_accuracy: 0.6888\n",
      "Epoch 141/500\n",
      "62/62 [==============================] - 1s 13ms/step - loss: 0.4054 - accuracy: 0.8057 - val_loss: 0.8079 - val_accuracy: 0.6901\n",
      "Epoch 142/500\n",
      "62/62 [==============================] - 1s 12ms/step - loss: 0.4015 - accuracy: 0.8052 - val_loss: 0.8414 - val_accuracy: 0.6952\n",
      "Epoch 143/500\n",
      "62/62 [==============================] - 1s 13ms/step - loss: 0.4011 - accuracy: 0.8021 - val_loss: 0.7752 - val_accuracy: 0.6875\n",
      "Epoch 144/500\n",
      "62/62 [==============================] - 1s 13ms/step - loss: 0.4034 - accuracy: 0.8050 - val_loss: 0.7750 - val_accuracy: 0.6926\n",
      "Epoch 145/500\n",
      "62/62 [==============================] - 1s 12ms/step - loss: 0.4018 - accuracy: 0.8043 - val_loss: 0.7857 - val_accuracy: 0.6913\n",
      "Epoch 146/500\n",
      "62/62 [==============================] - 1s 13ms/step - loss: 0.4061 - accuracy: 0.8021 - val_loss: 0.7821 - val_accuracy: 0.6901\n",
      "Epoch 147/500\n",
      "62/62 [==============================] - 1s 13ms/step - loss: 0.4054 - accuracy: 0.8050 - val_loss: 0.7802 - val_accuracy: 0.6977\n",
      "Epoch 148/500\n",
      "62/62 [==============================] - 1s 14ms/step - loss: 0.4006 - accuracy: 0.8038 - val_loss: 0.7811 - val_accuracy: 0.6926\n",
      "Epoch 149/500\n",
      "62/62 [==============================] - 1s 13ms/step - loss: 0.3968 - accuracy: 0.8099 - val_loss: 0.7808 - val_accuracy: 0.7041\n",
      "Epoch 150/500\n",
      "62/62 [==============================] - 1s 13ms/step - loss: 0.4106 - accuracy: 0.8021 - val_loss: 0.7642 - val_accuracy: 0.6952\n",
      "Epoch 151/500\n",
      "62/62 [==============================] - 1s 13ms/step - loss: 0.4032 - accuracy: 0.8050 - val_loss: 0.7906 - val_accuracy: 0.6939\n",
      "Epoch 152/500\n",
      "62/62 [==============================] - 1s 13ms/step - loss: 0.3920 - accuracy: 0.8109 - val_loss: 0.7877 - val_accuracy: 0.7028\n",
      "Epoch 153/500\n",
      "62/62 [==============================] - 1s 13ms/step - loss: 0.3928 - accuracy: 0.8079 - val_loss: 0.7982 - val_accuracy: 0.7003\n",
      "Epoch 154/500\n",
      "62/62 [==============================] - 1s 13ms/step - loss: 0.3986 - accuracy: 0.8058 - val_loss: 0.8099 - val_accuracy: 0.6888\n",
      "Epoch 155/500\n",
      "62/62 [==============================] - 1s 14ms/step - loss: 0.4053 - accuracy: 0.8070 - val_loss: 0.7959 - val_accuracy: 0.6913\n",
      "Epoch 156/500\n",
      "62/62 [==============================] - 1s 13ms/step - loss: 0.3930 - accuracy: 0.8110 - val_loss: 0.7834 - val_accuracy: 0.6901\n",
      "Epoch 157/500\n",
      "62/62 [==============================] - 1s 13ms/step - loss: 0.3940 - accuracy: 0.8095 - val_loss: 0.8201 - val_accuracy: 0.6837\n",
      "Epoch 158/500\n",
      "62/62 [==============================] - 1s 14ms/step - loss: 0.3963 - accuracy: 0.8045 - val_loss: 0.7897 - val_accuracy: 0.6901\n",
      "Epoch 159/500\n",
      "62/62 [==============================] - 1s 13ms/step - loss: 0.4032 - accuracy: 0.8041 - val_loss: 0.7934 - val_accuracy: 0.6964\n",
      "Epoch 160/500\n",
      "62/62 [==============================] - 1s 13ms/step - loss: 0.3940 - accuracy: 0.8128 - val_loss: 0.7826 - val_accuracy: 0.6824\n",
      "Epoch 161/500\n",
      "62/62 [==============================] - 1s 13ms/step - loss: 0.3933 - accuracy: 0.8060 - val_loss: 0.8214 - val_accuracy: 0.6849\n",
      "Epoch 162/500\n",
      "62/62 [==============================] - 1s 12ms/step - loss: 0.3945 - accuracy: 0.8064 - val_loss: 0.8028 - val_accuracy: 0.6837\n",
      "Epoch 163/500\n",
      "62/62 [==============================] - 1s 13ms/step - loss: 0.3860 - accuracy: 0.8119 - val_loss: 0.8279 - val_accuracy: 0.6824\n",
      "Epoch 164/500\n",
      "62/62 [==============================] - 1s 13ms/step - loss: 0.4025 - accuracy: 0.8080 - val_loss: 0.8414 - val_accuracy: 0.6837\n",
      "Epoch 165/500\n",
      "62/62 [==============================] - 1s 13ms/step - loss: 0.3930 - accuracy: 0.8090 - val_loss: 0.8078 - val_accuracy: 0.6913\n",
      "Epoch 166/500\n",
      "62/62 [==============================] - 1s 13ms/step - loss: 0.3897 - accuracy: 0.8127 - val_loss: 0.8149 - val_accuracy: 0.6913\n",
      "Epoch 167/500\n",
      "62/62 [==============================] - 1s 13ms/step - loss: 0.3900 - accuracy: 0.8082 - val_loss: 0.8286 - val_accuracy: 0.6849\n",
      "Epoch 168/500\n",
      "62/62 [==============================] - 1s 13ms/step - loss: 0.3911 - accuracy: 0.8130 - val_loss: 0.8062 - val_accuracy: 0.6964\n",
      "Epoch 169/500\n",
      "62/62 [==============================] - 1s 13ms/step - loss: 0.3920 - accuracy: 0.8055 - val_loss: 0.8191 - val_accuracy: 0.6926\n",
      "Epoch 170/500\n",
      "62/62 [==============================] - 1s 12ms/step - loss: 0.3915 - accuracy: 0.8075 - val_loss: 0.8179 - val_accuracy: 0.6786\n",
      "Epoch 171/500\n",
      "62/62 [==============================] - 1s 13ms/step - loss: 0.3910 - accuracy: 0.8129 - val_loss: 0.8439 - val_accuracy: 0.6798\n",
      "Epoch 172/500\n",
      "62/62 [==============================] - 1s 14ms/step - loss: 0.3862 - accuracy: 0.8177 - val_loss: 0.8278 - val_accuracy: 0.6952\n",
      "Epoch 173/500\n",
      "62/62 [==============================] - 1s 12ms/step - loss: 0.3868 - accuracy: 0.8144 - val_loss: 0.8551 - val_accuracy: 0.6913\n",
      "Epoch 174/500\n",
      "62/62 [==============================] - 1s 13ms/step - loss: 0.3866 - accuracy: 0.8066 - val_loss: 0.8271 - val_accuracy: 0.6824\n",
      "Epoch 175/500\n",
      "62/62 [==============================] - 1s 13ms/step - loss: 0.3861 - accuracy: 0.8148 - val_loss: 0.8346 - val_accuracy: 0.6888\n",
      "Epoch 176/500\n",
      "62/62 [==============================] - 1s 13ms/step - loss: 0.3941 - accuracy: 0.8087 - val_loss: 0.8039 - val_accuracy: 0.6888\n",
      "Epoch 177/500\n",
      "62/62 [==============================] - 1s 13ms/step - loss: 0.3899 - accuracy: 0.8108 - val_loss: 0.8533 - val_accuracy: 0.6849\n",
      "Epoch 178/500\n",
      "62/62 [==============================] - 1s 14ms/step - loss: 0.3885 - accuracy: 0.8086 - val_loss: 0.8039 - val_accuracy: 0.6862\n",
      "Epoch 179/500\n",
      "62/62 [==============================] - 1s 13ms/step - loss: 0.3864 - accuracy: 0.8124 - val_loss: 0.8330 - val_accuracy: 0.6849\n",
      "Epoch 180/500\n",
      "62/62 [==============================] - 1s 13ms/step - loss: 0.3920 - accuracy: 0.8103 - val_loss: 0.8740 - val_accuracy: 0.6926\n",
      "Epoch 181/500\n",
      "62/62 [==============================] - 1s 13ms/step - loss: 0.3807 - accuracy: 0.8161 - val_loss: 0.8471 - val_accuracy: 0.6875\n",
      "Epoch 182/500\n",
      "62/62 [==============================] - 1s 13ms/step - loss: 0.3889 - accuracy: 0.8132 - val_loss: 0.8381 - val_accuracy: 0.6939\n",
      "Epoch 183/500\n",
      "62/62 [==============================] - 1s 13ms/step - loss: 0.3848 - accuracy: 0.8148 - val_loss: 0.8315 - val_accuracy: 0.6849\n",
      "Epoch 184/500\n",
      "62/62 [==============================] - 1s 13ms/step - loss: 0.3867 - accuracy: 0.8075 - val_loss: 0.8311 - val_accuracy: 0.6862\n",
      "Epoch 185/500\n",
      "62/62 [==============================] - 1s 12ms/step - loss: 0.3870 - accuracy: 0.8119 - val_loss: 0.8118 - val_accuracy: 0.6862\n",
      "Epoch 186/500\n",
      "62/62 [==============================] - 1s 13ms/step - loss: 0.3931 - accuracy: 0.8091 - val_loss: 0.8454 - val_accuracy: 0.6913\n",
      "Epoch 187/500\n",
      "62/62 [==============================] - 1s 13ms/step - loss: 0.3859 - accuracy: 0.8164 - val_loss: 0.8234 - val_accuracy: 0.6913\n",
      "Epoch 188/500\n",
      "62/62 [==============================] - 1s 13ms/step - loss: 0.3866 - accuracy: 0.8162 - val_loss: 0.8121 - val_accuracy: 0.6862\n",
      "Epoch 189/500\n",
      "62/62 [==============================] - 1s 13ms/step - loss: 0.3817 - accuracy: 0.8133 - val_loss: 0.8139 - val_accuracy: 0.6888\n",
      "Epoch 190/500\n",
      "62/62 [==============================] - 1s 13ms/step - loss: 0.3903 - accuracy: 0.8132 - val_loss: 0.8118 - val_accuracy: 0.6913\n",
      "Epoch 191/500\n",
      "62/62 [==============================] - 1s 14ms/step - loss: 0.3769 - accuracy: 0.8164 - val_loss: 0.8546 - val_accuracy: 0.6913\n",
      "Epoch 192/500\n",
      "62/62 [==============================] - 1s 14ms/step - loss: 0.3777 - accuracy: 0.8173 - val_loss: 0.8444 - val_accuracy: 0.6888\n",
      "Epoch 193/500\n",
      "62/62 [==============================] - 1s 13ms/step - loss: 0.3783 - accuracy: 0.8178 - val_loss: 0.8633 - val_accuracy: 0.7003\n",
      "Epoch 194/500\n",
      "62/62 [==============================] - 1s 13ms/step - loss: 0.3853 - accuracy: 0.8118 - val_loss: 0.8231 - val_accuracy: 0.6939\n",
      "Epoch 195/500\n",
      "62/62 [==============================] - 1s 13ms/step - loss: 0.3857 - accuracy: 0.8147 - val_loss: 0.8266 - val_accuracy: 0.6926\n",
      "Epoch 196/500\n",
      "62/62 [==============================] - 1s 13ms/step - loss: 0.3859 - accuracy: 0.8114 - val_loss: 0.8109 - val_accuracy: 0.6901\n",
      "Epoch 197/500\n",
      "62/62 [==============================] - 1s 13ms/step - loss: 0.3808 - accuracy: 0.8149 - val_loss: 0.8247 - val_accuracy: 0.7015\n",
      "Epoch 198/500\n",
      "62/62 [==============================] - 1s 14ms/step - loss: 0.3807 - accuracy: 0.8142 - val_loss: 0.8442 - val_accuracy: 0.6811\n",
      "Epoch 199/500\n",
      "62/62 [==============================] - 1s 13ms/step - loss: 0.3769 - accuracy: 0.8122 - val_loss: 0.8816 - val_accuracy: 0.6926\n",
      "Epoch 200/500\n",
      "62/62 [==============================] - 1s 13ms/step - loss: 0.3870 - accuracy: 0.8161 - val_loss: 0.8092 - val_accuracy: 0.6875\n",
      "Epoch 201/500\n",
      "62/62 [==============================] - 1s 13ms/step - loss: 0.3813 - accuracy: 0.8113 - val_loss: 0.8174 - val_accuracy: 0.6875\n",
      "Epoch 202/500\n",
      "62/62 [==============================] - 1s 13ms/step - loss: 0.3739 - accuracy: 0.8231 - val_loss: 0.8638 - val_accuracy: 0.6952\n",
      "Epoch 203/500\n",
      "62/62 [==============================] - 1s 13ms/step - loss: 0.3754 - accuracy: 0.8216 - val_loss: 0.8518 - val_accuracy: 0.6875\n",
      "Epoch 204/500\n",
      "62/62 [==============================] - 1s 13ms/step - loss: 0.3751 - accuracy: 0.8132 - val_loss: 0.8555 - val_accuracy: 0.6952\n",
      "Epoch 205/500\n",
      "62/62 [==============================] - 1s 13ms/step - loss: 0.3715 - accuracy: 0.8180 - val_loss: 0.8317 - val_accuracy: 0.6952\n",
      "Epoch 206/500\n",
      "62/62 [==============================] - 1s 13ms/step - loss: 0.3799 - accuracy: 0.8161 - val_loss: 0.8473 - val_accuracy: 0.6990\n",
      "Epoch 207/500\n",
      "62/62 [==============================] - 1s 13ms/step - loss: 0.3789 - accuracy: 0.8193 - val_loss: 0.8630 - val_accuracy: 0.6977\n",
      "Epoch 208/500\n",
      "62/62 [==============================] - 1s 13ms/step - loss: 0.3887 - accuracy: 0.8148 - val_loss: 0.8240 - val_accuracy: 0.6926\n",
      "Epoch 209/500\n",
      "62/62 [==============================] - 1s 14ms/step - loss: 0.3757 - accuracy: 0.8153 - val_loss: 0.8630 - val_accuracy: 0.6824\n",
      "Epoch 210/500\n",
      "62/62 [==============================] - 1s 13ms/step - loss: 0.3744 - accuracy: 0.8163 - val_loss: 0.8479 - val_accuracy: 0.6798\n",
      "Epoch 211/500\n",
      "62/62 [==============================] - 1s 13ms/step - loss: 0.3791 - accuracy: 0.8169 - val_loss: 0.8561 - val_accuracy: 0.6849\n",
      "Epoch 212/500\n",
      "62/62 [==============================] - 1s 13ms/step - loss: 0.3747 - accuracy: 0.8220 - val_loss: 0.8091 - val_accuracy: 0.6837\n",
      "Epoch 213/500\n",
      "62/62 [==============================] - 1s 13ms/step - loss: 0.3740 - accuracy: 0.8212 - val_loss: 0.8396 - val_accuracy: 0.6875\n",
      "Epoch 214/500\n",
      "62/62 [==============================] - 1s 13ms/step - loss: 0.3709 - accuracy: 0.8217 - val_loss: 0.8328 - val_accuracy: 0.6913\n",
      "Epoch 215/500\n",
      "62/62 [==============================] - 1s 13ms/step - loss: 0.3750 - accuracy: 0.8156 - val_loss: 0.8509 - val_accuracy: 0.6990\n",
      "Epoch 216/500\n",
      "62/62 [==============================] - 1s 13ms/step - loss: 0.3812 - accuracy: 0.8185 - val_loss: 0.8275 - val_accuracy: 0.7028\n",
      "Epoch 217/500\n",
      "62/62 [==============================] - 1s 14ms/step - loss: 0.3625 - accuracy: 0.8264 - val_loss: 0.8710 - val_accuracy: 0.6939\n",
      "Epoch 218/500\n",
      "62/62 [==============================] - 1s 15ms/step - loss: 0.3800 - accuracy: 0.8182 - val_loss: 0.8444 - val_accuracy: 0.6913\n",
      "Epoch 219/500\n",
      "62/62 [==============================] - 1s 13ms/step - loss: 0.3664 - accuracy: 0.8269 - val_loss: 0.8664 - val_accuracy: 0.6862\n",
      "Epoch 220/500\n",
      "62/62 [==============================] - 1s 12ms/step - loss: 0.3768 - accuracy: 0.8163 - val_loss: 0.8648 - val_accuracy: 0.6939\n",
      "Epoch 221/500\n",
      "62/62 [==============================] - 1s 13ms/step - loss: 0.3764 - accuracy: 0.8137 - val_loss: 0.8717 - val_accuracy: 0.6901\n",
      "Epoch 222/500\n",
      "62/62 [==============================] - 1s 13ms/step - loss: 0.3745 - accuracy: 0.8235 - val_loss: 0.8898 - val_accuracy: 0.6862\n",
      "Epoch 223/500\n",
      "62/62 [==============================] - 1s 13ms/step - loss: 0.3675 - accuracy: 0.8212 - val_loss: 0.8798 - val_accuracy: 0.6862\n",
      "Epoch 224/500\n",
      "62/62 [==============================] - 1s 13ms/step - loss: 0.3742 - accuracy: 0.8172 - val_loss: 0.8812 - val_accuracy: 0.6926\n",
      "Epoch 225/500\n",
      "62/62 [==============================] - 1s 12ms/step - loss: 0.3761 - accuracy: 0.8209 - val_loss: 0.8315 - val_accuracy: 0.6901\n",
      "Epoch 226/500\n",
      "62/62 [==============================] - 1s 13ms/step - loss: 0.3795 - accuracy: 0.8191 - val_loss: 0.8348 - val_accuracy: 0.6901\n",
      "Epoch 227/500\n",
      "62/62 [==============================] - 1s 13ms/step - loss: 0.3653 - accuracy: 0.8195 - val_loss: 0.8725 - val_accuracy: 0.6888\n",
      "Epoch 228/500\n",
      "62/62 [==============================] - 1s 13ms/step - loss: 0.3759 - accuracy: 0.8226 - val_loss: 0.8274 - val_accuracy: 0.6888\n",
      "Epoch 229/500\n",
      "62/62 [==============================] - 1s 13ms/step - loss: 0.3738 - accuracy: 0.8157 - val_loss: 0.8239 - val_accuracy: 0.6862\n",
      "Epoch 230/500\n",
      "62/62 [==============================] - 1s 14ms/step - loss: 0.3723 - accuracy: 0.8227 - val_loss: 0.8237 - val_accuracy: 0.6913\n",
      "Epoch 231/500\n",
      "62/62 [==============================] - 1s 13ms/step - loss: 0.3693 - accuracy: 0.8224 - val_loss: 0.8114 - val_accuracy: 0.6849\n",
      "Epoch 232/500\n",
      "62/62 [==============================] - 1s 13ms/step - loss: 0.3700 - accuracy: 0.8222 - val_loss: 0.8445 - val_accuracy: 0.6913\n",
      "Epoch 233/500\n",
      "62/62 [==============================] - 1s 13ms/step - loss: 0.3729 - accuracy: 0.8195 - val_loss: 0.8430 - val_accuracy: 0.6888\n",
      "Epoch 234/500\n",
      "62/62 [==============================] - 1s 13ms/step - loss: 0.3740 - accuracy: 0.8185 - val_loss: 0.8378 - val_accuracy: 0.6837\n",
      "Epoch 235/500\n",
      "62/62 [==============================] - 1s 13ms/step - loss: 0.3676 - accuracy: 0.8220 - val_loss: 0.8329 - val_accuracy: 0.6773\n",
      "Epoch 236/500\n",
      "62/62 [==============================] - 1s 13ms/step - loss: 0.3712 - accuracy: 0.8212 - val_loss: 0.8552 - val_accuracy: 0.6837\n",
      "Epoch 237/500\n",
      "62/62 [==============================] - 1s 13ms/step - loss: 0.3735 - accuracy: 0.8174 - val_loss: 0.8437 - val_accuracy: 0.6760\n",
      "Epoch 238/500\n",
      "62/62 [==============================] - 1s 13ms/step - loss: 0.3738 - accuracy: 0.8207 - val_loss: 0.8514 - val_accuracy: 0.6760\n",
      "Epoch 239/500\n",
      "62/62 [==============================] - 1s 13ms/step - loss: 0.3766 - accuracy: 0.8203 - val_loss: 0.8308 - val_accuracy: 0.6862\n",
      "Epoch 240/500\n",
      "62/62 [==============================] - 1s 13ms/step - loss: 0.3678 - accuracy: 0.8212 - val_loss: 0.8539 - val_accuracy: 0.6913\n",
      "Epoch 241/500\n",
      "62/62 [==============================] - 1s 13ms/step - loss: 0.3785 - accuracy: 0.8162 - val_loss: 0.8349 - val_accuracy: 0.6837\n",
      "Epoch 242/500\n",
      "62/62 [==============================] - 1s 13ms/step - loss: 0.3683 - accuracy: 0.8264 - val_loss: 0.8764 - val_accuracy: 0.6913\n",
      "Epoch 243/500\n",
      "62/62 [==============================] - 1s 13ms/step - loss: 0.3625 - accuracy: 0.8267 - val_loss: 0.8959 - val_accuracy: 0.6837\n",
      "Epoch 244/500\n",
      "62/62 [==============================] - 1s 13ms/step - loss: 0.3680 - accuracy: 0.8182 - val_loss: 0.8345 - val_accuracy: 0.6849\n",
      "Epoch 245/500\n",
      "62/62 [==============================] - 1s 12ms/step - loss: 0.3661 - accuracy: 0.8225 - val_loss: 0.8446 - val_accuracy: 0.6824\n",
      "Epoch 246/500\n",
      "62/62 [==============================] - 1s 13ms/step - loss: 0.3698 - accuracy: 0.8149 - val_loss: 0.8471 - val_accuracy: 0.6849\n",
      "Epoch 247/500\n",
      "62/62 [==============================] - 1s 13ms/step - loss: 0.3601 - accuracy: 0.8285 - val_loss: 0.8841 - val_accuracy: 0.6824\n",
      "Epoch 248/500\n",
      "62/62 [==============================] - 1s 13ms/step - loss: 0.3691 - accuracy: 0.8234 - val_loss: 0.8719 - val_accuracy: 0.6849\n",
      "Epoch 249/500\n",
      "62/62 [==============================] - 1s 13ms/step - loss: 0.3717 - accuracy: 0.8205 - val_loss: 0.8507 - val_accuracy: 0.6939\n",
      "Epoch 250/500\n",
      "62/62 [==============================] - 1s 14ms/step - loss: 0.3722 - accuracy: 0.8225 - val_loss: 0.8742 - val_accuracy: 0.6837\n",
      "Epoch 251/500\n",
      "62/62 [==============================] - 1s 13ms/step - loss: 0.3639 - accuracy: 0.8227 - val_loss: 0.8900 - val_accuracy: 0.6837\n",
      "Epoch 252/500\n",
      "62/62 [==============================] - 1s 13ms/step - loss: 0.3650 - accuracy: 0.8260 - val_loss: 0.8702 - val_accuracy: 0.6824\n",
      "Epoch 253/500\n",
      "62/62 [==============================] - 1s 13ms/step - loss: 0.3613 - accuracy: 0.8258 - val_loss: 0.9252 - val_accuracy: 0.6811\n",
      "Epoch 254/500\n",
      "62/62 [==============================] - 1s 13ms/step - loss: 0.3626 - accuracy: 0.8263 - val_loss: 0.8387 - val_accuracy: 0.6824\n",
      "Epoch 255/500\n",
      "62/62 [==============================] - 1s 13ms/step - loss: 0.3648 - accuracy: 0.8212 - val_loss: 0.8583 - val_accuracy: 0.6888\n",
      "Epoch 256/500\n",
      "62/62 [==============================] - 1s 13ms/step - loss: 0.3637 - accuracy: 0.8230 - val_loss: 0.8618 - val_accuracy: 0.6849\n",
      "Epoch 257/500\n",
      "62/62 [==============================] - 1s 13ms/step - loss: 0.3642 - accuracy: 0.8249 - val_loss: 0.8631 - val_accuracy: 0.6888\n",
      "Epoch 258/500\n",
      "62/62 [==============================] - 1s 13ms/step - loss: 0.3649 - accuracy: 0.8232 - val_loss: 0.8451 - val_accuracy: 0.6901\n",
      "Epoch 259/500\n",
      "62/62 [==============================] - 1s 13ms/step - loss: 0.3637 - accuracy: 0.8249 - val_loss: 0.8922 - val_accuracy: 0.6913\n",
      "Epoch 260/500\n",
      "62/62 [==============================] - 1s 13ms/step - loss: 0.3689 - accuracy: 0.8182 - val_loss: 0.8487 - val_accuracy: 0.6862\n",
      "Epoch 261/500\n",
      "62/62 [==============================] - 1s 14ms/step - loss: 0.3678 - accuracy: 0.8217 - val_loss: 0.8868 - val_accuracy: 0.6862\n",
      "Epoch 262/500\n",
      "62/62 [==============================] - 1s 13ms/step - loss: 0.3660 - accuracy: 0.8215 - val_loss: 0.8810 - val_accuracy: 0.6849\n",
      "Epoch 263/500\n",
      "62/62 [==============================] - 1s 13ms/step - loss: 0.3643 - accuracy: 0.8188 - val_loss: 0.8804 - val_accuracy: 0.6837\n",
      "Epoch 264/500\n",
      "62/62 [==============================] - 1s 13ms/step - loss: 0.3618 - accuracy: 0.8217 - val_loss: 0.8604 - val_accuracy: 0.6837\n",
      "Epoch 265/500\n",
      "62/62 [==============================] - 1s 13ms/step - loss: 0.3560 - accuracy: 0.8338 - val_loss: 0.8741 - val_accuracy: 0.6837\n",
      "Epoch 266/500\n",
      "62/62 [==============================] - 1s 13ms/step - loss: 0.3630 - accuracy: 0.8290 - val_loss: 0.8400 - val_accuracy: 0.6964\n",
      "Epoch 267/500\n",
      "62/62 [==============================] - 1s 12ms/step - loss: 0.3673 - accuracy: 0.8220 - val_loss: 0.8274 - val_accuracy: 0.6913\n",
      "Epoch 268/500\n",
      "62/62 [==============================] - 1s 13ms/step - loss: 0.3694 - accuracy: 0.8203 - val_loss: 0.8467 - val_accuracy: 0.6875\n",
      "Epoch 269/500\n",
      "62/62 [==============================] - 1s 13ms/step - loss: 0.3628 - accuracy: 0.8234 - val_loss: 0.9007 - val_accuracy: 0.6837\n",
      "Epoch 270/500\n",
      "62/62 [==============================] - 1s 13ms/step - loss: 0.3601 - accuracy: 0.8273 - val_loss: 0.8987 - val_accuracy: 0.6862\n",
      "Epoch 271/500\n",
      "62/62 [==============================] - 1s 13ms/step - loss: 0.3654 - accuracy: 0.8191 - val_loss: 0.8736 - val_accuracy: 0.6952\n",
      "Epoch 272/500\n",
      "62/62 [==============================] - 1s 13ms/step - loss: 0.3679 - accuracy: 0.8239 - val_loss: 0.8488 - val_accuracy: 0.6901\n",
      "Epoch 273/500\n",
      "62/62 [==============================] - 1s 13ms/step - loss: 0.3638 - accuracy: 0.8214 - val_loss: 0.8530 - val_accuracy: 0.6926\n",
      "Epoch 274/500\n",
      "62/62 [==============================] - 1s 13ms/step - loss: 0.3646 - accuracy: 0.8238 - val_loss: 0.8500 - val_accuracy: 0.6939\n",
      "Epoch 275/500\n",
      "62/62 [==============================] - 1s 13ms/step - loss: 0.3659 - accuracy: 0.8224 - val_loss: 0.8411 - val_accuracy: 0.6837\n",
      "Epoch 276/500\n",
      "62/62 [==============================] - 1s 13ms/step - loss: 0.3596 - accuracy: 0.8265 - val_loss: 0.8300 - val_accuracy: 0.6875\n",
      "Epoch 277/500\n",
      "62/62 [==============================] - 1s 12ms/step - loss: 0.3637 - accuracy: 0.8226 - val_loss: 0.8357 - val_accuracy: 0.6849\n",
      "Epoch 278/500\n",
      "62/62 [==============================] - 1s 13ms/step - loss: 0.3588 - accuracy: 0.8269 - val_loss: 0.8483 - val_accuracy: 0.6875\n",
      "Epoch 279/500\n",
      "62/62 [==============================] - 1s 14ms/step - loss: 0.3639 - accuracy: 0.8277 - val_loss: 0.8431 - val_accuracy: 0.6888\n",
      "Epoch 280/500\n",
      "62/62 [==============================] - 1s 13ms/step - loss: 0.3594 - accuracy: 0.8302 - val_loss: 0.8581 - val_accuracy: 0.6837\n",
      "Epoch 281/500\n",
      "62/62 [==============================] - 1s 13ms/step - loss: 0.3598 - accuracy: 0.8279 - val_loss: 0.8426 - val_accuracy: 0.6964\n",
      "Epoch 282/500\n",
      "62/62 [==============================] - 1s 13ms/step - loss: 0.3706 - accuracy: 0.8219 - val_loss: 0.8334 - val_accuracy: 0.6926\n",
      "Epoch 283/500\n",
      "62/62 [==============================] - 1s 13ms/step - loss: 0.3703 - accuracy: 0.8212 - val_loss: 0.8044 - val_accuracy: 0.6977\n",
      "Epoch 284/500\n",
      "62/62 [==============================] - 1s 13ms/step - loss: 0.3609 - accuracy: 0.8279 - val_loss: 0.8215 - val_accuracy: 0.6849\n",
      "Epoch 285/500\n",
      "62/62 [==============================] - 1s 13ms/step - loss: 0.3591 - accuracy: 0.8244 - val_loss: 0.8433 - val_accuracy: 0.6913\n",
      "Epoch 286/500\n",
      "62/62 [==============================] - 1s 13ms/step - loss: 0.3558 - accuracy: 0.8258 - val_loss: 0.8418 - val_accuracy: 0.6952\n",
      "Epoch 287/500\n",
      "62/62 [==============================] - 1s 12ms/step - loss: 0.3545 - accuracy: 0.8296 - val_loss: 0.8735 - val_accuracy: 0.6952\n",
      "Epoch 288/500\n",
      "62/62 [==============================] - 1s 14ms/step - loss: 0.3595 - accuracy: 0.8275 - val_loss: 0.8418 - val_accuracy: 0.6952\n",
      "Epoch 289/500\n",
      "62/62 [==============================] - 1s 13ms/step - loss: 0.3604 - accuracy: 0.8248 - val_loss: 0.8446 - val_accuracy: 0.6926\n",
      "Epoch 290/500\n",
      "62/62 [==============================] - 1s 14ms/step - loss: 0.3539 - accuracy: 0.8290 - val_loss: 0.8999 - val_accuracy: 0.6939\n",
      "Epoch 291/500\n",
      "62/62 [==============================] - 1s 14ms/step - loss: 0.3539 - accuracy: 0.8288 - val_loss: 0.8932 - val_accuracy: 0.6824\n",
      "Epoch 292/500\n",
      "62/62 [==============================] - 1s 13ms/step - loss: 0.3558 - accuracy: 0.8299 - val_loss: 0.8756 - val_accuracy: 0.6837\n",
      "Epoch 293/500\n",
      "62/62 [==============================] - 1s 13ms/step - loss: 0.3600 - accuracy: 0.8235 - val_loss: 0.8635 - val_accuracy: 0.6862\n",
      "Epoch 294/500\n",
      "62/62 [==============================] - 1s 13ms/step - loss: 0.3558 - accuracy: 0.8292 - val_loss: 0.8648 - val_accuracy: 0.6862\n",
      "Epoch 295/500\n",
      "62/62 [==============================] - 1s 13ms/step - loss: 0.3608 - accuracy: 0.8245 - val_loss: 0.8446 - val_accuracy: 0.6913\n",
      "Epoch 296/500\n",
      "62/62 [==============================] - 1s 13ms/step - loss: 0.3528 - accuracy: 0.8279 - val_loss: 0.8766 - val_accuracy: 0.6888\n",
      "Epoch 297/500\n",
      "62/62 [==============================] - 1s 13ms/step - loss: 0.3647 - accuracy: 0.8217 - val_loss: 0.8609 - val_accuracy: 0.6888\n",
      "Epoch 298/500\n",
      "62/62 [==============================] - 1s 15ms/step - loss: 0.3563 - accuracy: 0.8282 - val_loss: 0.8707 - val_accuracy: 0.6760\n",
      "Epoch 299/500\n",
      "62/62 [==============================] - 1s 16ms/step - loss: 0.3527 - accuracy: 0.8348 - val_loss: 0.9033 - val_accuracy: 0.6875\n",
      "Epoch 300/500\n",
      "62/62 [==============================] - 1s 15ms/step - loss: 0.3645 - accuracy: 0.8197 - val_loss: 0.8546 - val_accuracy: 0.6875\n",
      "Epoch 301/500\n",
      "62/62 [==============================] - 1s 14ms/step - loss: 0.3516 - accuracy: 0.8328 - val_loss: 0.8646 - val_accuracy: 0.6901\n",
      "Epoch 302/500\n",
      "62/62 [==============================] - 1s 14ms/step - loss: 0.3559 - accuracy: 0.8283 - val_loss: 0.8352 - val_accuracy: 0.6811\n",
      "Epoch 303/500\n",
      "62/62 [==============================] - 1s 15ms/step - loss: 0.3543 - accuracy: 0.8297 - val_loss: 0.8852 - val_accuracy: 0.6913\n",
      "Epoch 304/500\n",
      "62/62 [==============================] - 1s 14ms/step - loss: 0.3502 - accuracy: 0.8328 - val_loss: 0.8783 - val_accuracy: 0.6849\n",
      "Epoch 305/500\n",
      "62/62 [==============================] - 1s 13ms/step - loss: 0.3562 - accuracy: 0.8293 - val_loss: 0.8619 - val_accuracy: 0.6913\n",
      "Epoch 306/500\n",
      "62/62 [==============================] - 1s 13ms/step - loss: 0.3560 - accuracy: 0.8270 - val_loss: 0.8658 - val_accuracy: 0.6888\n",
      "Epoch 307/500\n",
      "62/62 [==============================] - 1s 14ms/step - loss: 0.3565 - accuracy: 0.8292 - val_loss: 0.8513 - val_accuracy: 0.6824\n",
      "Epoch 308/500\n",
      "62/62 [==============================] - 1s 14ms/step - loss: 0.3548 - accuracy: 0.8290 - val_loss: 0.8777 - val_accuracy: 0.6773\n",
      "Epoch 309/500\n",
      "62/62 [==============================] - 1s 14ms/step - loss: 0.3492 - accuracy: 0.8297 - val_loss: 0.8675 - val_accuracy: 0.6824\n",
      "Epoch 310/500\n",
      "62/62 [==============================] - 1s 14ms/step - loss: 0.3535 - accuracy: 0.8308 - val_loss: 0.8993 - val_accuracy: 0.6849\n",
      "Epoch 311/500\n",
      "62/62 [==============================] - 1s 12ms/step - loss: 0.3576 - accuracy: 0.8278 - val_loss: 0.8697 - val_accuracy: 0.6901\n",
      "Epoch 312/500\n",
      "62/62 [==============================] - 1s 13ms/step - loss: 0.3500 - accuracy: 0.8292 - val_loss: 0.8673 - val_accuracy: 0.6824\n",
      "Epoch 313/500\n",
      "62/62 [==============================] - 1s 13ms/step - loss: 0.3577 - accuracy: 0.8265 - val_loss: 0.9058 - val_accuracy: 0.6862\n",
      "Epoch 314/500\n",
      "62/62 [==============================] - 1s 13ms/step - loss: 0.3594 - accuracy: 0.8261 - val_loss: 0.8433 - val_accuracy: 0.6875\n",
      "Epoch 315/500\n",
      "62/62 [==============================] - 1s 13ms/step - loss: 0.3580 - accuracy: 0.8244 - val_loss: 0.8960 - val_accuracy: 0.6913\n",
      "Epoch 316/500\n",
      "62/62 [==============================] - 1s 13ms/step - loss: 0.3555 - accuracy: 0.8279 - val_loss: 0.8855 - val_accuracy: 0.6875\n",
      "Epoch 317/500\n",
      "62/62 [==============================] - 1s 13ms/step - loss: 0.3566 - accuracy: 0.8277 - val_loss: 0.8923 - val_accuracy: 0.6875\n",
      "Epoch 318/500\n",
      "62/62 [==============================] - 1s 13ms/step - loss: 0.3451 - accuracy: 0.8299 - val_loss: 0.8981 - val_accuracy: 0.6913\n",
      "Epoch 319/500\n",
      "62/62 [==============================] - 1s 13ms/step - loss: 0.3553 - accuracy: 0.8292 - val_loss: 0.8833 - val_accuracy: 0.6837\n",
      "Epoch 320/500\n",
      "62/62 [==============================] - 1s 13ms/step - loss: 0.3540 - accuracy: 0.8273 - val_loss: 0.8725 - val_accuracy: 0.6964\n",
      "Epoch 321/500\n",
      "62/62 [==============================] - 1s 13ms/step - loss: 0.3494 - accuracy: 0.8319 - val_loss: 0.8887 - val_accuracy: 0.6798\n",
      "Epoch 322/500\n",
      "62/62 [==============================] - 1s 14ms/step - loss: 0.3486 - accuracy: 0.8283 - val_loss: 0.9009 - val_accuracy: 0.6913\n",
      "Epoch 323/500\n",
      "62/62 [==============================] - 1s 14ms/step - loss: 0.3544 - accuracy: 0.8316 - val_loss: 0.8970 - val_accuracy: 0.6939\n",
      "Epoch 324/500\n",
      "62/62 [==============================] - 1s 14ms/step - loss: 0.3550 - accuracy: 0.8272 - val_loss: 0.8575 - val_accuracy: 0.6913\n",
      "Epoch 325/500\n",
      "62/62 [==============================] - 1s 13ms/step - loss: 0.3567 - accuracy: 0.8245 - val_loss: 0.8828 - val_accuracy: 0.6849\n",
      "Epoch 326/500\n",
      "62/62 [==============================] - 1s 12ms/step - loss: 0.3509 - accuracy: 0.8267 - val_loss: 0.8703 - val_accuracy: 0.6913\n",
      "Epoch 327/500\n",
      "62/62 [==============================] - 1s 13ms/step - loss: 0.3516 - accuracy: 0.8342 - val_loss: 0.8633 - val_accuracy: 0.7028\n",
      "Epoch 328/500\n",
      "62/62 [==============================] - 1s 13ms/step - loss: 0.3531 - accuracy: 0.8317 - val_loss: 0.8274 - val_accuracy: 0.6888\n",
      "Epoch 329/500\n",
      "62/62 [==============================] - 1s 13ms/step - loss: 0.3501 - accuracy: 0.8298 - val_loss: 0.8953 - val_accuracy: 0.6862\n",
      "Epoch 330/500\n",
      "62/62 [==============================] - 1s 14ms/step - loss: 0.3585 - accuracy: 0.8293 - val_loss: 0.8560 - val_accuracy: 0.6849\n",
      "Epoch 331/500\n",
      "62/62 [==============================] - 1s 13ms/step - loss: 0.3457 - accuracy: 0.8313 - val_loss: 0.8725 - val_accuracy: 0.6875\n",
      "Epoch 332/500\n",
      "62/62 [==============================] - 1s 13ms/step - loss: 0.3530 - accuracy: 0.8258 - val_loss: 0.8563 - val_accuracy: 0.6862\n",
      "Epoch 333/500\n",
      "62/62 [==============================] - 1s 14ms/step - loss: 0.3570 - accuracy: 0.8283 - val_loss: 0.8772 - val_accuracy: 0.6862\n",
      "Epoch 334/500\n",
      "62/62 [==============================] - 1s 13ms/step - loss: 0.3451 - accuracy: 0.8347 - val_loss: 0.8934 - val_accuracy: 0.6939\n",
      "Epoch 335/500\n",
      "62/62 [==============================] - 1s 12ms/step - loss: 0.3523 - accuracy: 0.8299 - val_loss: 0.8633 - val_accuracy: 0.6926\n",
      "Epoch 336/500\n",
      "62/62 [==============================] - 1s 13ms/step - loss: 0.3481 - accuracy: 0.8302 - val_loss: 0.8746 - val_accuracy: 0.6952\n",
      "Epoch 337/500\n",
      "62/62 [==============================] - 1s 13ms/step - loss: 0.3464 - accuracy: 0.8259 - val_loss: 0.9147 - val_accuracy: 0.6901\n",
      "Epoch 338/500\n",
      "62/62 [==============================] - 1s 13ms/step - loss: 0.3558 - accuracy: 0.8275 - val_loss: 0.8614 - val_accuracy: 0.6811\n",
      "Epoch 339/500\n",
      "62/62 [==============================] - 1s 13ms/step - loss: 0.3531 - accuracy: 0.8269 - val_loss: 0.8731 - val_accuracy: 0.6888\n",
      "Epoch 340/500\n",
      "62/62 [==============================] - 1s 13ms/step - loss: 0.3468 - accuracy: 0.8337 - val_loss: 0.9107 - val_accuracy: 0.6875\n",
      "Epoch 341/500\n",
      "62/62 [==============================] - 1s 13ms/step - loss: 0.3477 - accuracy: 0.8294 - val_loss: 0.8443 - val_accuracy: 0.6875\n",
      "Epoch 342/500\n",
      "62/62 [==============================] - 1s 13ms/step - loss: 0.3496 - accuracy: 0.8321 - val_loss: 0.8787 - val_accuracy: 0.6888\n",
      "Epoch 343/500\n",
      "62/62 [==============================] - 1s 13ms/step - loss: 0.3457 - accuracy: 0.8322 - val_loss: 0.8795 - val_accuracy: 0.6824\n",
      "Epoch 344/500\n",
      "62/62 [==============================] - 1s 14ms/step - loss: 0.3482 - accuracy: 0.8302 - val_loss: 0.9114 - val_accuracy: 0.6888\n",
      "Epoch 345/500\n",
      "62/62 [==============================] - 1s 14ms/step - loss: 0.3451 - accuracy: 0.8354 - val_loss: 0.9609 - val_accuracy: 0.6926\n",
      "Epoch 346/500\n",
      "62/62 [==============================] - 1s 13ms/step - loss: 0.3480 - accuracy: 0.8260 - val_loss: 0.9213 - val_accuracy: 0.6926\n",
      "Epoch 347/500\n",
      "62/62 [==============================] - 1s 13ms/step - loss: 0.3472 - accuracy: 0.8302 - val_loss: 0.8950 - val_accuracy: 0.6939\n",
      "Epoch 348/500\n",
      "62/62 [==============================] - 1s 13ms/step - loss: 0.3505 - accuracy: 0.8321 - val_loss: 0.8833 - val_accuracy: 0.6913\n",
      "Epoch 349/500\n",
      "62/62 [==============================] - 1s 13ms/step - loss: 0.3442 - accuracy: 0.8298 - val_loss: 0.8652 - val_accuracy: 0.6837\n",
      "Epoch 350/500\n",
      "62/62 [==============================] - 1s 13ms/step - loss: 0.3516 - accuracy: 0.8301 - val_loss: 0.8952 - val_accuracy: 0.6888\n",
      "Epoch 351/500\n",
      "62/62 [==============================] - 1s 13ms/step - loss: 0.3439 - accuracy: 0.8338 - val_loss: 0.9215 - val_accuracy: 0.6888\n",
      "Epoch 352/500\n",
      "62/62 [==============================] - 1s 13ms/step - loss: 0.3465 - accuracy: 0.8321 - val_loss: 0.9123 - val_accuracy: 0.6849\n",
      "Epoch 353/500\n",
      "62/62 [==============================] - 1s 13ms/step - loss: 0.3458 - accuracy: 0.8332 - val_loss: 0.9284 - val_accuracy: 0.7015\n",
      "Epoch 354/500\n",
      "62/62 [==============================] - 1s 13ms/step - loss: 0.3431 - accuracy: 0.8328 - val_loss: 0.9380 - val_accuracy: 0.7003\n",
      "Epoch 355/500\n",
      "62/62 [==============================] - 1s 13ms/step - loss: 0.3444 - accuracy: 0.8338 - val_loss: 0.8888 - val_accuracy: 0.6888\n",
      "Epoch 356/500\n",
      "62/62 [==============================] - 1s 14ms/step - loss: 0.3452 - accuracy: 0.8302 - val_loss: 0.8919 - val_accuracy: 0.7041\n",
      "Epoch 357/500\n",
      "62/62 [==============================] - 1s 13ms/step - loss: 0.3394 - accuracy: 0.8346 - val_loss: 0.9046 - val_accuracy: 0.7003\n",
      "Epoch 358/500\n",
      "62/62 [==============================] - 1s 13ms/step - loss: 0.3443 - accuracy: 0.8303 - val_loss: 0.9172 - val_accuracy: 0.6939\n",
      "Epoch 359/500\n",
      "62/62 [==============================] - 1s 14ms/step - loss: 0.3447 - accuracy: 0.8361 - val_loss: 0.8920 - val_accuracy: 0.6926\n",
      "Epoch 360/500\n",
      "62/62 [==============================] - 1s 13ms/step - loss: 0.3480 - accuracy: 0.8317 - val_loss: 0.8931 - val_accuracy: 0.6811\n",
      "Epoch 361/500\n",
      "62/62 [==============================] - 1s 13ms/step - loss: 0.3494 - accuracy: 0.8332 - val_loss: 0.8877 - val_accuracy: 0.6875\n",
      "Epoch 362/500\n",
      "62/62 [==============================] - 1s 13ms/step - loss: 0.3520 - accuracy: 0.8287 - val_loss: 0.8552 - val_accuracy: 0.6773\n",
      "Epoch 363/500\n",
      "62/62 [==============================] - 1s 13ms/step - loss: 0.3349 - accuracy: 0.8360 - val_loss: 0.9922 - val_accuracy: 0.6913\n",
      "Epoch 364/500\n",
      "62/62 [==============================] - 1s 14ms/step - loss: 0.3460 - accuracy: 0.8335 - val_loss: 0.8925 - val_accuracy: 0.6798\n",
      "Epoch 365/500\n",
      "62/62 [==============================] - 1s 14ms/step - loss: 0.3483 - accuracy: 0.8294 - val_loss: 0.8588 - val_accuracy: 0.6773\n",
      "Epoch 366/500\n",
      "62/62 [==============================] - 1s 13ms/step - loss: 0.3478 - accuracy: 0.8308 - val_loss: 0.9080 - val_accuracy: 0.6888\n",
      "Epoch 367/500\n",
      "62/62 [==============================] - 1s 14ms/step - loss: 0.3385 - accuracy: 0.8369 - val_loss: 0.9103 - val_accuracy: 0.6849\n",
      "Epoch 368/500\n",
      "62/62 [==============================] - 1s 13ms/step - loss: 0.3491 - accuracy: 0.8302 - val_loss: 0.9185 - val_accuracy: 0.6862\n",
      "Epoch 369/500\n",
      "62/62 [==============================] - 1s 13ms/step - loss: 0.3467 - accuracy: 0.8321 - val_loss: 0.9069 - val_accuracy: 0.6786\n",
      "Epoch 370/500\n",
      "62/62 [==============================] - 1s 14ms/step - loss: 0.3427 - accuracy: 0.8319 - val_loss: 0.9075 - val_accuracy: 0.6939\n",
      "Epoch 371/500\n",
      "62/62 [==============================] - 1s 14ms/step - loss: 0.3442 - accuracy: 0.8364 - val_loss: 0.9785 - val_accuracy: 0.6901\n",
      "Epoch 372/500\n",
      "62/62 [==============================] - 1s 13ms/step - loss: 0.3507 - accuracy: 0.8350 - val_loss: 0.8668 - val_accuracy: 0.6837\n",
      "Epoch 373/500\n",
      "62/62 [==============================] - 1s 13ms/step - loss: 0.3480 - accuracy: 0.8354 - val_loss: 0.9178 - val_accuracy: 0.6824\n",
      "Epoch 374/500\n",
      "62/62 [==============================] - 1s 13ms/step - loss: 0.3510 - accuracy: 0.8318 - val_loss: 0.9107 - val_accuracy: 0.6913\n",
      "Epoch 375/500\n",
      "62/62 [==============================] - 1s 13ms/step - loss: 0.3457 - accuracy: 0.8301 - val_loss: 0.9047 - val_accuracy: 0.6824\n",
      "Epoch 376/500\n",
      "62/62 [==============================] - 1s 13ms/step - loss: 0.3500 - accuracy: 0.8294 - val_loss: 0.8617 - val_accuracy: 0.6747\n",
      "Epoch 377/500\n",
      "62/62 [==============================] - 1s 13ms/step - loss: 0.3393 - accuracy: 0.8369 - val_loss: 0.8765 - val_accuracy: 0.6722\n",
      "Epoch 378/500\n",
      "62/62 [==============================] - 1s 13ms/step - loss: 0.3476 - accuracy: 0.8256 - val_loss: 0.8605 - val_accuracy: 0.6760\n",
      "Epoch 379/500\n",
      "62/62 [==============================] - 1s 13ms/step - loss: 0.3402 - accuracy: 0.8326 - val_loss: 0.9048 - val_accuracy: 0.6773\n",
      "Epoch 380/500\n",
      "62/62 [==============================] - 1s 13ms/step - loss: 0.3439 - accuracy: 0.8345 - val_loss: 0.8205 - val_accuracy: 0.6773\n",
      "Epoch 381/500\n",
      "62/62 [==============================] - 1s 13ms/step - loss: 0.3446 - accuracy: 0.8362 - val_loss: 0.8876 - val_accuracy: 0.6939\n",
      "Epoch 382/500\n",
      "62/62 [==============================] - 1s 13ms/step - loss: 0.3506 - accuracy: 0.8313 - val_loss: 0.8541 - val_accuracy: 0.6875\n",
      "Epoch 383/500\n",
      "62/62 [==============================] - 1s 13ms/step - loss: 0.3454 - accuracy: 0.8352 - val_loss: 0.8706 - val_accuracy: 0.6849\n",
      "Epoch 384/500\n",
      "62/62 [==============================] - 1s 13ms/step - loss: 0.3476 - accuracy: 0.8356 - val_loss: 0.8628 - val_accuracy: 0.6862\n",
      "Epoch 385/500\n",
      "62/62 [==============================] - 1s 13ms/step - loss: 0.3450 - accuracy: 0.8314 - val_loss: 0.8288 - val_accuracy: 0.6913\n",
      "Epoch 386/500\n",
      "62/62 [==============================] - 1s 13ms/step - loss: 0.3500 - accuracy: 0.8301 - val_loss: 0.8576 - val_accuracy: 0.6913\n",
      "Epoch 387/500\n",
      "62/62 [==============================] - 1s 13ms/step - loss: 0.3359 - accuracy: 0.8401 - val_loss: 0.9362 - val_accuracy: 0.6888\n",
      "Epoch 388/500\n",
      "62/62 [==============================] - 1s 13ms/step - loss: 0.3410 - accuracy: 0.8311 - val_loss: 0.8767 - val_accuracy: 0.6798\n",
      "Epoch 389/500\n",
      "62/62 [==============================] - 1s 12ms/step - loss: 0.3503 - accuracy: 0.8322 - val_loss: 0.8722 - val_accuracy: 0.6913\n",
      "Epoch 390/500\n",
      "62/62 [==============================] - 1s 13ms/step - loss: 0.3355 - accuracy: 0.8411 - val_loss: 0.8991 - val_accuracy: 0.6926\n",
      "Epoch 391/500\n",
      "62/62 [==============================] - 1s 13ms/step - loss: 0.3370 - accuracy: 0.8362 - val_loss: 0.9262 - val_accuracy: 0.6952\n",
      "Epoch 392/500\n",
      "62/62 [==============================] - 1s 13ms/step - loss: 0.3421 - accuracy: 0.8360 - val_loss: 0.8650 - val_accuracy: 0.6862\n",
      "Epoch 393/500\n",
      "62/62 [==============================] - 1s 13ms/step - loss: 0.3501 - accuracy: 0.8277 - val_loss: 0.8627 - val_accuracy: 0.6837\n",
      "Epoch 394/500\n",
      "62/62 [==============================] - 1s 13ms/step - loss: 0.3405 - accuracy: 0.8323 - val_loss: 0.8957 - val_accuracy: 0.6747\n",
      "Epoch 395/500\n",
      "62/62 [==============================] - 1s 12ms/step - loss: 0.3375 - accuracy: 0.8343 - val_loss: 0.8894 - val_accuracy: 0.6875\n",
      "Epoch 396/500\n",
      "62/62 [==============================] - 1s 13ms/step - loss: 0.3407 - accuracy: 0.8420 - val_loss: 0.9111 - val_accuracy: 0.6837\n",
      "Epoch 397/500\n",
      "62/62 [==============================] - 1s 14ms/step - loss: 0.3503 - accuracy: 0.8269 - val_loss: 0.8995 - val_accuracy: 0.6888\n",
      "Epoch 398/500\n",
      "62/62 [==============================] - 1s 13ms/step - loss: 0.3450 - accuracy: 0.8401 - val_loss: 0.9155 - val_accuracy: 0.6952\n",
      "Epoch 399/500\n",
      "62/62 [==============================] - 1s 13ms/step - loss: 0.3431 - accuracy: 0.8298 - val_loss: 0.9018 - val_accuracy: 0.6837\n",
      "Epoch 400/500\n",
      "62/62 [==============================] - 1s 13ms/step - loss: 0.3458 - accuracy: 0.8381 - val_loss: 0.8890 - val_accuracy: 0.6811\n",
      "Epoch 401/500\n",
      "62/62 [==============================] - 1s 13ms/step - loss: 0.3408 - accuracy: 0.8337 - val_loss: 0.8906 - val_accuracy: 0.6862\n",
      "Epoch 402/500\n",
      "62/62 [==============================] - 1s 14ms/step - loss: 0.3457 - accuracy: 0.8294 - val_loss: 0.9029 - val_accuracy: 0.6926\n",
      "Epoch 403/500\n",
      "62/62 [==============================] - 1s 13ms/step - loss: 0.3445 - accuracy: 0.8316 - val_loss: 0.8888 - val_accuracy: 0.6786\n",
      "Epoch 404/500\n",
      "62/62 [==============================] - 1s 13ms/step - loss: 0.3475 - accuracy: 0.8325 - val_loss: 0.8800 - val_accuracy: 0.6798\n",
      "Epoch 405/500\n",
      "62/62 [==============================] - 1s 13ms/step - loss: 0.3400 - accuracy: 0.8352 - val_loss: 0.8955 - val_accuracy: 0.6862\n",
      "Epoch 406/500\n",
      "62/62 [==============================] - 1s 13ms/step - loss: 0.3386 - accuracy: 0.8330 - val_loss: 0.8572 - val_accuracy: 0.6786\n",
      "Epoch 407/500\n",
      "62/62 [==============================] - 1s 13ms/step - loss: 0.3421 - accuracy: 0.8388 - val_loss: 0.9409 - val_accuracy: 0.6875\n",
      "Epoch 408/500\n",
      "62/62 [==============================] - 1s 13ms/step - loss: 0.3424 - accuracy: 0.8336 - val_loss: 0.8422 - val_accuracy: 0.6837\n",
      "Epoch 409/500\n",
      "62/62 [==============================] - 1s 13ms/step - loss: 0.3392 - accuracy: 0.8332 - val_loss: 0.9052 - val_accuracy: 0.6824\n",
      "Epoch 410/500\n",
      "62/62 [==============================] - 1s 13ms/step - loss: 0.3492 - accuracy: 0.8316 - val_loss: 0.8345 - val_accuracy: 0.6862\n",
      "Epoch 411/500\n",
      "62/62 [==============================] - 1s 13ms/step - loss: 0.3412 - accuracy: 0.8359 - val_loss: 0.9023 - val_accuracy: 0.6862\n",
      "Epoch 412/500\n",
      "62/62 [==============================] - 1s 13ms/step - loss: 0.3354 - accuracy: 0.8371 - val_loss: 0.8953 - val_accuracy: 0.6952\n",
      "Epoch 413/500\n",
      "62/62 [==============================] - 1s 13ms/step - loss: 0.3419 - accuracy: 0.8360 - val_loss: 0.8811 - val_accuracy: 0.6901\n",
      "Epoch 414/500\n",
      "62/62 [==============================] - 1s 12ms/step - loss: 0.3372 - accuracy: 0.8337 - val_loss: 0.9048 - val_accuracy: 0.6849\n",
      "Epoch 415/500\n",
      "62/62 [==============================] - 1s 13ms/step - loss: 0.3454 - accuracy: 0.8352 - val_loss: 0.8672 - val_accuracy: 0.6837\n",
      "Epoch 416/500\n",
      "62/62 [==============================] - 1s 15ms/step - loss: 0.3418 - accuracy: 0.8374 - val_loss: 0.9196 - val_accuracy: 0.6837\n",
      "Epoch 417/500\n",
      "62/62 [==============================] - 1s 15ms/step - loss: 0.3426 - accuracy: 0.8354 - val_loss: 0.9176 - val_accuracy: 0.6786\n",
      "Epoch 418/500\n",
      "62/62 [==============================] - 1s 12ms/step - loss: 0.3394 - accuracy: 0.8361 - val_loss: 0.8897 - val_accuracy: 0.6875\n",
      "Epoch 419/500\n",
      "62/62 [==============================] - 1s 12ms/step - loss: 0.3336 - accuracy: 0.8384 - val_loss: 0.8790 - val_accuracy: 0.6837\n",
      "Epoch 420/500\n",
      "62/62 [==============================] - 1s 12ms/step - loss: 0.3456 - accuracy: 0.8312 - val_loss: 0.8751 - val_accuracy: 0.6862\n",
      "Epoch 421/500\n",
      "62/62 [==============================] - 1s 11ms/step - loss: 0.3430 - accuracy: 0.8369 - val_loss: 0.8931 - val_accuracy: 0.6901\n",
      "Epoch 422/500\n",
      "62/62 [==============================] - 1s 13ms/step - loss: 0.3393 - accuracy: 0.8364 - val_loss: 0.9386 - val_accuracy: 0.6875\n",
      "Epoch 423/500\n",
      "62/62 [==============================] - 1s 13ms/step - loss: 0.3390 - accuracy: 0.8356 - val_loss: 0.8900 - val_accuracy: 0.6849\n",
      "Epoch 424/500\n",
      "62/62 [==============================] - 1s 14ms/step - loss: 0.3402 - accuracy: 0.8347 - val_loss: 0.9161 - val_accuracy: 0.6888\n",
      "Epoch 425/500\n",
      "62/62 [==============================] - 1s 14ms/step - loss: 0.3406 - accuracy: 0.8370 - val_loss: 0.8703 - val_accuracy: 0.6849\n",
      "Epoch 426/500\n",
      "62/62 [==============================] - 1s 13ms/step - loss: 0.3417 - accuracy: 0.8381 - val_loss: 0.8928 - val_accuracy: 0.6824\n",
      "Epoch 427/500\n",
      "62/62 [==============================] - 1s 13ms/step - loss: 0.3430 - accuracy: 0.8348 - val_loss: 0.8507 - val_accuracy: 0.6811\n",
      "Epoch 428/500\n",
      "62/62 [==============================] - 1s 13ms/step - loss: 0.3376 - accuracy: 0.8355 - val_loss: 0.8883 - val_accuracy: 0.6837\n",
      "Epoch 429/500\n",
      "62/62 [==============================] - 1s 13ms/step - loss: 0.3392 - accuracy: 0.8376 - val_loss: 0.8788 - val_accuracy: 0.6901\n",
      "Epoch 430/500\n",
      "62/62 [==============================] - 1s 14ms/step - loss: 0.3465 - accuracy: 0.8336 - val_loss: 0.9005 - val_accuracy: 0.6849\n",
      "Epoch 431/500\n",
      "62/62 [==============================] - 1s 13ms/step - loss: 0.3407 - accuracy: 0.8343 - val_loss: 0.9596 - val_accuracy: 0.6747\n",
      "Epoch 432/500\n",
      "62/62 [==============================] - 1s 13ms/step - loss: 0.3389 - accuracy: 0.8357 - val_loss: 0.9166 - val_accuracy: 0.6722\n",
      "Epoch 433/500\n",
      "62/62 [==============================] - 1s 14ms/step - loss: 0.3471 - accuracy: 0.8303 - val_loss: 0.8768 - val_accuracy: 0.6952\n",
      "Epoch 434/500\n",
      "62/62 [==============================] - 1s 13ms/step - loss: 0.3391 - accuracy: 0.8381 - val_loss: 0.8860 - val_accuracy: 0.6837\n",
      "Epoch 435/500\n",
      "62/62 [==============================] - 1s 13ms/step - loss: 0.3375 - accuracy: 0.8364 - val_loss: 0.8881 - val_accuracy: 0.6862\n",
      "Epoch 436/500\n",
      "62/62 [==============================] - 1s 13ms/step - loss: 0.3347 - accuracy: 0.8413 - val_loss: 0.9106 - val_accuracy: 0.6811\n",
      "Epoch 437/500\n",
      "62/62 [==============================] - 1s 13ms/step - loss: 0.3358 - accuracy: 0.8366 - val_loss: 0.8947 - val_accuracy: 0.6849\n",
      "Epoch 438/500\n",
      "62/62 [==============================] - 1s 13ms/step - loss: 0.3388 - accuracy: 0.8356 - val_loss: 0.8910 - val_accuracy: 0.6824\n",
      "Epoch 439/500\n",
      "62/62 [==============================] - 1s 13ms/step - loss: 0.3385 - accuracy: 0.8405 - val_loss: 0.8819 - val_accuracy: 0.6798\n",
      "Epoch 440/500\n",
      "62/62 [==============================] - 1s 13ms/step - loss: 0.3362 - accuracy: 0.8388 - val_loss: 0.8952 - val_accuracy: 0.6875\n",
      "Epoch 441/500\n",
      "62/62 [==============================] - 1s 13ms/step - loss: 0.3367 - accuracy: 0.8350 - val_loss: 0.8857 - val_accuracy: 0.6824\n",
      "Epoch 442/500\n",
      "62/62 [==============================] - 1s 13ms/step - loss: 0.3360 - accuracy: 0.8385 - val_loss: 0.9330 - val_accuracy: 0.6901\n",
      "Epoch 443/500\n",
      "62/62 [==============================] - 1s 13ms/step - loss: 0.3374 - accuracy: 0.8322 - val_loss: 0.8985 - val_accuracy: 0.6926\n",
      "Epoch 444/500\n",
      "62/62 [==============================] - 1s 13ms/step - loss: 0.3392 - accuracy: 0.8381 - val_loss: 0.8862 - val_accuracy: 0.6913\n",
      "Epoch 445/500\n",
      "62/62 [==============================] - 1s 13ms/step - loss: 0.3435 - accuracy: 0.8356 - val_loss: 0.8786 - val_accuracy: 0.6913\n",
      "Epoch 446/500\n",
      "62/62 [==============================] - 1s 14ms/step - loss: 0.3406 - accuracy: 0.8345 - val_loss: 0.9378 - val_accuracy: 0.6837\n",
      "Epoch 447/500\n",
      "62/62 [==============================] - 1s 13ms/step - loss: 0.3348 - accuracy: 0.8386 - val_loss: 0.9538 - val_accuracy: 0.6926\n",
      "Epoch 448/500\n",
      "62/62 [==============================] - 1s 13ms/step - loss: 0.3412 - accuracy: 0.8365 - val_loss: 0.8855 - val_accuracy: 0.6849\n",
      "Epoch 449/500\n",
      "62/62 [==============================] - 1s 12ms/step - loss: 0.3377 - accuracy: 0.8367 - val_loss: 0.8930 - val_accuracy: 0.6786\n",
      "Epoch 450/500\n",
      "62/62 [==============================] - 1s 13ms/step - loss: 0.3375 - accuracy: 0.8419 - val_loss: 0.8900 - val_accuracy: 0.6811\n",
      "Epoch 451/500\n",
      "62/62 [==============================] - 1s 13ms/step - loss: 0.3357 - accuracy: 0.8376 - val_loss: 0.8990 - val_accuracy: 0.6888\n",
      "Epoch 452/500\n",
      "62/62 [==============================] - 1s 13ms/step - loss: 0.3446 - accuracy: 0.8343 - val_loss: 0.8840 - val_accuracy: 0.6875\n",
      "Epoch 453/500\n",
      "62/62 [==============================] - 1s 13ms/step - loss: 0.3326 - accuracy: 0.8389 - val_loss: 0.9137 - val_accuracy: 0.6824\n",
      "Epoch 454/500\n",
      "62/62 [==============================] - 1s 13ms/step - loss: 0.3319 - accuracy: 0.8364 - val_loss: 0.8928 - val_accuracy: 0.6849\n",
      "Epoch 455/500\n",
      "62/62 [==============================] - 1s 13ms/step - loss: 0.3369 - accuracy: 0.8362 - val_loss: 0.8941 - val_accuracy: 0.6849\n",
      "Epoch 456/500\n",
      "62/62 [==============================] - 1s 14ms/step - loss: 0.3302 - accuracy: 0.8413 - val_loss: 0.9293 - val_accuracy: 0.6862\n",
      "Epoch 457/500\n",
      "62/62 [==============================] - 1s 13ms/step - loss: 0.3391 - accuracy: 0.8370 - val_loss: 0.9350 - val_accuracy: 0.6888\n",
      "Epoch 458/500\n",
      "62/62 [==============================] - 1s 13ms/step - loss: 0.3412 - accuracy: 0.8342 - val_loss: 0.9061 - val_accuracy: 0.6811\n",
      "Epoch 459/500\n",
      "62/62 [==============================] - 1s 13ms/step - loss: 0.3381 - accuracy: 0.8354 - val_loss: 0.8971 - val_accuracy: 0.6875\n",
      "Epoch 460/500\n",
      "62/62 [==============================] - 1s 14ms/step - loss: 0.3335 - accuracy: 0.8370 - val_loss: 0.9411 - val_accuracy: 0.6824\n",
      "Epoch 461/500\n",
      "62/62 [==============================] - 1s 13ms/step - loss: 0.3441 - accuracy: 0.8325 - val_loss: 0.9244 - val_accuracy: 0.6837\n",
      "Epoch 462/500\n",
      "62/62 [==============================] - 1s 13ms/step - loss: 0.3377 - accuracy: 0.8366 - val_loss: 0.8806 - val_accuracy: 0.6875\n",
      "Epoch 463/500\n",
      "62/62 [==============================] - 1s 13ms/step - loss: 0.3392 - accuracy: 0.8361 - val_loss: 0.8832 - val_accuracy: 0.6837\n",
      "Epoch 464/500\n",
      "62/62 [==============================] - 1s 13ms/step - loss: 0.3339 - accuracy: 0.8357 - val_loss: 0.9406 - val_accuracy: 0.6875\n",
      "Epoch 465/500\n",
      "62/62 [==============================] - 1s 13ms/step - loss: 0.3289 - accuracy: 0.8386 - val_loss: 0.9315 - val_accuracy: 0.6913\n",
      "Epoch 466/500\n",
      "62/62 [==============================] - 1s 13ms/step - loss: 0.3306 - accuracy: 0.8422 - val_loss: 0.9329 - val_accuracy: 0.6747\n",
      "Epoch 467/500\n",
      "62/62 [==============================] - 1s 13ms/step - loss: 0.3292 - accuracy: 0.8404 - val_loss: 0.9045 - val_accuracy: 0.6849\n",
      "Epoch 468/500\n",
      "62/62 [==============================] - 1s 14ms/step - loss: 0.3367 - accuracy: 0.8360 - val_loss: 0.8706 - val_accuracy: 0.6888\n",
      "Epoch 469/500\n",
      "62/62 [==============================] - 1s 14ms/step - loss: 0.3309 - accuracy: 0.8361 - val_loss: 0.9140 - val_accuracy: 0.6901\n",
      "Epoch 470/500\n",
      "62/62 [==============================] - 1s 14ms/step - loss: 0.3342 - accuracy: 0.8419 - val_loss: 0.9081 - val_accuracy: 0.6952\n",
      "Epoch 471/500\n",
      "62/62 [==============================] - 1s 14ms/step - loss: 0.3304 - accuracy: 0.8398 - val_loss: 0.8860 - val_accuracy: 0.6798\n",
      "Epoch 472/500\n",
      "62/62 [==============================] - 1s 14ms/step - loss: 0.3326 - accuracy: 0.8372 - val_loss: 0.9117 - val_accuracy: 0.6798\n",
      "Epoch 473/500\n",
      "62/62 [==============================] - 1s 14ms/step - loss: 0.3393 - accuracy: 0.8391 - val_loss: 0.8834 - val_accuracy: 0.6786\n",
      "Epoch 474/500\n",
      "62/62 [==============================] - 1s 13ms/step - loss: 0.3392 - accuracy: 0.8357 - val_loss: 0.8679 - val_accuracy: 0.6990\n",
      "Epoch 475/500\n",
      "62/62 [==============================] - 1s 14ms/step - loss: 0.3360 - accuracy: 0.8425 - val_loss: 0.9237 - val_accuracy: 0.6773\n",
      "Epoch 476/500\n",
      "62/62 [==============================] - 1s 13ms/step - loss: 0.3346 - accuracy: 0.8367 - val_loss: 0.9060 - val_accuracy: 0.6849\n",
      "Epoch 477/500\n",
      "62/62 [==============================] - 1s 13ms/step - loss: 0.3325 - accuracy: 0.8413 - val_loss: 0.9229 - val_accuracy: 0.6888\n",
      "Epoch 478/500\n",
      "62/62 [==============================] - 1s 13ms/step - loss: 0.3281 - accuracy: 0.8395 - val_loss: 0.9456 - val_accuracy: 0.6926\n",
      "Epoch 479/500\n",
      "62/62 [==============================] - 1s 13ms/step - loss: 0.3365 - accuracy: 0.8381 - val_loss: 0.8633 - val_accuracy: 0.6862\n",
      "Epoch 480/500\n",
      "62/62 [==============================] - 1s 13ms/step - loss: 0.3349 - accuracy: 0.8361 - val_loss: 0.8663 - val_accuracy: 0.6901\n",
      "Epoch 481/500\n",
      "62/62 [==============================] - 1s 13ms/step - loss: 0.3384 - accuracy: 0.8356 - val_loss: 0.8712 - val_accuracy: 0.6811\n",
      "Epoch 482/500\n",
      "62/62 [==============================] - 1s 13ms/step - loss: 0.3363 - accuracy: 0.8417 - val_loss: 0.8672 - val_accuracy: 0.6875\n",
      "Epoch 483/500\n",
      "62/62 [==============================] - 1s 13ms/step - loss: 0.3327 - accuracy: 0.8415 - val_loss: 0.8605 - val_accuracy: 0.6901\n",
      "Epoch 484/500\n",
      "62/62 [==============================] - 1s 13ms/step - loss: 0.3360 - accuracy: 0.8375 - val_loss: 0.8861 - val_accuracy: 0.6824\n",
      "Epoch 485/500\n",
      "62/62 [==============================] - 1s 13ms/step - loss: 0.3376 - accuracy: 0.8343 - val_loss: 0.8307 - val_accuracy: 0.6901\n",
      "Epoch 486/500\n",
      "62/62 [==============================] - 1s 13ms/step - loss: 0.3337 - accuracy: 0.8376 - val_loss: 0.8651 - val_accuracy: 0.6837\n",
      "Epoch 487/500\n",
      "62/62 [==============================] - 1s 15ms/step - loss: 0.3351 - accuracy: 0.8384 - val_loss: 0.8637 - val_accuracy: 0.6875\n",
      "Epoch 488/500\n",
      "62/62 [==============================] - 1s 13ms/step - loss: 0.3332 - accuracy: 0.8411 - val_loss: 0.9101 - val_accuracy: 0.6875\n",
      "Epoch 489/500\n",
      "62/62 [==============================] - 1s 13ms/step - loss: 0.3320 - accuracy: 0.8377 - val_loss: 0.8743 - val_accuracy: 0.6875\n",
      "Epoch 490/500\n",
      "62/62 [==============================] - 1s 14ms/step - loss: 0.3311 - accuracy: 0.8389 - val_loss: 0.9110 - val_accuracy: 0.6939\n",
      "Epoch 491/500\n",
      "62/62 [==============================] - 1s 13ms/step - loss: 0.3338 - accuracy: 0.8366 - val_loss: 0.8914 - val_accuracy: 0.6875\n",
      "Epoch 492/500\n",
      "62/62 [==============================] - 1s 14ms/step - loss: 0.3308 - accuracy: 0.8366 - val_loss: 0.9685 - val_accuracy: 0.6913\n",
      "Epoch 493/500\n",
      "62/62 [==============================] - 1s 13ms/step - loss: 0.3361 - accuracy: 0.8380 - val_loss: 0.8919 - val_accuracy: 0.6888\n",
      "Epoch 494/500\n",
      "62/62 [==============================] - 1s 13ms/step - loss: 0.3301 - accuracy: 0.8384 - val_loss: 0.9320 - val_accuracy: 0.6964\n",
      "Epoch 495/500\n",
      "62/62 [==============================] - 1s 13ms/step - loss: 0.3278 - accuracy: 0.8408 - val_loss: 0.9667 - val_accuracy: 0.6939\n",
      "Epoch 496/500\n",
      "62/62 [==============================] - 1s 12ms/step - loss: 0.3314 - accuracy: 0.8428 - val_loss: 0.9286 - val_accuracy: 0.6875\n",
      "Epoch 497/500\n",
      "62/62 [==============================] - 1s 13ms/step - loss: 0.3293 - accuracy: 0.8364 - val_loss: 0.9090 - val_accuracy: 0.6888\n",
      "Epoch 498/500\n",
      "62/62 [==============================] - 1s 13ms/step - loss: 0.3388 - accuracy: 0.8335 - val_loss: 0.9073 - val_accuracy: 0.6990\n",
      "Epoch 499/500\n",
      "62/62 [==============================] - 1s 13ms/step - loss: 0.3341 - accuracy: 0.8342 - val_loss: 0.8716 - val_accuracy: 0.6926\n",
      "Epoch 500/500\n",
      "62/62 [==============================] - 1s 13ms/step - loss: 0.3291 - accuracy: 0.8422 - val_loss: 0.9400 - val_accuracy: 0.6824\n"
     ]
    }
   ],
   "source": [
    "models = [small_model, medium_model, large_model]\n",
    "\n",
    "for model in models:\n",
    "    model.fit(train_X, train_y, epochs = 500, batch_size = 128, validation_data = (val_X, val_y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3357\n",
      "190801\n",
      "1457251\n"
     ]
    }
   ],
   "source": [
    "for model in models:\n",
    "    print(model.count_params())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "25/25 [==============================] - 0s 5ms/step\n",
      "25/25 [==============================] - 0s 2ms/step\n",
      "25/25 [==============================] - 0s 2ms/step\n",
      "25/25 [==============================] - 0s 4ms/step\n",
      "25/25 [==============================] - 0s 2ms/step\n",
      "25/25 [==============================] - 0s 2ms/step\n",
      "25/25 [==============================] - 0s 2ms/step\n",
      "25/25 [==============================] - 0s 2ms/step\n",
      "25/25 [==============================] - 0s 2ms/step\n",
      "25/25 [==============================] - 0s 2ms/step\n",
      "25/25 [==============================] - 0s 2ms/step\n",
      "25/25 [==============================] - 0s 2ms/step\n",
      "25/25 [==============================] - 0s 2ms/step\n",
      "25/25 [==============================] - 0s 2ms/step\n",
      "25/25 [==============================] - 0s 2ms/step\n",
      "25/25 [==============================] - 0s 2ms/step\n",
      "25/25 [==============================] - 0s 2ms/step\n",
      "25/25 [==============================] - 0s 2ms/step\n",
      "25/25 [==============================] - 0s 3ms/step\n",
      "25/25 [==============================] - 0s 3ms/step\n",
      "25/25 [==============================] - 0s 2ms/step\n",
      "25/25 [==============================] - 0s 2ms/step\n",
      "25/25 [==============================] - 0s 2ms/step\n",
      "25/25 [==============================] - 0s 3ms/step\n",
      "25/25 [==============================] - 0s 3ms/step\n",
      "25/25 [==============================] - 0s 3ms/step\n",
      "25/25 [==============================] - 0s 3ms/step\n",
      "25/25 [==============================] - 0s 3ms/step\n",
      "25/25 [==============================] - 0s 5ms/step\n",
      "25/25 [==============================] - 0s 4ms/step\n",
      "25/25 [==============================] - 0s 3ms/step\n",
      "25/25 [==============================] - 0s 3ms/step\n",
      "25/25 [==============================] - 0s 3ms/step\n",
      "25/25 [==============================] - 0s 3ms/step\n",
      "25/25 [==============================] - 0s 3ms/step\n",
      "25/25 [==============================] - 0s 3ms/step\n",
      "25/25 [==============================] - 0s 2ms/step\n",
      "25/25 [==============================] - 0s 3ms/step\n",
      "25/25 [==============================] - 0s 3ms/step\n",
      "25/25 [==============================] - 0s 2ms/step\n",
      "25/25 [==============================] - 0s 2ms/step\n",
      "25/25 [==============================] - 0s 3ms/step\n",
      "25/25 [==============================] - 0s 3ms/step\n",
      "25/25 [==============================] - 0s 3ms/step\n",
      "25/25 [==============================] - 0s 4ms/step\n",
      "25/25 [==============================] - 0s 3ms/step\n",
      "25/25 [==============================] - 0s 4ms/step\n",
      "25/25 [==============================] - 0s 4ms/step\n",
      "25/25 [==============================] - 0s 4ms/step\n",
      "25/25 [==============================] - 0s 3ms/step\n",
      "25/25 [==============================] - 0s 3ms/step\n",
      "25/25 [==============================] - 0s 3ms/step\n",
      "25/25 [==============================] - 0s 3ms/step\n",
      "25/25 [==============================] - 0s 5ms/step\n",
      "25/25 [==============================] - 0s 4ms/step\n",
      "25/25 [==============================] - 0s 4ms/step\n",
      "25/25 [==============================] - 0s 3ms/step\n",
      "25/25 [==============================] - 0s 3ms/step\n",
      "25/25 [==============================] - 0s 3ms/step\n",
      "25/25 [==============================] - 0s 4ms/step\n",
      "25/25 [==============================] - 0s 3ms/step\n",
      "25/25 [==============================] - 0s 3ms/step\n",
      "25/25 [==============================] - 0s 3ms/step\n",
      "25/25 [==============================] - 0s 3ms/step\n",
      "25/25 [==============================] - 0s 3ms/step\n",
      "25/25 [==============================] - 0s 3ms/step\n",
      "25/25 [==============================] - 0s 3ms/step\n",
      "25/25 [==============================] - 0s 3ms/step\n",
      "25/25 [==============================] - 0s 3ms/step\n",
      "25/25 [==============================] - 0s 3ms/step\n",
      "25/25 [==============================] - 0s 3ms/step\n",
      "25/25 [==============================] - 0s 4ms/step\n",
      "25/25 [==============================] - 0s 3ms/step\n",
      "25/25 [==============================] - 0s 3ms/step\n",
      "25/25 [==============================] - 0s 3ms/step\n",
      "25/25 [==============================] - 0s 3ms/step\n",
      "25/25 [==============================] - 0s 3ms/step\n",
      "25/25 [==============================] - 0s 3ms/step\n",
      "25/25 [==============================] - 0s 3ms/step\n",
      "25/25 [==============================] - 0s 3ms/step\n",
      "25/25 [==============================] - 0s 3ms/step\n",
      "25/25 [==============================] - 0s 3ms/step\n",
      "25/25 [==============================] - 0s 2ms/step\n",
      "25/25 [==============================] - 0s 3ms/step\n",
      "25/25 [==============================] - 0s 3ms/step\n",
      "25/25 [==============================] - 0s 3ms/step\n",
      "25/25 [==============================] - 0s 3ms/step\n",
      "25/25 [==============================] - 0s 3ms/step\n",
      "25/25 [==============================] - 0s 3ms/step\n",
      "25/25 [==============================] - 0s 4ms/step\n",
      "25/25 [==============================] - 0s 3ms/step\n",
      "25/25 [==============================] - 0s 3ms/step\n",
      "25/25 [==============================] - 0s 4ms/step\n",
      "25/25 [==============================] - 0s 4ms/step\n",
      "25/25 [==============================] - 0s 3ms/step\n",
      "25/25 [==============================] - 0s 3ms/step\n",
      "25/25 [==============================] - 0s 4ms/step\n",
      "25/25 [==============================] - 0s 3ms/step\n",
      "25/25 [==============================] - 0s 4ms/step\n",
      "25/25 [==============================] - 0s 3ms/step\n",
      "25/25 [==============================] - 0s 4ms/step\n",
      "25/25 [==============================] - 0s 4ms/step\n",
      "25/25 [==============================] - 0s 4ms/step\n",
      "25/25 [==============================] - 0s 4ms/step\n",
      "25/25 [==============================] - 0s 3ms/step\n",
      "25/25 [==============================] - 0s 3ms/step\n",
      "25/25 [==============================] - 0s 3ms/step\n",
      "25/25 [==============================] - 0s 3ms/step\n",
      "25/25 [==============================] - 0s 3ms/step\n",
      "25/25 [==============================] - 0s 3ms/step\n",
      "25/25 [==============================] - 0s 3ms/step\n",
      "25/25 [==============================] - 0s 3ms/step\n",
      "25/25 [==============================] - 0s 3ms/step\n",
      "25/25 [==============================] - 0s 4ms/step\n",
      "25/25 [==============================] - 0s 3ms/step\n",
      "25/25 [==============================] - 0s 5ms/step\n",
      "25/25 [==============================] - 0s 4ms/step\n",
      "25/25 [==============================] - 0s 3ms/step\n",
      "25/25 [==============================] - 0s 5ms/step\n",
      "25/25 [==============================] - 0s 3ms/step\n",
      "25/25 [==============================] - 0s 3ms/step\n",
      "25/25 [==============================] - 0s 3ms/step\n",
      "25/25 [==============================] - 0s 3ms/step\n",
      "25/25 [==============================] - 0s 3ms/step\n",
      "25/25 [==============================] - 0s 3ms/step\n",
      "25/25 [==============================] - 0s 3ms/step\n",
      "25/25 [==============================] - 0s 3ms/step\n",
      "25/25 [==============================] - 0s 3ms/step\n",
      "25/25 [==============================] - 0s 3ms/step\n",
      "25/25 [==============================] - 0s 5ms/step\n",
      "25/25 [==============================] - 0s 4ms/step\n",
      "25/25 [==============================] - 0s 4ms/step\n",
      "25/25 [==============================] - 0s 4ms/step\n",
      "25/25 [==============================] - 0s 5ms/step\n",
      "25/25 [==============================] - 0s 4ms/step\n",
      "25/25 [==============================] - 0s 3ms/step\n",
      "25/25 [==============================] - 0s 3ms/step\n",
      "25/25 [==============================] - 0s 3ms/step\n",
      "25/25 [==============================] - 0s 3ms/step\n",
      "25/25 [==============================] - 0s 3ms/step\n",
      "25/25 [==============================] - 0s 3ms/step\n",
      "25/25 [==============================] - 0s 3ms/step\n",
      "25/25 [==============================] - 0s 3ms/step\n",
      "25/25 [==============================] - 0s 3ms/step\n",
      "25/25 [==============================] - 0s 3ms/step\n",
      "25/25 [==============================] - 0s 3ms/step\n",
      "25/25 [==============================] - 0s 5ms/step\n",
      "25/25 [==============================] - 0s 3ms/step\n",
      "25/25 [==============================] - 0s 3ms/step\n",
      "25/25 [==============================] - 0s 3ms/step\n",
      "25/25 [==============================] - 0s 3ms/step\n",
      "25/25 [==============================] - 0s 3ms/step\n",
      "25/25 [==============================] - 0s 4ms/step\n",
      "25/25 [==============================] - 0s 3ms/step\n",
      "25/25 [==============================] - 0s 3ms/step\n",
      "25/25 [==============================] - 0s 3ms/step\n",
      "25/25 [==============================] - 0s 3ms/step\n",
      "25/25 [==============================] - 0s 3ms/step\n",
      "25/25 [==============================] - 0s 5ms/step\n",
      "25/25 [==============================] - 0s 5ms/step\n",
      "25/25 [==============================] - 0s 5ms/step\n",
      "25/25 [==============================] - 0s 6ms/step\n",
      "25/25 [==============================] - 0s 3ms/step\n",
      "25/25 [==============================] - 0s 3ms/step\n",
      "25/25 [==============================] - 0s 8ms/step\n",
      "25/25 [==============================] - 0s 3ms/step\n",
      "25/25 [==============================] - 0s 3ms/step\n",
      "25/25 [==============================] - 0s 3ms/step\n",
      "25/25 [==============================] - 0s 3ms/step\n",
      "25/25 [==============================] - 0s 3ms/step\n",
      "25/25 [==============================] - 0s 6ms/step\n",
      "25/25 [==============================] - 0s 4ms/step\n",
      "25/25 [==============================] - 0s 5ms/step\n",
      "25/25 [==============================] - 0s 5ms/step\n",
      "25/25 [==============================] - 0s 4ms/step\n",
      "25/25 [==============================] - 0s 5ms/step\n",
      "25/25 [==============================] - 0s 8ms/step\n",
      "25/25 [==============================] - 0s 4ms/step\n",
      "25/25 [==============================] - 0s 4ms/step\n",
      "25/25 [==============================] - 0s 5ms/step\n",
      "25/25 [==============================] - 0s 3ms/step\n",
      "25/25 [==============================] - 0s 4ms/step\n",
      "25/25 [==============================] - 0s 3ms/step\n",
      "25/25 [==============================] - 0s 6ms/step\n",
      "25/25 [==============================] - 0s 7ms/step\n",
      "25/25 [==============================] - 0s 3ms/step\n",
      "25/25 [==============================] - 0s 3ms/step\n",
      "25/25 [==============================] - 0s 3ms/step\n",
      "25/25 [==============================] - 0s 3ms/step\n",
      "25/25 [==============================] - 0s 4ms/step\n",
      "25/25 [==============================] - 0s 8ms/step\n",
      "25/25 [==============================] - 0s 3ms/step\n",
      "25/25 [==============================] - 0s 3ms/step\n",
      "25/25 [==============================] - 0s 3ms/step\n",
      "25/25 [==============================] - 0s 4ms/step\n",
      "25/25 [==============================] - 0s 4ms/step\n",
      "25/25 [==============================] - 0s 3ms/step\n",
      "25/25 [==============================] - 0s 4ms/step\n",
      "25/25 [==============================] - 0s 3ms/step\n",
      "25/25 [==============================] - 0s 5ms/step\n",
      "25/25 [==============================] - 0s 4ms/step\n",
      "25/25 [==============================] - 0s 4ms/step\n",
      "25/25 [==============================] - 0s 3ms/step\n",
      "25/25 [==============================] - 0s 3ms/step\n",
      "25/25 [==============================] - 0s 3ms/step\n",
      "25/25 [==============================] - 0s 3ms/step\n",
      "25/25 [==============================] - 0s 3ms/step\n",
      "25/25 [==============================] - 0s 3ms/step\n",
      "25/25 [==============================] - 0s 3ms/step\n",
      "25/25 [==============================] - 0s 3ms/step\n",
      "25/25 [==============================] - 0s 4ms/step\n",
      "25/25 [==============================] - 0s 3ms/step\n",
      "25/25 [==============================] - 0s 4ms/step\n",
      "25/25 [==============================] - 0s 4ms/step\n",
      "25/25 [==============================] - 0s 4ms/step\n",
      "25/25 [==============================] - 0s 4ms/step\n",
      "25/25 [==============================] - 0s 3ms/step\n",
      "25/25 [==============================] - 0s 4ms/step\n",
      "25/25 [==============================] - 0s 4ms/step\n",
      "25/25 [==============================] - 0s 4ms/step\n",
      "25/25 [==============================] - 0s 4ms/step\n",
      "25/25 [==============================] - 0s 3ms/step\n",
      "25/25 [==============================] - 0s 3ms/step\n",
      "25/25 [==============================] - 0s 3ms/step\n",
      "25/25 [==============================] - 0s 5ms/step\n",
      "25/25 [==============================] - 0s 4ms/step\n",
      "25/25 [==============================] - 0s 4ms/step\n",
      "25/25 [==============================] - 0s 5ms/step\n",
      "25/25 [==============================] - 0s 5ms/step\n",
      "25/25 [==============================] - 0s 5ms/step\n",
      "25/25 [==============================] - 0s 3ms/step\n",
      "25/25 [==============================] - 0s 4ms/step\n",
      "25/25 [==============================] - 0s 3ms/step\n",
      "25/25 [==============================] - 0s 3ms/step\n",
      "25/25 [==============================] - 0s 3ms/step\n",
      "25/25 [==============================] - 0s 3ms/step\n",
      "25/25 [==============================] - 0s 4ms/step\n",
      "25/25 [==============================] - 0s 3ms/step\n",
      "25/25 [==============================] - 0s 3ms/step\n",
      "25/25 [==============================] - 0s 3ms/step\n",
      "25/25 [==============================] - 0s 3ms/step\n",
      "25/25 [==============================] - 0s 5ms/step\n",
      "25/25 [==============================] - 0s 4ms/step\n",
      "25/25 [==============================] - 0s 3ms/step\n",
      "25/25 [==============================] - 0s 5ms/step\n",
      "25/25 [==============================] - 0s 4ms/step\n",
      "25/25 [==============================] - 0s 3ms/step\n",
      "25/25 [==============================] - 0s 3ms/step\n",
      "25/25 [==============================] - 0s 4ms/step\n",
      "25/25 [==============================] - 0s 3ms/step\n",
      "25/25 [==============================] - 0s 3ms/step\n",
      "25/25 [==============================] - 0s 4ms/step\n",
      "25/25 [==============================] - 0s 4ms/step\n",
      "25/25 [==============================] - 0s 6ms/step\n",
      "25/25 [==============================] - 0s 3ms/step\n",
      "25/25 [==============================] - 0s 3ms/step\n",
      "25/25 [==============================] - 0s 8ms/step\n",
      "25/25 [==============================] - 0s 4ms/step\n",
      "25/25 [==============================] - 0s 5ms/step\n",
      "25/25 [==============================] - 0s 3ms/step\n",
      "25/25 [==============================] - 0s 3ms/step\n",
      "25/25 [==============================] - 0s 3ms/step\n",
      "25/25 [==============================] - 0s 3ms/step\n",
      "25/25 [==============================] - 0s 4ms/step\n",
      "25/25 [==============================] - 0s 4ms/step\n",
      "25/25 [==============================] - 0s 3ms/step\n",
      "25/25 [==============================] - 0s 3ms/step\n",
      "25/25 [==============================] - 0s 3ms/step\n",
      "25/25 [==============================] - 0s 3ms/step\n",
      "25/25 [==============================] - 0s 4ms/step\n",
      "25/25 [==============================] - 0s 3ms/step\n",
      "25/25 [==============================] - 0s 3ms/step\n",
      "25/25 [==============================] - 0s 3ms/step\n",
      "25/25 [==============================] - 0s 3ms/step\n",
      "25/25 [==============================] - 0s 3ms/step\n",
      "25/25 [==============================] - 0s 3ms/step\n",
      "25/25 [==============================] - 0s 3ms/step\n",
      "25/25 [==============================] - 0s 4ms/step\n",
      "25/25 [==============================] - 0s 3ms/step\n",
      "25/25 [==============================] - 0s 3ms/step\n",
      "25/25 [==============================] - 0s 5ms/step\n",
      "25/25 [==============================] - 0s 4ms/step\n",
      "25/25 [==============================] - 0s 4ms/step\n",
      "25/25 [==============================] - 0s 4ms/step\n",
      "25/25 [==============================] - 0s 3ms/step\n",
      "25/25 [==============================] - 0s 6ms/step\n",
      "25/25 [==============================] - 0s 4ms/step\n",
      "25/25 [==============================] - 0s 5ms/step\n",
      "25/25 [==============================] - 0s 4ms/step\n",
      "25/25 [==============================] - 0s 6ms/step\n",
      "25/25 [==============================] - 0s 5ms/step\n",
      "25/25 [==============================] - 0s 3ms/step\n",
      "25/25 [==============================] - 0s 3ms/step\n",
      "25/25 [==============================] - 0s 4ms/step\n",
      "25/25 [==============================] - 0s 4ms/step\n",
      "25/25 [==============================] - 0s 3ms/step\n",
      "25/25 [==============================] - 0s 3ms/step\n",
      "25/25 [==============================] - 0s 3ms/step\n",
      "25/25 [==============================] - 0s 6ms/step\n",
      "25/25 [==============================] - 0s 3ms/step\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import fbeta_score\n",
    "import model_stats\n",
    "\n",
    "\n",
    "model_stats_dict = {}\n",
    "\n",
    "for model in models:\n",
    "    ms = model_stats.stats(model, test_X.drop('ids', axis = 1), test_y)\n",
    "    ms.get_threshold_scores()\n",
    "    model_stats_dict[model] = ms\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.0, 1.0)"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "colors = ['green', 'orange', 'red']\n",
    "\n",
    "for i, (k, v) in enumerate(model_stats_dict.items()):\n",
    "    combined = v.threshold_scores_df['combined']\n",
    "    combined.plot(label = k.count_params(), color=colors[i], linewidth = 4)\n",
    "\n",
    "plt.legend(title='Number of parameters')   \n",
    "plt.xlabel('Threshold', fontsize = 14)\n",
    "plt.ylabel('Combined Score', fontsize = 14) \n",
    "plt.xlim(0, 1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "25/25 [==============================] - 0s 4ms/step\n"
     ]
    }
   ],
   "source": [
    "y_pred = small_model.predict(test_X.drop('ids', axis = 1))\n",
    "\n",
    "\n",
    "prediction = pd.concat([test_X['ids'], test_y, pd.DataFrame(y_pred)], axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ids</th>\n",
       "      <th>tox_bin</th>\n",
       "      <th>prediction</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>O=S(=O)([O-])c1cc(O)ccc1O</td>\n",
       "      <td>0</td>\n",
       "      <td>0.547206</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Cc1cn([C@H]2C=C[C@@H](CO)O2)c(=O)[nH]c1=O</td>\n",
       "      <td>0</td>\n",
       "      <td>0.246894</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>CCCCc1nc2cccnc2n1Cc1ccc(-c2ccccc2-c2nnn[n-]2)cc1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.698589</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>CCN(CC)CCOC(=O)C1(c2ccccc2)CCCC1.CCN(CC)CCOC(=...</td>\n",
       "      <td>0</td>\n",
       "      <td>0.424995</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>CC(=O)SC[C@@H](C)C(=O)N1CCC[C@H]1C(=O)N[C@@H](...</td>\n",
       "      <td>0</td>\n",
       "      <td>0.304463</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>778</th>\n",
       "      <td>C1CSCCS1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.591752</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>779</th>\n",
       "      <td>CC(=O)CC(C)(C)O</td>\n",
       "      <td>0</td>\n",
       "      <td>0.305277</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>780</th>\n",
       "      <td>CC(C)=CCNc1ncnc2c1ncn2[C@@H]1O[C@H](CO)[C@@H](...</td>\n",
       "      <td>1</td>\n",
       "      <td>0.343047</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>781</th>\n",
       "      <td>COc1ccc(CN2CCN(C(c3ccc(F)cc3)c3ccc(F)cc3)CC2)c...</td>\n",
       "      <td>1</td>\n",
       "      <td>0.510794</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>782</th>\n",
       "      <td>COC(=O)[C@]12CCC(C)(C)C[C@H]1[C@H]1C(=O)C=C3[C...</td>\n",
       "      <td>1</td>\n",
       "      <td>0.812893</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>783 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   ids  tox_bin  prediction\n",
       "0                            O=S(=O)([O-])c1cc(O)ccc1O        0    0.547206\n",
       "1            Cc1cn([C@H]2C=C[C@@H](CO)O2)c(=O)[nH]c1=O        0    0.246894\n",
       "2     CCCCc1nc2cccnc2n1Cc1ccc(-c2ccccc2-c2nnn[n-]2)cc1        1    0.698589\n",
       "3    CCN(CC)CCOC(=O)C1(c2ccccc2)CCCC1.CCN(CC)CCOC(=...        0    0.424995\n",
       "4    CC(=O)SC[C@@H](C)C(=O)N1CCC[C@H]1C(=O)N[C@@H](...        0    0.304463\n",
       "..                                                 ...      ...         ...\n",
       "778                                           C1CSCCS1        0    0.591752\n",
       "779                                    CC(=O)CC(C)(C)O        0    0.305277\n",
       "780  CC(C)=CCNc1ncnc2c1ncn2[C@@H]1O[C@H](CO)[C@@H](...        1    0.343047\n",
       "781  COc1ccc(CN2CCN(C(c3ccc(F)cc3)c3ccc(F)cc3)CC2)c...        1    0.510794\n",
       "782  COC(=O)[C@]12CCC(C)(C)C[C@H]1[C@H]1C(=O)C=C3[C...        1    0.812893\n",
       "\n",
       "[783 rows x 3 columns]"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prediction = prediction.rename(columns = {0: 'prediction'})\n",
    "prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ids</th>\n",
       "      <th>tox_bin</th>\n",
       "      <th>prediction</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>700</th>\n",
       "      <td>CC(C(O)c1ccccc1)N(C)CCOC(c1ccccc1)c1ccccc1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.976399</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>398</th>\n",
       "      <td>IC(I)I</td>\n",
       "      <td>1</td>\n",
       "      <td>0.972524</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>333</th>\n",
       "      <td>Cc1cc(O)c2c(c1)C(=O)c1cc(O)cc(O)c1C2=O</td>\n",
       "      <td>1</td>\n",
       "      <td>0.971642</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>Nc1c(Cl)cc(Cl)cc1Cl</td>\n",
       "      <td>0</td>\n",
       "      <td>0.971518</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>429</th>\n",
       "      <td>C1CC2OC2CC1C1CO1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.969301</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>441</th>\n",
       "      <td>C#CC(C)(C)O</td>\n",
       "      <td>0</td>\n",
       "      <td>0.170571</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>326</th>\n",
       "      <td>COc1nc(C)nc(NC(=O)NS(=O)(=O)c2ccccc2OCCCl)n1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.160016</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>575</th>\n",
       "      <td>CCN[C@@H]1C[C@H](N)[C@@H](OC2OC(CN)=CCC2N)[C@H...</td>\n",
       "      <td>0</td>\n",
       "      <td>0.145643</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>365</th>\n",
       "      <td>CCc1c(C)[nH]c2c1C(=O)C(CN1CCOCC1)CC2</td>\n",
       "      <td>0</td>\n",
       "      <td>0.129314</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>164</th>\n",
       "      <td>c1ccc2cc3ccccc3cc2c1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.117159</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>783 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   ids  tox_bin  prediction\n",
       "700         CC(C(O)c1ccccc1)N(C)CCOC(c1ccccc1)c1ccccc1        0    0.976399\n",
       "398                                             IC(I)I        1    0.972524\n",
       "333             Cc1cc(O)c2c(c1)C(=O)c1cc(O)cc(O)c1C2=O        1    0.971642\n",
       "42                                 Nc1c(Cl)cc(Cl)cc1Cl        0    0.971518\n",
       "429                                   C1CC2OC2CC1C1CO1        0    0.969301\n",
       "..                                                 ...      ...         ...\n",
       "441                                        C#CC(C)(C)O        0    0.170571\n",
       "326       COc1nc(C)nc(NC(=O)NS(=O)(=O)c2ccccc2OCCCl)n1        0    0.160016\n",
       "575  CCN[C@@H]1C[C@H](N)[C@@H](OC2OC(CN)=CCC2N)[C@H...        0    0.145643\n",
       "365               CCc1c(C)[nH]c2c1C(=O)C(CN1CCOCC1)CC2        0    0.129314\n",
       "164                               c1ccc2cc3ccccc3cc2c1        1    0.117159\n",
       "\n",
       "[783 rows x 3 columns]"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sorted_df = prediction.sort_values(by = 'prediction', ascending = False)\n",
    "\n",
    "sorted_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "prediction.to_csv('prediction.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ml_for_chemists_tf2",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
